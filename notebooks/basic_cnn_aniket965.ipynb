{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\nfrom os.path import isdir, join\nimport librosa\n\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[{"output_type":"stream","text":"['train', 'sample_submission.csv']\n","name":"stdout"}]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"audio_path = \"../input/train/audio\"\nprint(os.listdir(audio_path))","execution_count":2,"outputs":[{"output_type":"stream","text":"['no', 'seven', 'right', 'up', 'down', 'eight', 'six', 'wow', 'bird', 'tree', 'happy', 'three', 'five', 'zero', 'go', 'left', 'nine', 'two', 'four', 'yes', 'bed', 'stop', '_background_noise_', 'cat', 'dog', 'marvin', 'off', 'one', 'on', 'sheila', 'house']\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# all audio dirs\ndirs = [f for f in os.listdir(audio_path) if os.path.isdir(join(audio_path, f))]\ndirs.sort()","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import matplotlib.pyplot as plt\n# plt.figure(figsize=(10, 4))\n# librosa.display.specshow(mfcc, x_axis='time')\n# plt.colorbar()\n# plt.title('MFCC')\n# plt.tight_layout()","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import librosa.display","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import matplotlib.pyplot as plt\n# plt.figure(figsize=(10, 4))\n# librosa.display.specshow(mfcc, x_axis='time')\n# plt.colorbar()\n# plt.title('MFCC')\n# plt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport librosa\nimport numpy as np\nclass AudioFeatureDataset():\n    def __init__(self,file_path):\n        self.file_path = file_path\n        self.labels = os.listdir(self.file_path)\n        self.target_labels = ['no', 'seven', 'right', 'up', 'down', 'eight', 'six', 'wow', 'bird', 'tree', 'happy', 'three', 'five', 'zero', 'go', 'left', 'nine', 'two', 'four', 'yes', 'bed', 'stop', 'cat', 'dog', 'marvin', 'off', 'one', 'on', 'sheila', 'house']\n        self.data_dict = {}\n        for tl in self.target_labels:\n            files_dir = os.path.join(file_path,tl)\n            all_audio_fp_s =[ os.path.join(files_dir,f) for f in os.listdir(files_dir)]\n            self.data_dict[tl] = all_audio_fp_s\n    \n    def process(self,file,max_pad = 35):\n        samps,sr = librosa.load(file, mono=True, sr=None)\n        mfcc = librosa.feature.mfcc(samps, sr = sr)\n        pad_width = max_pad - mfcc.shape[1]\n        mfcc = np.pad(mfcc, pad_width=((0, 0), (0, pad_width)), mode='constant')\n        return mfcc\n    def get_dataset(self):\n        labels =  []\n        features = []\n        for t in self.target_labels:\n            for fp in self.data_dict[t]:\n                labels.append(t)\n                features.append(self.process(fp))\n        return labels, features","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a = AudioFeatureDataset(audio_path)","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y,x = a.get_dataset()","execution_count":24,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = np.array(x)\nY = np.array(Y)","execution_count":25,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ndef get_train_test(split_ratio=0.6, random_state=42):\n    return train_test_split(librosa.util.normalize(x), Y, test_size= (1 - split_ratio), random_state=random_state, shuffle=True)","execution_count":26,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = get_train_test()","execution_count":27,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.figure(figsize=(10, 4))\nlibrosa.display.specshow(X_train[3], x_axis='time')\nplt.colorbar()\nplt.title('MFCC')\nplt.tight_layout()","execution_count":28,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 720x288 with 2 Axes>","image/png":"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\n"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.utils.np_utils import to_categorical","execution_count":29,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nX_train = X_train.reshape(X_train.shape[0], 20, 35, 1)","execution_count":30,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nlabelencoder = LabelEncoder()","execution_count":31,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labelencoder.fit_transform(y_test)","execution_count":32,"outputs":[{"output_type":"execute_result","execution_count":32,"data":{"text/plain":"array([ 3, 14, 25, ..., 25, 21,  6])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"mapping = dict(zip(labelencoder.classes_, range(len(labelencoder.classes_))))","execution_count":33,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mapping","execution_count":34,"outputs":[{"output_type":"execute_result","execution_count":34,"data":{"text/plain":"{'bed': 0,\n 'bird': 1,\n 'cat': 2,\n 'dog': 3,\n 'down': 4,\n 'eight': 5,\n 'five': 6,\n 'four': 7,\n 'go': 8,\n 'happy': 9,\n 'house': 10,\n 'left': 11,\n 'marvin': 12,\n 'nine': 13,\n 'no': 14,\n 'off': 15,\n 'on': 16,\n 'one': 17,\n 'right': 18,\n 'seven': 19,\n 'sheila': 20,\n 'six': 21,\n 'stop': 22,\n 'three': 23,\n 'tree': 24,\n 'two': 25,\n 'up': 26,\n 'wow': 27,\n 'yes': 28,\n 'zero': 29}"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test = labelencoder.fit_transform(y_test)\nmapping = dict(zip(labelencoder.classes_, range(len(labelencoder.classes_))))","execution_count":35,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mapping","execution_count":36,"outputs":[{"output_type":"execute_result","execution_count":36,"data":{"text/plain":"{'bed': 0,\n 'bird': 1,\n 'cat': 2,\n 'dog': 3,\n 'down': 4,\n 'eight': 5,\n 'five': 6,\n 'four': 7,\n 'go': 8,\n 'happy': 9,\n 'house': 10,\n 'left': 11,\n 'marvin': 12,\n 'nine': 13,\n 'no': 14,\n 'off': 15,\n 'on': 16,\n 'one': 17,\n 'right': 18,\n 'seven': 19,\n 'sheila': 20,\n 'six': 21,\n 'stop': 22,\n 'three': 23,\n 'tree': 24,\n 'two': 25,\n 'up': 26,\n 'wow': 27,\n 'yes': 28,\n 'zero': 29}"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test","execution_count":37,"outputs":[{"output_type":"execute_result","execution_count":37,"data":{"text/plain":"array([ 3, 14, 25, ..., 25, 21,  6])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = labelencoder.fit_transform(y_train)\nmapping = dict(zip(labelencoder.classes_, range(len(labelencoder.classes_))))","execution_count":38,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mapping","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D","execution_count":39,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test = to_categorical(y_test)\ny_train = to_categorical(y_train)","execution_count":40,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test.shape","execution_count":41,"outputs":[{"output_type":"execute_result","execution_count":41,"data":{"text/plain":"(25889, 20, 35)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nX_test = X_test.reshape(X_test.shape[0], 20, 35, 1)","execution_count":42,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test.shape","execution_count":43,"outputs":[{"output_type":"execute_result","execution_count":43,"data":{"text/plain":"(25889, 20, 35, 1)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.optimizers import Optimizer\nfrom keras import backend as K\nimport six\nimport copy\nfrom six.moves import zip\nfrom keras.utils.generic_utils import serialize_keras_object\nfrom keras.utils.generic_utils import deserialize_keras_object\nfrom keras.legacy import interfaces\nclass AdamW(Optimizer):\n    \"\"\"Adam optimizer.\n    Default parameters follow those provided in the original paper.\n    # Arguments\n        lr: float >= 0. Learning rate.\n        beta_1: float, 0 < beta < 1. Generally close to 1.\n        beta_2: float, 0 < beta < 1. Generally close to 1.\n        epsilon: float >= 0. Fuzz factor.\n        decay: float >= 0. Learning rate decay over each update.\n        weight_decay: float >= 0. Decoupled weight decay over each update.\n    # References\n        - [Adam - A Method for Stochastic Optimization](http://arxiv.org/abs/1412.6980v8)\n        - [Optimization for Deep Learning Highlights in 2017](http://ruder.io/deep-learning-optimization-2017/index.html)\n        - [Fixing Weight Decay Regularization in Adam](https://arxiv.org/abs/1711.05101)\n    \"\"\"\n\n    def __init__(self, lr=0.001, beta_1=0.9, beta_2=0.999, weight_decay=1e-4,  # decoupled weight decay (1/6)\n                 epsilon=1e-8, decay=0., **kwargs):\n        super(AdamW, self).__init__(**kwargs)\n        with K.name_scope(self.__class__.__name__):\n            self.iterations = K.variable(0, dtype='int64', name='iterations')\n            self.lr = K.variable(lr, name='lr')\n            self.init_lr = lr # decoupled weight decay (2/6)\n            self.beta_1 = K.variable(beta_1, name='beta_1')\n            self.beta_2 = K.variable(beta_2, name='beta_2')\n            self.decay = K.variable(decay, name='decay')\n            self.wd = K.variable(weight_decay, name='weight_decay') # decoupled weight decay (3/6)\n        self.epsilon = epsilon\n        self.initial_decay = decay\n\n    @interfaces.legacy_get_updates_support\n    def get_updates(self, loss, params):\n        grads = self.get_gradients(loss, params)\n        self.updates = [K.update_add(self.iterations, 1)]\n        wd = self.wd # decoupled weight decay (4/6)\n\n        lr = self.lr\n        if self.initial_decay > 0:\n            lr *= (1. / (1. + self.decay * K.cast(self.iterations,\n                                                  K.dtype(self.decay))))\n        eta_t = lr / self.init_lr # decoupled weight decay (5/6)\n\n        t = K.cast(self.iterations, K.floatx()) + 1\n        lr_t = lr * (K.sqrt(1. - K.pow(self.beta_2, t)) /\n                     (1. - K.pow(self.beta_1, t)))\n\n        ms = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n        vs = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n        self.weights = [self.iterations] + ms + vs\n\n        for p, g, m, v in zip(params, grads, ms, vs):\n            m_t = (self.beta_1 * m) + (1. - self.beta_1) * g\n            v_t = (self.beta_2 * v) + (1. - self.beta_2) * K.square(g)\n            p_t = p - lr_t * m_t / (K.sqrt(v_t) + self.epsilon) - eta_t * wd * p # decoupled weight decay (6/6)\n\n            self.updates.append(K.update(m, m_t))\n            self.updates.append(K.update(v, v_t))\n            new_p = p_t\n\n            # Apply constraints.\n            if getattr(p, 'constraint', None) is not None:\n                new_p = p.constraint(new_p)\n\n            self.updates.append(K.update(p, new_p))\n        return self.updates\n\n    def get_config(self):\n        config = {'lr': float(K.get_value(self.lr)),\n                  'beta_1': float(K.get_value(self.beta_1)),\n                  'beta_2': float(K.get_value(self.beta_2)),\n                  'decay': float(K.get_value(self.decay)),\n                  'weight_decay': float(K.get_value(self.wd)),\n                  'epsilon': self.epsilon}\n        base_config = super(AdamW, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))","execution_count":44,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(Conv2D(64, kernel_size=(20, 8), activation='relu', input_shape=(20, 35, 1)))\nmodel.add(MaxPooling2D(pool_size=(2, 2),dim_ordering=\"th\"))\nmodel.add(Dropout(0.25))\nmodel.add(Conv2D(64, kernel_size=(10, 4), activation='relu',dim_ordering=\"th\"))\nmodel.add(MaxPooling2D(pool_size=(2, 2),dim_ordering=\"th\"))\nmodel.add(Dropout(0.25))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(30, activation='softmax'))\nmodel.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=keras.optimizers.adam(),metrics=['accuracy'])","execution_count":46,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\")`\n  This is separate from the ipykernel package so we can avoid doing imports until\n/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, kernel_size=(10, 4), activation=\"relu\", data_format=\"channels_first\")`\n  \"\"\"\n/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:6: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\")`\n  \n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(X_train[1000:], y_train[1000:], batch_size=100, epochs=50, verbose=1, validation_data=(X_test, y_test))","execution_count":49,"outputs":[{"output_type":"stream","text":"Train on 37832 samples, validate on 25889 samples\nEpoch 1/50\n37832/37832 [==============================] - 18s 483us/step - loss: 1.3368 - acc: 0.5922 - val_loss: 0.8635 - val_acc: 0.7608\nEpoch 2/50\n37832/37832 [==============================] - 18s 478us/step - loss: 0.9520 - acc: 0.7133 - val_loss: 0.7140 - val_acc: 0.8023\nEpoch 3/50\n37832/37832 [==============================] - 18s 481us/step - loss: 0.7901 - acc: 0.7615 - val_loss: 0.6204 - val_acc: 0.8286\nEpoch 4/50\n37832/37832 [==============================] - 18s 480us/step - loss: 0.7033 - acc: 0.7836 - val_loss: 0.5740 - val_acc: 0.8423\nEpoch 5/50\n37832/37832 [==============================] - 18s 483us/step - loss: 0.6438 - acc: 0.8045 - val_loss: 0.5437 - val_acc: 0.8510\nEpoch 6/50\n37832/37832 [==============================] - 18s 480us/step - loss: 0.6061 - acc: 0.8148 - val_loss: 0.5074 - val_acc: 0.8579\nEpoch 7/50\n37832/37832 [==============================] - 18s 481us/step - loss: 0.5771 - acc: 0.8235 - val_loss: 0.4888 - val_acc: 0.8638\nEpoch 8/50\n37832/37832 [==============================] - 18s 483us/step - loss: 0.5445 - acc: 0.8335 - val_loss: 0.4617 - val_acc: 0.8694\nEpoch 9/50\n37832/37832 [==============================] - 18s 480us/step - loss: 0.5277 - acc: 0.8378 - val_loss: 0.4606 - val_acc: 0.8699\nEpoch 10/50\n37832/37832 [==============================] - 18s 480us/step - loss: 0.5111 - acc: 0.8417 - val_loss: 0.4381 - val_acc: 0.8779\nEpoch 11/50\n37832/37832 [==============================] - 18s 483us/step - loss: 0.4927 - acc: 0.8511 - val_loss: 0.4278 - val_acc: 0.8823\nEpoch 12/50\n37832/37832 [==============================] - 18s 478us/step - loss: 0.4754 - acc: 0.8528 - val_loss: 0.4236 - val_acc: 0.8793\nEpoch 13/50\n37832/37832 [==============================] - 18s 483us/step - loss: 0.4588 - acc: 0.8583 - val_loss: 0.4036 - val_acc: 0.8853\nEpoch 14/50\n37832/37832 [==============================] - 18s 480us/step - loss: 0.4545 - acc: 0.8594 - val_loss: 0.4002 - val_acc: 0.8850\nEpoch 15/50\n37832/37832 [==============================] - 18s 481us/step - loss: 0.4449 - acc: 0.8621 - val_loss: 0.3962 - val_acc: 0.8885\nEpoch 16/50\n37832/37832 [==============================] - 18s 480us/step - loss: 0.4400 - acc: 0.8626 - val_loss: 0.3984 - val_acc: 0.8869\nEpoch 17/50\n37832/37832 [==============================] - 19s 491us/step - loss: 0.4247 - acc: 0.8699 - val_loss: 0.4012 - val_acc: 0.8871\nEpoch 18/50\n37832/37832 [==============================] - 18s 487us/step - loss: 0.4238 - acc: 0.8692 - val_loss: 0.3915 - val_acc: 0.8879\nEpoch 19/50\n37832/37832 [==============================] - 18s 481us/step - loss: 0.4178 - acc: 0.8712 - val_loss: 0.3900 - val_acc: 0.8867\nEpoch 20/50\n37832/37832 [==============================] - 18s 480us/step - loss: 0.4010 - acc: 0.8767 - val_loss: 0.3750 - val_acc: 0.8913\nEpoch 21/50\n37832/37832 [==============================] - 18s 481us/step - loss: 0.4011 - acc: 0.8757 - val_loss: 0.3784 - val_acc: 0.8928\nEpoch 22/50\n37832/37832 [==============================] - 18s 482us/step - loss: 0.3938 - acc: 0.8787 - val_loss: 0.3734 - val_acc: 0.8878\nEpoch 23/50\n37832/37832 [==============================] - 18s 487us/step - loss: 0.3898 - acc: 0.8793 - val_loss: 0.3713 - val_acc: 0.8937\nEpoch 24/50\n37832/37832 [==============================] - 19s 490us/step - loss: 0.3767 - acc: 0.8839 - val_loss: 0.3614 - val_acc: 0.8954\nEpoch 25/50\n37832/37832 [==============================] - 19s 491us/step - loss: 0.3746 - acc: 0.8840 - val_loss: 0.3693 - val_acc: 0.8927\nEpoch 26/50\n37832/37832 [==============================] - 18s 486us/step - loss: 0.3712 - acc: 0.8850 - val_loss: 0.3581 - val_acc: 0.8967\nEpoch 27/50\n37832/37832 [==============================] - 18s 485us/step - loss: 0.3695 - acc: 0.8852 - val_loss: 0.3654 - val_acc: 0.8954\nEpoch 28/50\n37832/37832 [==============================] - 19s 489us/step - loss: 0.3644 - acc: 0.8857 - val_loss: 0.3600 - val_acc: 0.8940\nEpoch 29/50\n37832/37832 [==============================] - 18s 481us/step - loss: 0.3606 - acc: 0.8867 - val_loss: 0.3562 - val_acc: 0.8979\nEpoch 30/50\n37832/37832 [==============================] - 18s 485us/step - loss: 0.3588 - acc: 0.8871 - val_loss: 0.3647 - val_acc: 0.8969\nEpoch 31/50\n37832/37832 [==============================] - 18s 484us/step - loss: 0.3471 - acc: 0.8916 - val_loss: 0.3566 - val_acc: 0.8978\nEpoch 32/50\n37832/37832 [==============================] - 18s 480us/step - loss: 0.3471 - acc: 0.8916 - val_loss: 0.3595 - val_acc: 0.8954\nEpoch 33/50\n37832/37832 [==============================] - 18s 486us/step - loss: 0.3484 - acc: 0.8912 - val_loss: 0.3544 - val_acc: 0.8981\nEpoch 34/50\n37832/37832 [==============================] - 19s 496us/step - loss: 0.3410 - acc: 0.8928 - val_loss: 0.3511 - val_acc: 0.8979\nEpoch 35/50\n37832/37832 [==============================] - 19s 489us/step - loss: 0.3388 - acc: 0.8935 - val_loss: 0.3514 - val_acc: 0.8966\nEpoch 36/50\n37832/37832 [==============================] - 18s 486us/step - loss: 0.3291 - acc: 0.8969 - val_loss: 0.3567 - val_acc: 0.8959\nEpoch 37/50\n37832/37832 [==============================] - 18s 487us/step - loss: 0.3288 - acc: 0.8965 - val_loss: 0.3478 - val_acc: 0.8988\nEpoch 38/50\n37832/37832 [==============================] - 18s 484us/step - loss: 0.3254 - acc: 0.8967 - val_loss: 0.3486 - val_acc: 0.8987\nEpoch 39/50\n37832/37832 [==============================] - 18s 486us/step - loss: 0.3256 - acc: 0.8959 - val_loss: 0.3463 - val_acc: 0.8998\nEpoch 40/50\n37832/37832 [==============================] - 18s 486us/step - loss: 0.3313 - acc: 0.8949 - val_loss: 0.3460 - val_acc: 0.9007\nEpoch 41/50\n37832/37832 [==============================] - 19s 490us/step - loss: 0.3177 - acc: 0.8999 - val_loss: 0.3375 - val_acc: 0.8985\nEpoch 42/50\n37832/37832 [==============================] - 18s 485us/step - loss: 0.3164 - acc: 0.8990 - val_loss: 0.3484 - val_acc: 0.8971\nEpoch 43/50\n37832/37832 [==============================] - 18s 486us/step - loss: 0.3186 - acc: 0.8996 - val_loss: 0.3440 - val_acc: 0.8975\nEpoch 44/50\n37832/37832 [==============================] - 18s 489us/step - loss: 0.3097 - acc: 0.9018 - val_loss: 0.3431 - val_acc: 0.8989\nEpoch 45/50\n37832/37832 [==============================] - 18s 481us/step - loss: 0.3125 - acc: 0.8997 - val_loss: 0.3399 - val_acc: 0.8996\nEpoch 46/50\n37832/37832 [==============================] - 18s 485us/step - loss: 0.3091 - acc: 0.9009 - val_loss: 0.3402 - val_acc: 0.9013\nEpoch 47/50\n37832/37832 [==============================] - 18s 484us/step - loss: 0.3102 - acc: 0.9024 - val_loss: 0.3401 - val_acc: 0.9010\nEpoch 48/50\n37832/37832 [==============================] - 18s 481us/step - loss: 0.3093 - acc: 0.9020 - val_loss: 0.3417 - val_acc: 0.8982\nEpoch 49/50\n37832/37832 [==============================] - 18s 483us/step - loss: 0.3064 - acc: 0.9030 - val_loss: 0.3367 - val_acc: 0.9016\nEpoch 50/50\n37832/37832 [==============================] - 18s 485us/step - loss: 0.3034 - acc: 0.9032 - val_loss: 0.3346 - val_acc: 0.9019\n","name":"stdout"},{"output_type":"execute_result","execution_count":49,"data":{"text/plain":"<keras.callbacks.History at 0x7f5429a08780>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ncount = 0\nfor i in range(1000):    \n    tesval = np.array([X_train[i]]).reshape(1,20,35,1)\n    if np.argmax(model.predict(tesval)) ==  np.argmax(y_train[i]):\n        count+= 1\nprint(count)","execution_count":51,"outputs":[{"output_type":"stream","text":"903\nCPU times: user 2.29 s, sys: 980 ms, total: 3.27 s\nWall time: 1.84 s\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"tesval.shape","execution_count":52,"outputs":[{"output_type":"execute_result","execution_count":52,"data":{"text/plain":"(1, 20, 35, 1)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.argmax(model.predict(tesval))","execution_count":53,"outputs":[{"output_type":"execute_result","execution_count":53,"data":{"text/plain":"6"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"tesval.shape","execution_count":56,"outputs":[{"output_type":"execute_result","execution_count":56,"data":{"text/plain":"(1, 20, 35, 1)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save_weights('result.h5')","execution_count":60,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":59,"outputs":[{"output_type":"execute_result","execution_count":59,"data":{"text/plain":"['input', 'config', 'working', 'lib']"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}