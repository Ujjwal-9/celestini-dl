{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\nfrom os.path import isdir, join\nimport librosa\nfrom tqdm import tqdm\n# Any results you write to the current directory are saved as output.\nimport tensorflow as tf\nif tf.test.gpu_device_name():\n    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\nelse:\n    print(\"Please install GPU version of TF\")","execution_count":2,"outputs":[{"output_type":"stream","text":"['train', 'sample_submission.csv']\nDefault GPU Device: /device:GPU:0\n","name":"stdout"}]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# os.listdir(\"../input/dataasdfasd/\")\n# audio_file_path = \"../input/dataasdfasd/output.wav\"\n# os.linesep()\n# samps,sr = librosa.load(audio_file_path, mono=True, sr=None)\n# mfcc = librosa.feature.mfcc(samps, sr = sr)z\n# pad_width = max_pad - mfcc.shape[1]\n# mfcc = np.pad(mfcc, pad_width=((0, 0), (0, pad_width)), mode='constant')\naudio_path = \"../input/train/audio/\"","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# all audio dirs\ndirs = [f for f in os.listdir(audio_path) if os.path.isdir(join(audio_path, f))]\ndirs.sort()","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(dirs)","execution_count":5,"outputs":[{"output_type":"stream","text":"['_background_noise_', 'bed', 'bird', 'cat', 'dog', 'down', 'eight', 'five', 'four', 'go', 'happy', 'house', 'left', 'marvin', 'nine', 'no', 'off', 'on', 'one', 'right', 'seven', 'sheila', 'six', 'stop', 'three', 'tree', 'two', 'up', 'wow', 'yes', 'zero']\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import librosa.display","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import matplotlib.pyplot as plt\n# plt.figure(figsize=(10, 4))\n# librosa.display.specshow(mfcc, x_axis='time')\n# plt.colorbar()\n# plt.title('MFCC')\n# plt.tight_layout()","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport librosa\nimport numpy as np\nclass AudioFeatureDataset():\n    def __init__(self,file_path):\n        self.file_path = file_path\n        self.labels = os.listdir(self.file_path)\n        self.labels.remove('_background_noise_')\n        self.target_labels = ['no', 'left', 'right', 'up', 'yes', 'down', 'stop', 'go', 'on', 'off','silence','unknown']\n        self.data_dict = {}\n        for tl in self.labels:\n            files_dir = os.path.join(file_path,tl)\n            all_audio_fp_s =[ os.path.join(files_dir,f) for f in os.listdir(files_dir)]\n            self.data_dict[tl] = all_audio_fp_s\n    \n    def process(self,file,max_pad = 32):\n        try:\n            samps,sr = librosa.load(file, mono=True, sr=None)\n            pad_len = 16000 - samps.shape[0]\n            if pad_len  >= 0:\n                samps= np.pad(samps,(0,pad_len),'constant')\n            return np.array(samps[:16000])\n        except:\n            print(file)\n\n\n    def get_dataset(self, include_background = False):\n        labels =  []\n        features = []\n        for t in tqdm(self.labels):\n            if (t == \"_background_noise_\"):\n                pass\n            if( t not in self.target_labels):\n                for fp in self.data_dict[t]:\n                    labels.append('unknown')\n                    features.append(self.process(fp))\n            else:\n                 for fp in self.data_dict[t]:\n                    labels.append(t)\n                    features.append(self.process(fp))\n        if include_background:\n            _dir_path = (audio_path + \"/_background_noise_\")\n            all_files_in_dir = os.listdir(_dir_path)\n            all_files_in_dir.remove('README.md')\n            all_sound_path = [ (audio_path + \"/_background_noise_/\" + x) for x in all_files_in_dir]\n            all_sound_path\n            all_samps = []\n            for file in all_sound_path:\n                samps,sr = librosa.load(file, mono=True, sr=None)\n                k = int(samps.shape[0]/16000) * 16000\n                samps =samps[:k].reshape(int(samps.shape[0]/16000),16000)\n                for s in tqdm(range(len(samps))):\n                    all_samps.append(samps[s])\n                    labels.append('silence')\n                    features.append(samps[s])\n            all_samps = np.array(all_samps)\n            \n        return labels, features","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a = AudioFeatureDataset(audio_path)","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y,x = a.get_dataset(True)","execution_count":10,"outputs":[{"output_type":"stream","text":"100%|██████████| 30/30 [02:23<00:00,  4.52s/it]\n100%|██████████| 60/60 [00:00<00:00, 64165.79it/s]\n100%|██████████| 61/61 [00:00<00:00, 197112.90it/s]\n100%|██████████| 95/95 [00:00<00:00, 242077.08it/s]\n100%|██████████| 61/61 [00:00<00:00, 196055.59it/s]\n100%|██████████| 61/61 [00:00<00:00, 79260.39it/s]\n100%|██████████| 60/60 [00:00<00:00, 83220.32it/s]\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = np.array(x)\nY = np.array(Y)","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del a","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.utils import class_weight\nclass_weights = class_weight.compute_class_weight('balanced',np.unique(Y),Y)","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class_weights","execution_count":15,"outputs":[{"output_type":"execute_result","execution_count":15,"data":{"text/plain":"array([ 2.30037445,  2.287767  ,  2.30624026,  2.28487719,  2.3023264 ,\n        2.29259963,  2.29259963, 13.63463149,  2.28007703,  0.13222991,\n        2.28487719,  2.2829547 ])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for i in range(len(x)):\n#     pad_len = 16000 - x[i].shape[0]\n#     x[i] = np.pad(x[i],(0,pad_len),'constant')","execution_count":16,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = x.reshape(x.shape[0], 1, 16000) ","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"z  = [[1,2],[1,2]]\nz = np.array(z)","execution_count":18,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x.shape","execution_count":19,"outputs":[{"output_type":"execute_result","execution_count":19,"data":{"text/plain":"(65119, 1, 16000)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ndef get_train_test(split_ratio=0.6, random_state=42):\n    return train_test_split(x, Y, test_size= (1 - split_ratio), random_state=random_state, shuffle=True)","execution_count":20,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = get_train_test()","execution_count":21,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del x","execution_count":22,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import matplotlib.pyplot as plt\n# plt.figure(figsize=(10, 4))\n# librosa.display.specshow(X_train[3], x_axis='time')\n# plt.colorbar()\n# plt.title('MFCC')\n# plt.tight_layout()","execution_count":23,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.utils.np_utils import to_categorical","execution_count":24,"outputs":[{"output_type":"stream","text":"Using TensorFlow backend.\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"del Y","execution_count":25,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nlabelencoder = LabelEncoder()","execution_count":26,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labelencoder.fit_transform(y_test)","execution_count":27,"outputs":[{"output_type":"execute_result","execution_count":27,"data":{"text/plain":"array([ 4,  9,  0, ...,  9,  9, 11])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"mapping = dict(zip(labelencoder.classes_, range(len(labelencoder.classes_))))","execution_count":28,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mapping","execution_count":29,"outputs":[{"output_type":"execute_result","execution_count":29,"data":{"text/plain":"{'down': 0,\n 'go': 1,\n 'left': 2,\n 'no': 3,\n 'off': 4,\n 'on': 5,\n 'right': 6,\n 'silence': 7,\n 'stop': 8,\n 'unknown': 9,\n 'up': 10,\n 'yes': 11}"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test = labelencoder.fit_transform(y_test)\nmapping = dict(zip(labelencoder.classes_, range(len(labelencoder.classes_))))","execution_count":30,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mapping","execution_count":31,"outputs":[{"output_type":"execute_result","execution_count":31,"data":{"text/plain":"{'down': 0,\n 'go': 1,\n 'left': 2,\n 'no': 3,\n 'off': 4,\n 'on': 5,\n 'right': 6,\n 'silence': 7,\n 'stop': 8,\n 'unknown': 9,\n 'up': 10,\n 'yes': 11}"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test","execution_count":32,"outputs":[{"output_type":"execute_result","execution_count":32,"data":{"text/plain":"array([ 4,  9,  0, ...,  9,  9, 11])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = labelencoder.fit_transform(y_train)\nmapping = dict(zip(labelencoder.classes_, range(len(labelencoder.classes_))))","execution_count":33,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install kapre","execution_count":34,"outputs":[{"output_type":"stream","text":"Collecting kapre\n  Downloading https://files.pythonhosted.org/packages/3f/2e/f540d1d1f05c764686163fdb5bb1e5c703f1528076d2829bfc3900683f06/kapre-0.1.4-py3-none-any.whl\nRequirement already satisfied: keras>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from kapre) (2.2.4)\nRequirement already satisfied: future in /opt/conda/lib/python3.6/site-packages (from kapre) (0.17.1)\nRequirement already satisfied: numpy>=1.8.0 in /opt/conda/lib/python3.6/site-packages (from kapre) (1.16.3)\nRequirement already satisfied: librosa>=0.5 in /opt/conda/lib/python3.6/site-packages (from kapre) (0.6.3)\nRequirement already satisfied: keras-applications>=1.0.6 in /opt/conda/lib/python3.6/site-packages (from keras>=2.0.0->kapre) (1.0.7)\nRequirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.6/site-packages (from keras>=2.0.0->kapre) (1.0.9)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.6/site-packages (from keras>=2.0.0->kapre) (3.12)\nRequirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.6/site-packages (from keras>=2.0.0->kapre) (1.12.0)\nRequirement already satisfied: scipy>=0.14 in /opt/conda/lib/python3.6/site-packages (from keras>=2.0.0->kapre) (1.1.0)\nRequirement already satisfied: h5py in /opt/conda/lib/python3.6/site-packages (from keras>=2.0.0->kapre) (2.9.0)\nRequirement already satisfied: numba>=0.38.0 in /opt/conda/lib/python3.6/site-packages (from librosa>=0.5->kapre) (0.38.0)\nRequirement already satisfied: resampy>=0.2.0 in /opt/conda/lib/python3.6/site-packages (from librosa>=0.5->kapre) (0.2.1)\nRequirement already satisfied: decorator>=3.0.0 in /opt/conda/lib/python3.6/site-packages (from librosa>=0.5->kapre) (4.3.0)\nRequirement already satisfied: audioread>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from librosa>=0.5->kapre) (2.1.6)\nRequirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /opt/conda/lib/python3.6/site-packages (from librosa>=0.5->kapre) (0.20.3)\nRequirement already satisfied: joblib>=0.12 in /opt/conda/lib/python3.6/site-packages (from librosa>=0.5->kapre) (0.13.2)\nRequirement already satisfied: llvmlite>=0.23.0dev0 in /opt/conda/lib/python3.6/site-packages (from numba>=0.38.0->librosa>=0.5->kapre) (0.23.1)\nInstalling collected packages: kapre\nSuccessfully installed kapre-0.1.4\n\u001b[33mYou are using pip version 19.0.3, however version 19.1.1 is available.\nYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D","execution_count":35,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\nimport kapre\nfrom keras.models import Sequential\nfrom keras.layers import Dense,AveragePooling2D,BatchNormalization,SeparableConv2D\nfrom kapre.time_frequency import Melspectrogram\nfrom kapre.utils import Normalization2D\nfrom kapre.augmentation import AdditiveNoise\n\n# 6 channels (!), maybe 1-sec audio signal, for an example.\ninput_shape = (1,16000)\nsr = 16000\nmodel = Sequential()\n# A mel-spectrogram layer\nmodel.add(Melspectrogram(n_dft=512, n_hop=512, input_shape=input_shape,\n                         padding='same', sr=sr, n_mels=128,\n                         fmin=0.0, fmax=sr/2, power_melgram=1.0,\n                         return_decibel_melgram=True,trainable_fb=False,\n                         trainable_kernel=False,\n                         name='trainable_stft'))\n# Maybe some additive white noise.\nmodel.add(AdditiveNoise(power=0.1))\n# If you wanna normalise it per-frequency\nmodel.add(Normalization2D(str_axis='freq')) # or 'channel', 'time', 'batch', 'data_sample'\n# After this, it's just a usual keras workflow. For example..\n# Add some layers, e.g., model.add(some convolution layers..)\n# Compile the model\n\nmodel.add(Conv2D(64, kernel_size=(20, 8), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2),dim_ordering=\"th\"))\nmodel.add(Dropout(0.25))\nmodel.add(Conv2D(64, kernel_size=(10, 4), activation='relu',dim_ordering=\"th\"))\nmodel.add(MaxPooling2D(pool_size=(2, 2),dim_ordering=\"th\"))\nmodel.add(Dropout(0.25))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(12, activation='softmax'))\nmodel.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=keras.optimizers.adam(),metrics=['accuracy'])\nmodel.summary() ","execution_count":50,"outputs":[{"output_type":"stream","text":"_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ntrainable_stft (Melspectrogr (None, 128, 32, 1)        296064    \n_________________________________________________________________\nadditive_noise_3 (AdditiveNo (None, 128, 32, 1)        0         \n_________________________________________________________________\nnormalization2d_3 (Normaliza (None, 128, 32, 1)        0         \n_________________________________________________________________\nconv2d_7 (Conv2D)            (None, 109, 25, 64)       10304     \n_________________________________________________________________\nmax_pooling2d_3 (MaxPooling2 (None, 109, 12, 32)       0         \n_________________________________________________________________\ndropout_3 (Dropout)          (None, 109, 12, 32)       0         \n_________________________________________________________________\nconv2d_8 (Conv2D)            (None, 64, 3, 29)         279104    \n_________________________________________________________________\nmax_pooling2d_4 (MaxPooling2 (None, 64, 1, 14)         0         \n_________________________________________________________________\ndropout_4 (Dropout)          (None, 64, 1, 14)         0         \n_________________________________________________________________\nflatten_3 (Flatten)          (None, 896)               0         \n_________________________________________________________________\ndense_3 (Dense)              (None, 128)               114816    \n_________________________________________________________________\ndropout_5 (Dropout)          (None, 128)               0         \n_________________________________________________________________\ndense_4 (Dense)              (None, 12)                1548      \n=================================================================\nTotal params: 701,836\nTrainable params: 405,772\nNon-trainable params: 296,064\n_________________________________________________________________\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:29: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\")`\n/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:31: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, kernel_size=(10, 4), activation=\"relu\", data_format=\"channels_first\")`\n/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:32: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\")`\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.utils import to_categorical\ny_test = to_categorical(y_test)\ny_train = to_categorical(y_train)","execution_count":37,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# X_train.reshape(-1,13062,16000).shape","execution_count":38,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# X_test = X_test.reshape(X_test.shape[0], 20, 32, 1)","execution_count":39,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# a = X_train[0].reshape(1,16000)","execution_count":40,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model.predict(np.array([a]))","execution_count":41,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.optimizers import Optimizer\nfrom keras import backend as K\nimport six\nimport copy\nfrom six.moves import zip\nfrom keras.utils.generic_utils import serialize_keras_object\nfrom keras.utils.generic_utils import deserialize_keras_object\nfrom keras.legacy import interfaces\nclass AdamW(Optimizer):\n    \"\"\"Adam optimizer.\n    Default parameters follow those provided in the original paper.\n    # Arguments\n        lr: float >= 0. Learning rate.\n        beta_1: float, 0 < beta < 1. Generally close to 1.\n        beta_2: float, 0 < beta < 1. Generally close to 1.\n        epsilon: float >= 0. Fuzz factor.\n        decay: float >= 0. Learning rate decay over each update.\n        weight_decay: float >= 0. Decoupled weight decay over each update.\n    # References\n        - [Adam - A Method for Stochastic Optimization](http://arxiv.org/abs/1412.6980v8)\n        - [Optimization for Deep Learning Highlights in 2017](http://ruder.io/deep-learning-optimization-2017/index.html)\n        - [Fixing Weight Decay Regularization in Adam](https://arxiv.org/abs/1711.05101)\n    \"\"\"\n\n    def __init__(self, lr=0.001, beta_1=0.9, beta_2=0.999, weight_decay=1e-4,  # decoupled weight decay (1/6)\n                 epsilon=1e-8, decay=0., **kwargs):\n        super(AdamW, self).__init__(**kwargs)\n        with K.name_scope(self.__class__.__name__):\n            self.iterations = K.variable(0, dtype='int64', name='iterations')\n            self.lr = K.variable(lr, name='lr')\n            self.init_lr = lr # decoupled weight decay (2/6)\n            self.beta_1 = K.variable(beta_1, name='beta_1')\n            self.beta_2 = K.variable(beta_2, name='beta_2')\n            self.decay = K.variable(decay, name='decay')\n            self.wd = K.variable(weight_decay, name='weight_decay') # decoupled weight decay (3/6)\n        self.epsilon = epsilon\n        self.initial_decay = decay\n\n    @interfaces.legacy_get_updates_support\n    def get_updates(self, loss, params):\n        grads = self.get_gradients(loss, params)\n        self.updates = [K.update_add(self.iterations, 1)]\n        wd = self.wd # decoupled weight decay (4/6)\n\n        lr = self.lr\n        if self.initial_decay > 0:\n            lr *= (1. / (1. + self.decay * K.cast(self.iterations,\n                                                  K.dtype(self.decay))))\n        eta_t = lr / self.init_lr # decoupled weight decay (5/6)\n\n        t = K.cast(self.iterations, K.floatx()) + 1\n        lr_t = lr * (K.sqrt(1. - K.pow(self.beta_2, t)) /\n                     (1. - K.pow(self.beta_1, t)))\n\n        ms = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n        vs = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n        self.weights = [self.iterations] + ms + vs\n\n        for p, g, m, v in zip(params, grads, ms, vs):\n            m_t = (self.beta_1 * m) + (1. - self.beta_1) * g\n            v_t = (self.beta_2 * v) + (1. - self.beta_2) * K.square(g)\n            p_t = p - lr_t * m_t / (K.sqrt(v_t) + self.epsilon) - eta_t * wd * p # decoupled weight decay (6/6)\n\n            self.updates.append(K.update(m, m_t))\n            self.updates.append(K.update(v, v_t))\n            new_p = p_t\n\n            # Apply constraints.\n            if getattr(p, 'constraint', None) is not None:\n                new_p = p.constraint(new_p)\n\n            self.updates.append(K.update(p, new_p))\n        return self.updates\n\n    def get_config(self):\n        config = {'lr': float(K.get_value(self.lr)),\n                  'beta_1': float(K.get_value(self.beta_1)),\n                  'beta_2': float(K.get_value(self.beta_2)),\n                  'decay': float(K.get_value(self.decay)),\n                  'weight_decay': float(K.get_value(self.wd)),\n                  'epsilon': self.epsilon}\n        base_config = super(AdamW, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))","execution_count":42,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(X_train, y_train, batch_size=100, epochs=50, verbose=1, validation_data=(X_test, y_test),shuffle=True)","execution_count":51,"outputs":[{"output_type":"stream","text":"Train on 39071 samples, validate on 26048 samples\nEpoch 1/50\n39071/39071 [==============================] - 10s 244us/step - loss: 1.2288 - acc: 0.6509 - val_loss: 0.7423 - val_acc: 0.7592\nEpoch 2/50\n39071/39071 [==============================] - 8s 216us/step - loss: 0.7849 - acc: 0.7420 - val_loss: 0.5501 - val_acc: 0.8206\nEpoch 3/50\n39071/39071 [==============================] - 9s 218us/step - loss: 0.6434 - acc: 0.7880 - val_loss: 0.4809 - val_acc: 0.8454\nEpoch 4/50\n39071/39071 [==============================] - 9s 218us/step - loss: 0.5855 - acc: 0.8063 - val_loss: 0.4678 - val_acc: 0.8553\nEpoch 5/50\n39071/39071 [==============================] - 8s 217us/step - loss: 0.5404 - acc: 0.8221 - val_loss: 0.4368 - val_acc: 0.8604\nEpoch 6/50\n39071/39071 [==============================] - 8s 217us/step - loss: 0.5033 - acc: 0.8340 - val_loss: 0.4005 - val_acc: 0.8736\nEpoch 7/50\n39071/39071 [==============================] - 8s 217us/step - loss: 0.4855 - acc: 0.8402 - val_loss: 0.3736 - val_acc: 0.8819\nEpoch 8/50\n39071/39071 [==============================] - 8s 216us/step - loss: 0.4559 - acc: 0.8485 - val_loss: 0.3671 - val_acc: 0.8849\nEpoch 9/50\n39071/39071 [==============================] - 9s 218us/step - loss: 0.4490 - acc: 0.8523 - val_loss: 0.3680 - val_acc: 0.8824\nEpoch 10/50\n39071/39071 [==============================] - 8s 217us/step - loss: 0.4290 - acc: 0.8605 - val_loss: 0.3572 - val_acc: 0.8864\nEpoch 11/50\n39071/39071 [==============================] - 9s 218us/step - loss: 0.4128 - acc: 0.8640 - val_loss: 0.3486 - val_acc: 0.8893\nEpoch 12/50\n39071/39071 [==============================] - 8s 216us/step - loss: 0.4101 - acc: 0.8652 - val_loss: 0.3310 - val_acc: 0.8953\nEpoch 13/50\n39071/39071 [==============================] - 8s 217us/step - loss: 0.3974 - acc: 0.8688 - val_loss: 0.3281 - val_acc: 0.8962\nEpoch 14/50\n39071/39071 [==============================] - 9s 218us/step - loss: 0.3946 - acc: 0.8727 - val_loss: 0.3143 - val_acc: 0.9008\nEpoch 15/50\n39071/39071 [==============================] - 8s 216us/step - loss: 0.3756 - acc: 0.8757 - val_loss: 0.3136 - val_acc: 0.9016\nEpoch 16/50\n39071/39071 [==============================] - 8s 217us/step - loss: 0.3687 - acc: 0.8797 - val_loss: 0.3007 - val_acc: 0.9081\nEpoch 17/50\n39071/39071 [==============================] - 8s 217us/step - loss: 0.3686 - acc: 0.8790 - val_loss: 0.3008 - val_acc: 0.9036\nEpoch 18/50\n39071/39071 [==============================] - 9s 220us/step - loss: 0.3597 - acc: 0.8818 - val_loss: 0.2968 - val_acc: 0.9077\nEpoch 19/50\n39071/39071 [==============================] - 9s 218us/step - loss: 0.3482 - acc: 0.8855 - val_loss: 0.3035 - val_acc: 0.9069\nEpoch 20/50\n39071/39071 [==============================] - 8s 217us/step - loss: 0.3469 - acc: 0.8872 - val_loss: 0.3036 - val_acc: 0.9060\nEpoch 21/50\n39071/39071 [==============================] - 9s 219us/step - loss: 0.3524 - acc: 0.8839 - val_loss: 0.3002 - val_acc: 0.9057\nEpoch 22/50\n39071/39071 [==============================] - 8s 217us/step - loss: 0.3399 - acc: 0.8867 - val_loss: 0.2978 - val_acc: 0.9074\nEpoch 23/50\n39071/39071 [==============================] - 9s 222us/step - loss: 0.3282 - acc: 0.8911 - val_loss: 0.2884 - val_acc: 0.9092\nEpoch 24/50\n39071/39071 [==============================] - 9s 220us/step - loss: 0.3310 - acc: 0.8920 - val_loss: 0.2898 - val_acc: 0.9111\nEpoch 25/50\n39071/39071 [==============================] - 9s 220us/step - loss: 0.3125 - acc: 0.8978 - val_loss: 0.2874 - val_acc: 0.9105\nEpoch 26/50\n39071/39071 [==============================] - 8s 217us/step - loss: 0.3119 - acc: 0.8967 - val_loss: 0.2875 - val_acc: 0.9124\nEpoch 27/50\n39071/39071 [==============================] - 8s 217us/step - loss: 0.3032 - acc: 0.8987 - val_loss: 0.2786 - val_acc: 0.9145\nEpoch 28/50\n39071/39071 [==============================] - 9s 219us/step - loss: 0.3022 - acc: 0.9004 - val_loss: 0.3089 - val_acc: 0.9064\nEpoch 29/50\n39071/39071 [==============================] - 8s 217us/step - loss: 0.2961 - acc: 0.9043 - val_loss: 0.2712 - val_acc: 0.9159\nEpoch 30/50\n39071/39071 [==============================] - 8s 216us/step - loss: 0.2950 - acc: 0.9038 - val_loss: 0.2746 - val_acc: 0.9133\nEpoch 31/50\n39071/39071 [==============================] - 8s 217us/step - loss: 0.2867 - acc: 0.9046 - val_loss: 0.2935 - val_acc: 0.9102\nEpoch 32/50\n39071/39071 [==============================] - 9s 220us/step - loss: 0.2849 - acc: 0.9058 - val_loss: 0.2708 - val_acc: 0.9176\nEpoch 33/50\n39071/39071 [==============================] - 9s 218us/step - loss: 0.2743 - acc: 0.9082 - val_loss: 0.2951 - val_acc: 0.9093\nEpoch 34/50\n39071/39071 [==============================] - 8s 216us/step - loss: 0.2778 - acc: 0.9096 - val_loss: 0.2790 - val_acc: 0.9148\nEpoch 35/50\n39071/39071 [==============================] - 9s 219us/step - loss: 0.2651 - acc: 0.9118 - val_loss: 0.2650 - val_acc: 0.9191\nEpoch 36/50\n39071/39071 [==============================] - 9s 219us/step - loss: 0.2617 - acc: 0.9149 - val_loss: 0.2649 - val_acc: 0.9187\nEpoch 37/50\n39071/39071 [==============================] - 9s 218us/step - loss: 0.2565 - acc: 0.9167 - val_loss: 0.2848 - val_acc: 0.9140\nEpoch 38/50\n39071/39071 [==============================] - 9s 218us/step - loss: 0.2534 - acc: 0.9161 - val_loss: 0.2746 - val_acc: 0.9195\nEpoch 39/50\n39071/39071 [==============================] - 9s 219us/step - loss: 0.2490 - acc: 0.9188 - val_loss: 0.2753 - val_acc: 0.9177\nEpoch 40/50\n39071/39071 [==============================] - 8s 216us/step - loss: 0.2463 - acc: 0.9202 - val_loss: 0.2731 - val_acc: 0.9190\nEpoch 41/50\n39071/39071 [==============================] - 8s 217us/step - loss: 0.2503 - acc: 0.9161 - val_loss: 0.2786 - val_acc: 0.9206\nEpoch 42/50\n39071/39071 [==============================] - 8s 217us/step - loss: 0.2332 - acc: 0.9227 - val_loss: 0.2666 - val_acc: 0.9201\nEpoch 43/50\n39071/39071 [==============================] - 9s 218us/step - loss: 0.2403 - acc: 0.9215 - val_loss: 0.2624 - val_acc: 0.9235\nEpoch 44/50\n39071/39071 [==============================] - 8s 217us/step - loss: 0.2382 - acc: 0.9222 - val_loss: 0.2547 - val_acc: 0.9240\nEpoch 45/50\n39071/39071 [==============================] - 8s 217us/step - loss: 0.2313 - acc: 0.9237 - val_loss: 0.2729 - val_acc: 0.9192\nEpoch 46/50\n39071/39071 [==============================] - 9s 219us/step - loss: 0.2372 - acc: 0.9237 - val_loss: 0.2649 - val_acc: 0.9221\nEpoch 47/50\n39071/39071 [==============================] - 9s 218us/step - loss: 0.2226 - acc: 0.9263 - val_loss: 0.2578 - val_acc: 0.9235\nEpoch 48/50\n39071/39071 [==============================] - 8s 217us/step - loss: 0.2187 - acc: 0.9290 - val_loss: 0.2811 - val_acc: 0.9169\nEpoch 49/50\n39071/39071 [==============================] - 9s 218us/step - loss: 0.2169 - acc: 0.9284 - val_loss: 0.2693 - val_acc: 0.9205\nEpoch 50/50\n39071/39071 [==============================] - 8s 217us/step - loss: 0.2111 - acc: 0.9301 - val_loss: 0.2657 - val_acc: 0.9234\n","name":"stdout"},{"output_type":"execute_result","execution_count":51,"data":{"text/plain":"<keras.callbacks.History at 0x7f48eb58c9e8>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(model.output.op.name)\nprint(model.input.op.name)","execution_count":52,"outputs":[{"output_type":"stream","text":"dense_4/Softmax\ntrainable_stft_input_2\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save_weights('cnn.h5',keras)","execution_count":53,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save(\"cnn-model.h5\")\nimport tensorflow as tf","execution_count":56,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from tensorflow.contrib import lite\n# converter = lite.TFLiteConverter.from_keras_model_file( 'yo.h5')\n# tfmodel = converter.convert()\n# converter.allow_custom_ops=True\n# open (\"model.tflite\" , \"wb\") .write(tfmodel)\n","execution_count":55,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}