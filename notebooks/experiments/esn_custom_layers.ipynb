{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train', 'sample_submission.csv']\n",
      "Default GPU Device: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "from os.path import isdir, join\n",
    "import librosa\n",
    "from tqdm import tqdm\n",
    "# Any results you write to the current directory are saved as output.\n",
    "import tensorflow as tf\n",
    "if tf.test.gpu_device_name():\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"Please install GPU version of TF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# os.listdir(\"../input/dataasdfasd/\")\n",
    "# audio_file_path = \"../input/dataasdfasd/output.wav\"\n",
    "# os.linesep()\n",
    "# samps,sr = librosa.load(audio_file_path, mono=True, sr=None)\n",
    "# mfcc = librosa.feature.mfcc(samps, sr = sr)z\n",
    "# pad_width = max_pad - mfcc.shape[1]\n",
    "# mfcc = np.pad(mfcc, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "audio_path = \"../input/train/audio/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all audio dirs\n",
    "dirs = [f for f in os.listdir(audio_path) if os.path.isdir(join(audio_path, f))]\n",
    "dirs.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# plt.figure(figsize=(10, 4))\n",
    "# librosa.display.specshow(mfcc, x_axis='time')\n",
    "# plt.colorbar()\n",
    "# plt.title('MFCC')\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa.display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# plt.figure(figsize=(10, 4))\n",
    "# librosa.display.specshow(mfcc, x_axis='time')\n",
    "# plt.colorbar()\n",
    "# plt.title('MFCC')\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "class AudioFeatureDataset():\n",
    "    def __init__(self,file_path):\n",
    "        self.file_path = file_path\n",
    "        self.labels = os.listdir(self.file_path)\n",
    "        self.target_labels = ['no', 'left', 'nine', 'two', 'yes', 'bed', 'stop', 'cat', 'dog', 'off']\n",
    "        self.data_dict = {}\n",
    "        for tl in self.target_labels:\n",
    "            files_dir = os.path.join(file_path,tl)\n",
    "            all_audio_fp_s =[ os.path.join(files_dir,f) for f in os.listdir(files_dir)]\n",
    "            self.data_dict[tl] = all_audio_fp_s\n",
    "    \n",
    "    def process(self,file,max_pad = 32):\n",
    "        samps,sr = librosa.load(file, mono=True, sr=None)\n",
    "#         mfcc = librosa.feature.mfcc(samps, sr = sr)\n",
    "#         pad_width = max_pad - mfcc.shape[1]\n",
    "#         mfcc = np.pad(mfcc, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "        pad_len = 16000 - samps.shape[0]\n",
    "        samps= np.pad(samps,(0,pad_len),'constant')\n",
    "        return np.array(samps)\n",
    "    def get_dataset(self):\n",
    "        labels =  []\n",
    "        features = []\n",
    "        for t in tqdm(self.target_labels):\n",
    "            for fp in self.data_dict[t]:\n",
    "                labels.append(t)\n",
    "                features.append(self.process(fp))\n",
    "        return labels, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = AudioFeatureDataset(audio_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:25<00:00,  2.50s/it]\n"
     ]
    }
   ],
   "source": [
    "Y,x = a.get_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(x)\n",
    "Y = np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(x)):\n",
    "    pad_len = 16000 - x[i].shape[0]\n",
    "    x[i] = np.pad(x[i],(0,pad_len),'constant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.reshape(21771, 1, 16000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "z  = [[1,2],[1,2]]\n",
    "z = np.array(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21771, 1, 16000)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def get_train_test(split_ratio=0.6, random_state=42):\n",
    "    return train_test_split(x, Y, test_size= (1 - split_ratio), random_state=random_state, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = get_train_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# plt.figure(figsize=(10, 4))\n",
    "# librosa.display.specshow(X_train[3], x_axis='time')\n",
    "# plt.colorbar()\n",
    "# plt.title('MFCC')\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 4, 8, ..., 3, 9, 5])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelencoder.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = dict(zip(labelencoder.classes_, range(len(labelencoder.classes_))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bed': 0,\n",
       " 'cat': 1,\n",
       " 'dog': 2,\n",
       " 'left': 3,\n",
       " 'nine': 4,\n",
       " 'no': 5,\n",
       " 'off': 6,\n",
       " 'stop': 7,\n",
       " 'two': 8,\n",
       " 'yes': 9}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = labelencoder.fit_transform(y_test)\n",
    "mapping = dict(zip(labelencoder.classes_, range(len(labelencoder.classes_))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bed': 0,\n",
       " 'cat': 1,\n",
       " 'dog': 2,\n",
       " 'left': 3,\n",
       " 'nine': 4,\n",
       " 'no': 5,\n",
       " 'off': 6,\n",
       " 'stop': 7,\n",
       " 'two': 8,\n",
       " 'yes': 9}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 4, 8, ..., 3, 9, 5])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = labelencoder.fit_transform(y_train)\n",
    "mapping = dict(zip(labelencoder.classes_, range(len(labelencoder.classes_))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kapre\r\n",
      "  Downloading https://files.pythonhosted.org/packages/3f/2e/f540d1d1f05c764686163fdb5bb1e5c703f1528076d2829bfc3900683f06/kapre-0.1.4-py3-none-any.whl\r\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.6/site-packages (from kapre) (0.17.1)\r\n",
      "Requirement already satisfied: librosa>=0.5 in /opt/conda/lib/python3.6/site-packages (from kapre) (0.6.3)\r\n",
      "Requirement already satisfied: keras>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from kapre) (2.2.4)\r\n",
      "Requirement already satisfied: numpy>=1.8.0 in /opt/conda/lib/python3.6/site-packages (from kapre) (1.16.3)\r\n",
      "Requirement already satisfied: six>=1.3 in /opt/conda/lib/python3.6/site-packages (from librosa>=0.5->kapre) (1.12.0)\r\n",
      "Requirement already satisfied: joblib>=0.12 in /opt/conda/lib/python3.6/site-packages (from librosa>=0.5->kapre) (0.13.2)\r\n",
      "Requirement already satisfied: audioread>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from librosa>=0.5->kapre) (2.1.6)\r\n",
      "Requirement already satisfied: resampy>=0.2.0 in /opt/conda/lib/python3.6/site-packages (from librosa>=0.5->kapre) (0.2.1)\r\n",
      "Requirement already satisfied: decorator>=3.0.0 in /opt/conda/lib/python3.6/site-packages (from librosa>=0.5->kapre) (4.3.0)\r\n",
      "Requirement already satisfied: numba>=0.38.0 in /opt/conda/lib/python3.6/site-packages (from librosa>=0.5->kapre) (0.38.0)\r\n",
      "Requirement already satisfied: scipy>=1.0.0 in /opt/conda/lib/python3.6/site-packages (from librosa>=0.5->kapre) (1.1.0)\r\n",
      "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /opt/conda/lib/python3.6/site-packages (from librosa>=0.5->kapre) (0.20.3)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.6/site-packages (from keras>=2.0.0->kapre) (3.12)\r\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.6/site-packages (from keras>=2.0.0->kapre) (2.9.0)\r\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.6/site-packages (from keras>=2.0.0->kapre) (1.0.9)\r\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /opt/conda/lib/python3.6/site-packages (from keras>=2.0.0->kapre) (1.0.7)\r\n",
      "Requirement already satisfied: llvmlite>=0.23.0dev0 in /opt/conda/lib/python3.6/site-packages (from numba>=0.38.0->librosa>=0.5->kapre) (0.23.1)\r\n",
      "Installing collected packages: kapre\r\n",
      "Successfully installed kapre-0.1.4\r\n",
      "\u001b[33mYou are using pip version 19.0.3, however version 19.1.1 is available.\r\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install kapre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:28: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(20, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:29: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(39, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:30: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(15, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:31: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(39, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:32: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(25, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:33: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(39, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:34: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(22, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:35: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(39, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:36: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(22, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:37: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(39, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:38: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(25, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:39: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(39, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:40: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(45, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "trainable_stft (Melspectrogr (None, 128, 32, 1)        296064    \n",
      "_________________________________________________________________\n",
      "additive_noise_1 (AdditiveNo (None, 128, 32, 1)        0         \n",
      "_________________________________________________________________\n",
      "normalization2d_1 (Normaliza (None, 128, 32, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 126, 30, 39)       390       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 20, 28, 37)        22700     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 39, 26, 35)        7059      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 15, 24, 33)        5280      \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 39, 22, 31)        5304      \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 25, 20, 29)        8800      \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 39, 18, 27)        8814      \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 22, 16, 25)        7744      \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 39, 14, 23)        7761      \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 22, 12, 21)        7744      \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 39, 10, 19)        7761      \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 25, 8, 17)         8800      \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 39, 6, 15)         8814      \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 45, 4, 13)         15840     \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average (None, 22, 2, 13)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 572)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12)                6876      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                130       \n",
      "=================================================================\n",
      "Total params: 425,881\n",
      "Trainable params: 129,817\n",
      "Non-trainable params: 296,064\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import kapre\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,AveragePooling2D\n",
    "from kapre.time_frequency import Melspectrogram\n",
    "from kapre.utils import Normalization2D\n",
    "from kapre.augmentation import AdditiveNoise\n",
    "\n",
    "# 6 channels (!), maybe 1-sec audio signal, for an example.\n",
    "input_shape = (1,16000)\n",
    "sr = 16000\n",
    "model = Sequential()\n",
    "# A mel-spectrogram layer\n",
    "model.add(Melspectrogram(n_dft=512, n_hop=512, input_shape=input_shape,\n",
    "                         padding='same', sr=sr, n_mels=128,\n",
    "                         fmin=0.0, fmax=sr/2, power_melgram=1.0,\n",
    "                         return_decibel_melgram=True,trainable_fb=False,\n",
    "                         trainable_kernel=False,\n",
    "                         name='trainable_stft'))\n",
    "# Maybe some additive white noise.\n",
    "model.add(AdditiveNoise(power=0.1))\n",
    "# If you wanna normalise it per-frequency\n",
    "model.add(Normalization2D(str_axis='freq')) # or 'channel', 'time', 'batch', 'data_sample'\n",
    "# After this, it's just a usual keras workflow. For example..\n",
    "# Add some layers, e.g., model.add(some convolution layers..)\n",
    "# Compile the model\n",
    "model.add(Conv2D(39, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(Conv2D(20, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\n",
    "model.add(Conv2D(39, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\n",
    "model.add(Conv2D(15, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\n",
    "model.add(Conv2D(39, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\n",
    "model.add(Conv2D(25, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\n",
    "model.add(Conv2D(39, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\n",
    "model.add(Conv2D(22, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\n",
    "model.add(Conv2D(39, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\n",
    "model.add(Conv2D(22, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\n",
    "model.add(Conv2D(39, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\n",
    "model.add(Conv2D(25, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\n",
    "model.add(Conv2D(39, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\n",
    "model.add(Conv2D(45, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\n",
    "\n",
    "model.add(AveragePooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(12))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.adam(),metrics=['accuracy'])\n",
    "model.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = to_categorical(y_test)\n",
    "y_train = to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train.reshape(-1,13062,16000).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# X_test = X_test.reshape(X_test.shape[0], 20, 32, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = X_train[0].reshape(1,16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.predict(np.array([a]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Optimizer\n",
    "from keras import backend as K\n",
    "import six\n",
    "import copy\n",
    "from six.moves import zip\n",
    "from keras.utils.generic_utils import serialize_keras_object\n",
    "from keras.utils.generic_utils import deserialize_keras_object\n",
    "from keras.legacy import interfaces\n",
    "class AdamW(Optimizer):\n",
    "    \"\"\"Adam optimizer.\n",
    "    Default parameters follow those provided in the original paper.\n",
    "    # Arguments\n",
    "        lr: float >= 0. Learning rate.\n",
    "        beta_1: float, 0 < beta < 1. Generally close to 1.\n",
    "        beta_2: float, 0 < beta < 1. Generally close to 1.\n",
    "        epsilon: float >= 0. Fuzz factor.\n",
    "        decay: float >= 0. Learning rate decay over each update.\n",
    "        weight_decay: float >= 0. Decoupled weight decay over each update.\n",
    "    # References\n",
    "        - [Adam - A Method for Stochastic Optimization](http://arxiv.org/abs/1412.6980v8)\n",
    "        - [Optimization for Deep Learning Highlights in 2017](http://ruder.io/deep-learning-optimization-2017/index.html)\n",
    "        - [Fixing Weight Decay Regularization in Adam](https://arxiv.org/abs/1711.05101)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, lr=0.001, beta_1=0.9, beta_2=0.999, weight_decay=1e-4,  # decoupled weight decay (1/6)\n",
    "                 epsilon=1e-8, decay=0., **kwargs):\n",
    "        super(AdamW, self).__init__(**kwargs)\n",
    "        with K.name_scope(self.__class__.__name__):\n",
    "            self.iterations = K.variable(0, dtype='int64', name='iterations')\n",
    "            self.lr = K.variable(lr, name='lr')\n",
    "            self.init_lr = lr # decoupled weight decay (2/6)\n",
    "            self.beta_1 = K.variable(beta_1, name='beta_1')\n",
    "            self.beta_2 = K.variable(beta_2, name='beta_2')\n",
    "            self.decay = K.variable(decay, name='decay')\n",
    "            self.wd = K.variable(weight_decay, name='weight_decay') # decoupled weight decay (3/6)\n",
    "        self.epsilon = epsilon\n",
    "        self.initial_decay = decay\n",
    "\n",
    "    @interfaces.legacy_get_updates_support\n",
    "    def get_updates(self, loss, params):\n",
    "        grads = self.get_gradients(loss, params)\n",
    "        self.updates = [K.update_add(self.iterations, 1)]\n",
    "        wd = self.wd # decoupled weight decay (4/6)\n",
    "\n",
    "        lr = self.lr\n",
    "        if self.initial_decay > 0:\n",
    "            lr *= (1. / (1. + self.decay * K.cast(self.iterations,\n",
    "                                                  K.dtype(self.decay))))\n",
    "        eta_t = lr / self.init_lr # decoupled weight decay (5/6)\n",
    "\n",
    "        t = K.cast(self.iterations, K.floatx()) + 1\n",
    "        lr_t = lr * (K.sqrt(1. - K.pow(self.beta_2, t)) /\n",
    "                     (1. - K.pow(self.beta_1, t)))\n",
    "\n",
    "        ms = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n",
    "        vs = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n",
    "        self.weights = [self.iterations] + ms + vs\n",
    "\n",
    "        for p, g, m, v in zip(params, grads, ms, vs):\n",
    "            m_t = (self.beta_1 * m) + (1. - self.beta_1) * g\n",
    "            v_t = (self.beta_2 * v) + (1. - self.beta_2) * K.square(g)\n",
    "            p_t = p - lr_t * m_t / (K.sqrt(v_t) + self.epsilon) - eta_t * wd * p # decoupled weight decay (6/6)\n",
    "\n",
    "            self.updates.append(K.update(m, m_t))\n",
    "            self.updates.append(K.update(v, v_t))\n",
    "            new_p = p_t\n",
    "\n",
    "            # Apply constraints.\n",
    "            if getattr(p, 'constraint', None) is not None:\n",
    "                new_p = p.constraint(new_p)\n",
    "\n",
    "            self.updates.append(K.update(p, new_p))\n",
    "        return self.updates\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'lr': float(K.get_value(self.lr)),\n",
    "                  'beta_1': float(K.get_value(self.beta_1)),\n",
    "                  'beta_2': float(K.get_value(self.beta_2)),\n",
    "                  'decay': float(K.get_value(self.decay)),\n",
    "                  'weight_decay': float(K.get_value(self.wd)),\n",
    "                  'epsilon': self.epsilon}\n",
    "        base_config = super(AdamW, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Conv2D(64, kernel_size=(20, 8), activation='relu', input_shape=(20, 32, 1)))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2),dim_ordering=\"th\"))\n",
    "# model.add(Dropout(0.25))\n",
    "# model.add(Conv2D(64, kernel_size=(10, 4), activation='relu',dim_ordering=\"th\"))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2),dim_ordering=\"th\"))\n",
    "# model.add(Dropout(0.25))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(128, activation='relu'))\n",
    "# model.add(Dropout(0.25))\n",
    "# model.add(Dense(10, activation='softmax'))\n",
    "# model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "#               optimizer=keras.optimizers.adam(),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 12062 samples, validate on 8709 samples\n",
      "Epoch 1/100\n",
      "12062/12062 [==============================] - 7s 546us/step - loss: 2.1498 - acc: 0.1954 - val_loss: 1.5195 - val_acc: 0.4351\n",
      "Epoch 2/100\n",
      "12062/12062 [==============================] - 4s 307us/step - loss: 1.0175 - acc: 0.6448 - val_loss: 0.7041 - val_acc: 0.7637\n",
      "Epoch 3/100\n",
      "12062/12062 [==============================] - 4s 309us/step - loss: 0.6509 - acc: 0.7861 - val_loss: 0.5293 - val_acc: 0.8266\n",
      "Epoch 4/100\n",
      "12062/12062 [==============================] - 4s 308us/step - loss: 0.4397 - acc: 0.8612 - val_loss: 0.4016 - val_acc: 0.8745\n",
      "Epoch 5/100\n",
      "12062/12062 [==============================] - 4s 310us/step - loss: 0.3301 - acc: 0.8983 - val_loss: 0.3361 - val_acc: 0.8916\n",
      "Epoch 6/100\n",
      "12062/12062 [==============================] - 4s 310us/step - loss: 0.2717 - acc: 0.9166 - val_loss: 0.2754 - val_acc: 0.9119\n",
      "Epoch 7/100\n",
      "12062/12062 [==============================] - 4s 308us/step - loss: 0.2460 - acc: 0.9208 - val_loss: 0.2708 - val_acc: 0.9171\n",
      "Epoch 8/100\n",
      "12062/12062 [==============================] - 4s 309us/step - loss: 0.2046 - acc: 0.9345 - val_loss: 0.2795 - val_acc: 0.9132\n",
      "Epoch 9/100\n",
      "12062/12062 [==============================] - 4s 308us/step - loss: 0.1827 - acc: 0.9414 - val_loss: 0.2603 - val_acc: 0.9193\n",
      "Epoch 10/100\n",
      "12062/12062 [==============================] - 4s 314us/step - loss: 0.1712 - acc: 0.9440 - val_loss: 0.2390 - val_acc: 0.9278\n",
      "Epoch 11/100\n",
      "12062/12062 [==============================] - 4s 315us/step - loss: 0.1556 - acc: 0.9500 - val_loss: 0.2206 - val_acc: 0.9371\n",
      "Epoch 12/100\n",
      "12062/12062 [==============================] - 4s 306us/step - loss: 0.1353 - acc: 0.9537 - val_loss: 0.2172 - val_acc: 0.9326\n",
      "Epoch 13/100\n",
      "12062/12062 [==============================] - 4s 309us/step - loss: 0.1359 - acc: 0.9537 - val_loss: 0.2132 - val_acc: 0.9356\n",
      "Epoch 14/100\n",
      "12062/12062 [==============================] - 4s 307us/step - loss: 0.1196 - acc: 0.9607 - val_loss: 0.2545 - val_acc: 0.9313\n",
      "Epoch 15/100\n",
      "12062/12062 [==============================] - 4s 308us/step - loss: 0.1280 - acc: 0.9561 - val_loss: 0.2902 - val_acc: 0.9186\n",
      "Epoch 16/100\n",
      "12062/12062 [==============================] - 4s 307us/step - loss: 0.1211 - acc: 0.9594 - val_loss: 0.2390 - val_acc: 0.9332\n",
      "Epoch 17/100\n",
      "12062/12062 [==============================] - 4s 308us/step - loss: 0.1048 - acc: 0.9641 - val_loss: 0.2322 - val_acc: 0.9355\n",
      "Epoch 18/100\n",
      "12062/12062 [==============================] - 4s 306us/step - loss: 0.0875 - acc: 0.9711 - val_loss: 0.2113 - val_acc: 0.9404\n",
      "Epoch 19/100\n",
      "12062/12062 [==============================] - 4s 308us/step - loss: 0.0961 - acc: 0.9684 - val_loss: 0.2162 - val_acc: 0.9419\n",
      "Epoch 20/100\n",
      "12062/12062 [==============================] - 4s 309us/step - loss: 0.0803 - acc: 0.9731 - val_loss: 0.2832 - val_acc: 0.9300\n",
      "Epoch 21/100\n",
      "12062/12062 [==============================] - 4s 316us/step - loss: 0.0959 - acc: 0.9671 - val_loss: 0.2261 - val_acc: 0.9389\n",
      "Epoch 22/100\n",
      "12062/12062 [==============================] - 4s 316us/step - loss: 0.0831 - acc: 0.9716 - val_loss: 0.2268 - val_acc: 0.9360\n",
      "Epoch 23/100\n",
      "12062/12062 [==============================] - 4s 310us/step - loss: 0.0819 - acc: 0.9714 - val_loss: 0.2051 - val_acc: 0.9447\n",
      "Epoch 24/100\n",
      "12062/12062 [==============================] - 4s 306us/step - loss: 0.0698 - acc: 0.9756 - val_loss: 0.2820 - val_acc: 0.9377\n",
      "Epoch 25/100\n",
      "12062/12062 [==============================] - 4s 307us/step - loss: 0.0678 - acc: 0.9776 - val_loss: 0.2570 - val_acc: 0.9394\n",
      "Epoch 26/100\n",
      "12062/12062 [==============================] - 4s 305us/step - loss: 0.0667 - acc: 0.9767 - val_loss: 0.2197 - val_acc: 0.9433\n",
      "Epoch 27/100\n",
      "12062/12062 [==============================] - 4s 303us/step - loss: 0.0704 - acc: 0.9759 - val_loss: 0.2501 - val_acc: 0.9329\n",
      "Epoch 28/100\n",
      "12062/12062 [==============================] - 4s 305us/step - loss: 0.0615 - acc: 0.9799 - val_loss: 0.2277 - val_acc: 0.9432\n",
      "Epoch 29/100\n",
      "12062/12062 [==============================] - 4s 311us/step - loss: 0.0753 - acc: 0.9746 - val_loss: 0.2175 - val_acc: 0.9458\n",
      "Epoch 30/100\n",
      "12062/12062 [==============================] - 4s 304us/step - loss: 0.0547 - acc: 0.9812 - val_loss: 0.2553 - val_acc: 0.9449\n",
      "Epoch 31/100\n",
      "12062/12062 [==============================] - 4s 303us/step - loss: 0.0497 - acc: 0.9826 - val_loss: 0.2711 - val_acc: 0.9478\n",
      "Epoch 32/100\n",
      "12062/12062 [==============================] - 4s 302us/step - loss: 0.0650 - acc: 0.9778 - val_loss: 0.2555 - val_acc: 0.9382\n",
      "Epoch 33/100\n",
      "12062/12062 [==============================] - 4s 305us/step - loss: 0.0625 - acc: 0.9780 - val_loss: 0.3041 - val_acc: 0.9419\n",
      "Epoch 34/100\n",
      "12062/12062 [==============================] - 4s 301us/step - loss: 0.0523 - acc: 0.9818 - val_loss: 0.3466 - val_acc: 0.9355\n",
      "Epoch 35/100\n",
      "12062/12062 [==============================] - 4s 300us/step - loss: 0.0551 - acc: 0.9813 - val_loss: 0.2517 - val_acc: 0.9456\n",
      "Epoch 36/100\n",
      "12062/12062 [==============================] - 4s 307us/step - loss: 0.0490 - acc: 0.9837 - val_loss: 0.2630 - val_acc: 0.9459\n",
      "Epoch 37/100\n",
      "12062/12062 [==============================] - 4s 306us/step - loss: 0.0391 - acc: 0.9876 - val_loss: 0.2492 - val_acc: 0.9497\n",
      "Epoch 38/100\n",
      "12062/12062 [==============================] - 4s 306us/step - loss: 0.0571 - acc: 0.9806 - val_loss: 0.2621 - val_acc: 0.9435\n",
      "Epoch 39/100\n",
      "12062/12062 [==============================] - 4s 305us/step - loss: 0.0515 - acc: 0.9836 - val_loss: 0.2527 - val_acc: 0.9411\n",
      "Epoch 40/100\n",
      "12062/12062 [==============================] - 4s 306us/step - loss: 0.0504 - acc: 0.9824 - val_loss: 0.2335 - val_acc: 0.9483\n",
      "Epoch 41/100\n",
      "12062/12062 [==============================] - 4s 309us/step - loss: 0.0435 - acc: 0.9854 - val_loss: 0.2556 - val_acc: 0.9473\n",
      "Epoch 42/100\n",
      "12062/12062 [==============================] - 4s 307us/step - loss: 0.0432 - acc: 0.9856 - val_loss: 0.2768 - val_acc: 0.9503\n",
      "Epoch 43/100\n",
      "12062/12062 [==============================] - 4s 304us/step - loss: 0.0508 - acc: 0.9833 - val_loss: 0.2945 - val_acc: 0.9420\n",
      "Epoch 44/100\n",
      "12062/12062 [==============================] - 4s 306us/step - loss: 0.0506 - acc: 0.9840 - val_loss: 0.2400 - val_acc: 0.9464\n",
      "Epoch 45/100\n",
      "12062/12062 [==============================] - 4s 303us/step - loss: 0.0455 - acc: 0.9855 - val_loss: 0.2701 - val_acc: 0.9466\n",
      "Epoch 46/100\n",
      "12062/12062 [==============================] - 4s 306us/step - loss: 0.0385 - acc: 0.9865 - val_loss: 0.2777 - val_acc: 0.9428\n",
      "Epoch 47/100\n",
      "12062/12062 [==============================] - 4s 309us/step - loss: 0.0449 - acc: 0.9852 - val_loss: 0.2339 - val_acc: 0.9443\n",
      "Epoch 48/100\n",
      "12062/12062 [==============================] - 4s 305us/step - loss: 0.0399 - acc: 0.9867 - val_loss: 0.2865 - val_acc: 0.9398\n",
      "Epoch 49/100\n",
      "12062/12062 [==============================] - 4s 307us/step - loss: 0.0404 - acc: 0.9857 - val_loss: 0.2484 - val_acc: 0.9436\n",
      "Epoch 50/100\n",
      "12062/12062 [==============================] - 4s 306us/step - loss: 0.0437 - acc: 0.9851 - val_loss: 0.2922 - val_acc: 0.9468\n",
      "Epoch 51/100\n",
      "12062/12062 [==============================] - 4s 302us/step - loss: 0.0327 - acc: 0.9887 - val_loss: 0.2688 - val_acc: 0.9439\n",
      "Epoch 52/100\n",
      "12062/12062 [==============================] - 4s 308us/step - loss: 0.0367 - acc: 0.9880 - val_loss: 0.2715 - val_acc: 0.9457\n",
      "Epoch 53/100\n",
      "12062/12062 [==============================] - 4s 303us/step - loss: 0.0393 - acc: 0.9875 - val_loss: 0.2711 - val_acc: 0.9449\n",
      "Epoch 54/100\n",
      "12062/12062 [==============================] - 4s 305us/step - loss: 0.0405 - acc: 0.9867 - val_loss: 0.3192 - val_acc: 0.9494\n",
      "Epoch 55/100\n",
      "12062/12062 [==============================] - 4s 304us/step - loss: 0.0393 - acc: 0.9873 - val_loss: 0.2546 - val_acc: 0.9498\n",
      "Epoch 56/100\n",
      "12062/12062 [==============================] - 4s 303us/step - loss: 0.0267 - acc: 0.9915 - val_loss: 0.3067 - val_acc: 0.9471\n",
      "Epoch 57/100\n",
      "12062/12062 [==============================] - 4s 303us/step - loss: 0.0462 - acc: 0.9840 - val_loss: 0.2812 - val_acc: 0.9483\n",
      "Epoch 58/100\n",
      "12062/12062 [==============================] - 4s 302us/step - loss: 0.0349 - acc: 0.9884 - val_loss: 0.2504 - val_acc: 0.9452\n",
      "Epoch 59/100\n",
      "12062/12062 [==============================] - 4s 303us/step - loss: 0.0293 - acc: 0.9901 - val_loss: 0.3660 - val_acc: 0.9380\n",
      "Epoch 60/100\n",
      "12062/12062 [==============================] - 4s 303us/step - loss: 0.0423 - acc: 0.9850 - val_loss: 0.2534 - val_acc: 0.9497\n",
      "Epoch 61/100\n",
      "12062/12062 [==============================] - 4s 303us/step - loss: 0.0365 - acc: 0.9873 - val_loss: 0.2394 - val_acc: 0.9417\n",
      "Epoch 62/100\n",
      "12062/12062 [==============================] - 4s 303us/step - loss: 0.0294 - acc: 0.9898 - val_loss: 0.3163 - val_acc: 0.9488\n",
      "Epoch 63/100\n",
      "12062/12062 [==============================] - 4s 305us/step - loss: 0.0403 - acc: 0.9876 - val_loss: 0.2515 - val_acc: 0.9455\n",
      "Epoch 64/100\n",
      "12062/12062 [==============================] - 4s 306us/step - loss: 0.0368 - acc: 0.9889 - val_loss: 0.2209 - val_acc: 0.9470\n",
      "Epoch 65/100\n",
      "12062/12062 [==============================] - 4s 303us/step - loss: 0.0213 - acc: 0.9931 - val_loss: 0.3063 - val_acc: 0.9502\n",
      "Epoch 66/100\n",
      "12062/12062 [==============================] - 4s 304us/step - loss: 0.0381 - acc: 0.9876 - val_loss: 0.2724 - val_acc: 0.9513\n",
      "Epoch 67/100\n",
      "12062/12062 [==============================] - 4s 301us/step - loss: 0.0302 - acc: 0.9910 - val_loss: 0.2892 - val_acc: 0.9425\n",
      "Epoch 68/100\n",
      "12062/12062 [==============================] - 4s 306us/step - loss: 0.0269 - acc: 0.9911 - val_loss: 0.3201 - val_acc: 0.9491\n",
      "Epoch 69/100\n",
      "12062/12062 [==============================] - 4s 302us/step - loss: 0.0349 - acc: 0.9883 - val_loss: 0.2594 - val_acc: 0.9479\n",
      "Epoch 70/100\n",
      "12062/12062 [==============================] - 4s 306us/step - loss: 0.0274 - acc: 0.9909 - val_loss: 0.2868 - val_acc: 0.9483\n",
      "Epoch 71/100\n",
      "12062/12062 [==============================] - 4s 307us/step - loss: 0.0323 - acc: 0.9891 - val_loss: 0.2359 - val_acc: 0.9507\n",
      "Epoch 72/100\n",
      "12062/12062 [==============================] - 4s 306us/step - loss: 0.0186 - acc: 0.9940 - val_loss: 0.2797 - val_acc: 0.9476\n",
      "Epoch 73/100\n",
      "12062/12062 [==============================] - 4s 304us/step - loss: 0.0273 - acc: 0.9911 - val_loss: 0.2980 - val_acc: 0.9453\n",
      "Epoch 74/100\n",
      "12062/12062 [==============================] - 4s 306us/step - loss: 0.0256 - acc: 0.9915 - val_loss: 0.2846 - val_acc: 0.9447\n",
      "Epoch 75/100\n",
      "12062/12062 [==============================] - 4s 305us/step - loss: 0.0299 - acc: 0.9910 - val_loss: 0.3020 - val_acc: 0.9491\n",
      "Epoch 76/100\n",
      "12062/12062 [==============================] - 4s 305us/step - loss: 0.0333 - acc: 0.9894 - val_loss: 0.3168 - val_acc: 0.9409\n",
      "Epoch 77/100\n",
      "12062/12062 [==============================] - 4s 303us/step - loss: 0.0353 - acc: 0.9886 - val_loss: 0.2943 - val_acc: 0.9498\n",
      "Epoch 78/100\n",
      "12062/12062 [==============================] - 4s 304us/step - loss: 0.0250 - acc: 0.9921 - val_loss: 0.2868 - val_acc: 0.9466\n",
      "Epoch 79/100\n",
      "12062/12062 [==============================] - 4s 305us/step - loss: 0.0298 - acc: 0.9910 - val_loss: 0.2905 - val_acc: 0.9496\n",
      "Epoch 80/100\n",
      "12062/12062 [==============================] - 4s 303us/step - loss: 0.0226 - acc: 0.9931 - val_loss: 0.3230 - val_acc: 0.9517\n",
      "Epoch 81/100\n",
      "12062/12062 [==============================] - 4s 304us/step - loss: 0.0268 - acc: 0.9915 - val_loss: 0.3239 - val_acc: 0.9465\n",
      "Epoch 82/100\n",
      "12062/12062 [==============================] - 4s 308us/step - loss: 0.0278 - acc: 0.9916 - val_loss: 0.3036 - val_acc: 0.9482\n",
      "Epoch 83/100\n",
      "12062/12062 [==============================] - 4s 304us/step - loss: 0.0339 - acc: 0.9895 - val_loss: 0.2534 - val_acc: 0.9429\n",
      "Epoch 84/100\n",
      "12062/12062 [==============================] - 4s 305us/step - loss: 0.0185 - acc: 0.9941 - val_loss: 0.2922 - val_acc: 0.9476\n",
      "Epoch 85/100\n",
      "12062/12062 [==============================] - 4s 306us/step - loss: 0.0259 - acc: 0.9920 - val_loss: 0.2820 - val_acc: 0.9499\n",
      "Epoch 86/100\n",
      "12062/12062 [==============================] - 4s 304us/step - loss: 0.0267 - acc: 0.9916 - val_loss: 0.2813 - val_acc: 0.9512\n",
      "Epoch 87/100\n",
      "12062/12062 [==============================] - 4s 307us/step - loss: 0.0251 - acc: 0.9905 - val_loss: 0.2753 - val_acc: 0.9430\n",
      "Epoch 88/100\n",
      "12062/12062 [==============================] - 4s 306us/step - loss: 0.0343 - acc: 0.9892 - val_loss: 0.2578 - val_acc: 0.9451\n",
      "Epoch 89/100\n",
      "12062/12062 [==============================] - 4s 306us/step - loss: 0.0196 - acc: 0.9946 - val_loss: 0.3085 - val_acc: 0.9521\n",
      "Epoch 90/100\n",
      "12062/12062 [==============================] - 4s 305us/step - loss: 0.0224 - acc: 0.9932 - val_loss: 0.3013 - val_acc: 0.9441\n",
      "Epoch 91/100\n",
      "12062/12062 [==============================] - 4s 306us/step - loss: 0.0235 - acc: 0.9922 - val_loss: 0.2860 - val_acc: 0.9510\n",
      "Epoch 92/100\n",
      "12062/12062 [==============================] - 4s 313us/step - loss: 0.0262 - acc: 0.9917 - val_loss: 0.3089 - val_acc: 0.9474\n",
      "Epoch 93/100\n",
      "12062/12062 [==============================] - 4s 309us/step - loss: 0.0141 - acc: 0.9957 - val_loss: 0.2829 - val_acc: 0.9517\n",
      "Epoch 94/100\n",
      "12062/12062 [==============================] - 4s 306us/step - loss: 0.0175 - acc: 0.9944 - val_loss: 0.2725 - val_acc: 0.9458\n",
      "Epoch 95/100\n",
      "12062/12062 [==============================] - 4s 303us/step - loss: 0.0265 - acc: 0.9920 - val_loss: 0.3029 - val_acc: 0.9334\n",
      "Epoch 96/100\n",
      "12062/12062 [==============================] - 4s 304us/step - loss: 0.0221 - acc: 0.9927 - val_loss: 0.2972 - val_acc: 0.9466\n",
      "Epoch 97/100\n",
      "12062/12062 [==============================] - 4s 305us/step - loss: 0.0185 - acc: 0.9948 - val_loss: 0.2976 - val_acc: 0.9519\n",
      "Epoch 98/100\n",
      "12062/12062 [==============================] - 4s 306us/step - loss: 0.0191 - acc: 0.9939 - val_loss: 0.3327 - val_acc: 0.9447\n",
      "Epoch 99/100\n",
      "12062/12062 [==============================] - 4s 303us/step - loss: 0.0221 - acc: 0.9935 - val_loss: 0.2835 - val_acc: 0.9488\n",
      "Epoch 100/100\n",
      "12062/12062 [==============================] - 4s 305us/step - loss: 0.0196 - acc: 0.9939 - val_loss: 0.2894 - val_acc: 0.9479\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4e803b0860>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train[1000:], y_train[1000:], batch_size=100, epochs=100, verbose=1, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense_2/Softmax\n",
      "trainable_stft_input\n"
     ]
    }
   ],
   "source": [
    "print(model.output.op.name)\n",
    "print(model.input.op.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "872\n",
      "CPU times: user 2.72 s, sys: 148 ms, total: 2.87 s\n",
      "Wall time: 2.17 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "count = 0\n",
    "for i in range(1000):    \n",
    "    tesval = np.array([X_train[i]]).reshape(1,1,16000)\n",
    "    if np.argmax(model.predict(tesval)) ==  np.argmax(y_train[i]):\n",
    "        count+= 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(model.predict(tesval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dense_2/Softmax'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.output.op.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('94_cnn.h5',keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"yo.h5\")\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown layer: Melspectrogram",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-d577127b235e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlite\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mconverter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFLiteConverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_keras_model_file\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m'yo.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtfmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallow_custom_ops\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mopen\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"model.tflite\"\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36mfrom_keras_model_file\u001b[0;34m(cls, model_file, input_arrays, input_shapes, output_arrays)\u001b[0m\n\u001b[1;32m    368\u001b[0m     \u001b[0m_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m     \u001b[0m_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_learning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m     \u001b[0mkeras_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m     \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    232\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No model found in config file.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_from_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;31m# set weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/engine/saving.py\u001b[0m in \u001b[0;36mmodel_from_config\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m    322\u001b[0m                     '`Sequential.from_config(config)`?')\n\u001b[1;32m    323\u001b[0m   \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeserialize\u001b[0m  \u001b[0;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/layers/serialization.py\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m     72\u001b[0m       \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m       \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m       printable_module_name='layer')\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    190\u001b[0m             custom_objects=dict(\n\u001b[1;32m    191\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_GLOBAL_CUSTOM_OBJECTS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m                 list(custom_objects.items())))\n\u001b[0m\u001b[1;32m    193\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mCustomObjectScope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m    347\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlayer_config\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayer_configs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m       layer = layer_module.deserialize(layer_config,\n\u001b[0;32m--> 349\u001b[0;31m                                        custom_objects=custom_objects)\n\u001b[0m\u001b[1;32m    350\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbuild_input_shape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/layers/serialization.py\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m     72\u001b[0m       \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m       \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m       printable_module_name='layer')\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midentifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     (cls, cls_config) = class_and_config_for_serialized_keras_object(\n\u001b[0;32m--> 181\u001b[0;31m         config, module_objects, custom_objects, printable_module_name)\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'from_config'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mclass_and_config_for_serialized_keras_object\u001b[0;34m(config, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule_objects\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unknown '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mprintable_module_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mclass_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown layer: Melspectrogram"
     ]
    }
   ],
   "source": [
    "from tensorflow.contrib import lite\n",
    "converter = lite.TFLiteConverter.from_keras_model_file( 'yo.h5')\n",
    "tfmodel = converter.convert()\n",
    "converter.allow_custom_ops=True\n",
    "open (\"model.tflite\" , \"wb\") .write(tfmodel)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
