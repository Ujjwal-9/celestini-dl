{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Collecting kapre\r\n",
      "  Downloading https://files.pythonhosted.org/packages/3f/2e/f540d1d1f05c764686163fdb5bb1e5c703f1528076d2829bfc3900683f06/kapre-0.1.4-py3-none-any.whl\r\n",
      "Requirement already satisfied: numpy>=1.8.0 in /opt/conda/lib/python3.6/site-packages (from kapre) (1.16.4)\r\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.6/site-packages (from kapre) (0.17.1)\r\n",
      "Requirement already satisfied: librosa>=0.5 in /opt/conda/lib/python3.6/site-packages (from kapre) (0.6.3)\r\n",
      "Requirement already satisfied: keras>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from kapre) (2.2.4)\r\n",
      "Requirement already satisfied: six>=1.3 in /opt/conda/lib/python3.6/site-packages (from librosa>=0.5->kapre) (1.12.0)\r\n",
      "Requirement already satisfied: scipy>=1.0.0 in /opt/conda/lib/python3.6/site-packages (from librosa>=0.5->kapre) (1.3.0)\r\n",
      "Requirement already satisfied: audioread>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from librosa>=0.5->kapre) (2.1.8)\r\n",
      "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /opt/conda/lib/python3.6/site-packages (from librosa>=0.5->kapre) (0.21.2)\r\n",
      "Requirement already satisfied: decorator>=3.0.0 in /opt/conda/lib/python3.6/site-packages (from librosa>=0.5->kapre) (4.4.0)\r\n",
      "Requirement already satisfied: joblib>=0.12 in /opt/conda/lib/python3.6/site-packages (from librosa>=0.5->kapre) (0.13.2)\r\n",
      "Requirement already satisfied: resampy>=0.2.0 in /opt/conda/lib/python3.6/site-packages (from librosa>=0.5->kapre) (0.2.1)\r\n",
      "Requirement already satisfied: numba>=0.38.0 in /opt/conda/lib/python3.6/site-packages (from librosa>=0.5->kapre) (0.38.0)\r\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /opt/conda/lib/python3.6/site-packages (from keras>=2.0.0->kapre) (1.0.8)\r\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.6/site-packages (from keras>=2.0.0->kapre) (2.9.0)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.6/site-packages (from keras>=2.0.0->kapre) (5.1)\r\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.6/site-packages (from keras>=2.0.0->kapre) (1.1.0)\r\n",
      "Requirement already satisfied: llvmlite>=0.23.0dev0 in /opt/conda/lib/python3.6/site-packages (from numba>=0.38.0->librosa>=0.5->kapre) (0.29.0)\r\n",
      "Installing collected packages: kapre\r\n",
      "Successfully installed kapre-0.1.4\r\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "import librosa\n",
    "import random\n",
    "!pip install kapre\n",
    "\n",
    "# Any results you write to the current directory are saved as output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roll(data):\n",
    "    data_roll = np.roll(data, 5000)\n",
    "    return data_roll\n",
    "def stretch(data, rate=2):\n",
    "    input_length = 16000*3\n",
    "    data = librosa.effects.time_stretch(data, rate)\n",
    "    if len(data)>input_length:\n",
    "        data = data[:input_length]\n",
    "    else:\n",
    "        data = np.pad(data, (0, max(0, input_length - len(data))), \"constant\")\n",
    "\n",
    "    return data\n",
    "\n",
    "def wnoise(data):\n",
    "    wn = np.random.randn(len(data))\n",
    "    data_wn = data + 0.005*wn\n",
    "    return data_wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'dataset'...\r\n",
      "remote: Enumerating objects: 2719, done.\u001b[K\r\n",
      "remote: Total 2719 (delta 0), reused 0 (delta 0), pack-reused 2719\u001b[K\r\n",
      "Receiving objects: 100% (2719/2719), 184.15 MiB | 14.13 MiB/s, done.\r\n",
      "Resolving deltas: 100% (77/77), done.\r\n"
     ]
    }
   ],
   "source": [
    "# put dataset in folder named dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def get_all_files(datapath, dataset_type=\"keyword\"):\n",
    "    data_dir = datapath\n",
    "    data = []\n",
    "    all_files = os.listdir(data_dir)\n",
    "    all_files.remove('.DS_Store')\n",
    "    labels = set()\n",
    "    for file in all_files:\n",
    "        filelabels = file.split(\"-\")[:3]\n",
    "        data_dict = {\n",
    "            \"filepath\": data_dir + file,\n",
    "            \"stress\": filelabels[2],\n",
    "            \"environment\": filelabels[1],\n",
    "            \"keyword\":filelabels[0]\n",
    "        }\n",
    "        labels.add(data_dict[dataset_type])\n",
    "        data.append(data_dict)\n",
    "\n",
    "    return data,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "class AudioFeatureDataset():\n",
    "\n",
    "    ''' To create audio dataset\n",
    "        @param dataset_type = ( keyword | stress | environment   )\n",
    "    '''\n",
    "\n",
    "    def __init__(self,datapath, samplingrate=16000, dt=\"keyword\"):\n",
    "        print(dt)\n",
    "        datafiles, labels = get_all_files(datapath,dataset_type=dt)\n",
    "        self.datafiles = datafiles\n",
    "        self.samplingrate = samplingrate\n",
    "        self.target_labels = list(labels)\n",
    "        self.dataset_type = dt\n",
    "\n",
    "    def process(self, file, max_len=16000):\n",
    "        ''' extracts raw audio  and returns samps '''\n",
    "        try:\n",
    "            samps, sr = librosa.load(file, mono=True, sr=None)\n",
    "            pad_len = max_len - samps.shape[0]\n",
    "            if pad_len >= 0:\n",
    "                samps = np.pad(samps, (0, pad_len), 'constant')\n",
    "            return np.array(samps[:max_len])\n",
    "        except:\n",
    "            print(file)\n",
    "\n",
    "    def get_dataset(self, include_background=False):\n",
    "        labels = []\n",
    "        features = []\n",
    "        for file_data in tqdm(self.datafiles):\n",
    "            labels.append(file_data[self.dataset_type])\n",
    "            samps = self.process(file_data[\"filepath\"], self.samplingrate * 3)\n",
    "            features.append(samps)\n",
    "            # with roll\n",
    "            labels.append(file_data[self.dataset_type])\n",
    "            features.append(roll(samps)) \n",
    "            # with strech\n",
    "            labels.append(file_data[self.dataset_type])\n",
    "            features.append(stretch(samps)) \n",
    "            # white noise\n",
    "            labels.append(file_data[self.dataset_type])\n",
    "            features.append(wnoise(samps)) \n",
    "        labels = np.array(labels)\n",
    "        features = np.array(features)\n",
    "        return features, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword\n"
     ]
    }
   ],
   "source": [
    "a = AudioFeatureDataset(datapath=\"dataset/data/\",dt=\"keyword\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2599/2599 [11:06<00:00,  1.94it/s]\n"
     ]
    }
   ],
   "source": [
    "features,labels = a.get_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(features)\n",
    "del features\n",
    "Y = np.array(labels)\n",
    "del labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "class_weights = class_weight.compute_class_weight('balanced',np.unique(Y),Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10396, 48000)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.reshape(x.shape[0], 1, 16000 * 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unknown       3292\n",
      "help          2692\n",
      "background    2248\n",
      "bacho         2164\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.Series(Y)\n",
    "target_count = df.value_counts()\n",
    "print(target_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "labelencoder = LabelEncoder()\n",
    "Y = labelencoder.fit_transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def get_train_test(split_ratio=0.7, random_state=42):\n",
    "    return train_test_split(x, Y, test_size= (1 - split_ratio), random_state=random_state, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = get_train_test()\n",
    "def get_test_val(split_ratio=0.5, random_state=42):\n",
    "    return train_test_split(X_train, y_train, test_size= (1 - split_ratio), random_state=random_state, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, X_test, y_val, y_test = get_test_val()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3638, 1, 48000)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\"logs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<!-- JUPYTER_TENSORBOARD_TEST_MARKER -->\n",
       "<script>\n",
       "    const req = {\n",
       "        method: 'POST',\n",
       "        contentType: 'application/json',\n",
       "        body: JSON.stringify({ 'logdir': 'logs' }),\n",
       "        headers: { 'Content-Type': 'application/json' }\n",
       "    };\n",
       "\n",
       "    const baseUrl = Jupyter.notebook.base_url;\n",
       "\n",
       "    fetch(baseUrl + 'api/tensorboard', req)\n",
       "        .then(res => res.json())\n",
       "        .then(res => {\n",
       "            const iframe = document.getElementById('tensorboard-2f8a908c-9712-4640-8328-004710efce8a');\n",
       "            iframe.src = baseUrl + 'tensorboard/' + res.name;\n",
       "            iframe.style.display = 'block';\n",
       "        });\n",
       "</script>\n",
       "\n",
       "<iframe\n",
       "    id=\"tensorboard-2f8a908c-9712-4640-8328-004710efce8a\"\n",
       "    style=\"width: 100%; height: 620px; display: none;\"\n",
       "    frameBorder=\"0\">\n",
       "</iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard.notebook\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bacho': 0, 'background': 1, 'help': 2, 'unknown': 3}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_train = labelencoder.fit_transform(y_train)\n",
    "mapping = dict(zip(labelencoder.classes_, range(len(labelencoder.classes_))))\n",
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = to_categorical(y_test)\n",
    "y_train = to_categorical(y_train)\n",
    "y_val = to_categorical(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "del x\n",
    "del Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kapre in /opt/conda/lib/python3.6/site-packages (0.1.4)\r\n",
      "Requirement already satisfied: keras>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from kapre) (2.2.4)\r\n",
      "Requirement already satisfied: librosa>=0.5 in /opt/conda/lib/python3.6/site-packages (from kapre) (0.6.3)\r\n",
      "Requirement already satisfied: numpy>=1.8.0 in /opt/conda/lib/python3.6/site-packages (from kapre) (1.16.4)\r\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.6/site-packages (from kapre) (0.17.1)\r\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.6/site-packages (from keras>=2.0.0->kapre) (1.1.0)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.6/site-packages (from keras>=2.0.0->kapre) (5.1)\r\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.6/site-packages (from keras>=2.0.0->kapre) (1.12.0)\r\n",
      "Requirement already satisfied: scipy>=0.14 in /opt/conda/lib/python3.6/site-packages (from keras>=2.0.0->kapre) (1.3.0)\r\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /opt/conda/lib/python3.6/site-packages (from keras>=2.0.0->kapre) (1.0.8)\r\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.6/site-packages (from keras>=2.0.0->kapre) (2.9.0)\r\n",
      "Requirement already satisfied: resampy>=0.2.0 in /opt/conda/lib/python3.6/site-packages (from librosa>=0.5->kapre) (0.2.1)\r\n",
      "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /opt/conda/lib/python3.6/site-packages (from librosa>=0.5->kapre) (0.21.2)\r\n",
      "Requirement already satisfied: decorator>=3.0.0 in /opt/conda/lib/python3.6/site-packages (from librosa>=0.5->kapre) (4.4.0)\r\n",
      "Requirement already satisfied: joblib>=0.12 in /opt/conda/lib/python3.6/site-packages (from librosa>=0.5->kapre) (0.13.2)\r\n",
      "Requirement already satisfied: numba>=0.38.0 in /opt/conda/lib/python3.6/site-packages (from librosa>=0.5->kapre) (0.38.0)\r\n",
      "Requirement already satisfied: audioread>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from librosa>=0.5->kapre) (2.1.8)\r\n",
      "Requirement already satisfied: llvmlite>=0.23.0dev0 in /opt/conda/lib/python3.6/site-packages (from numba>=0.38.0->librosa>=0.5->kapre) (0.29.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install kapre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, Dense, Dropout, Flatten, Conv2D, MaxPooling2D,SeparableConv2D,BatchNormalization,LSTM,Reshape,TimeDistributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import kapre\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,AveragePooling2D\n",
    "from kapre.time_frequency import Melspectrogram\n",
    "from kapre.utils import Normalization2D\n",
    "from kapre.augmentation import AdditiveNoise\n",
    "\n",
    "# 6 channels (!), maybe 1-sec audio signal, for an example.\n",
    "\n",
    "sr = 16000\n",
    "input_shape = (1,sr*3)\n",
    "\n",
    "\n",
    "def edge_speech_neta():\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(\"logs/esna\")\n",
    "    model = Sequential()\n",
    "    # A mel-spectrogram layer\n",
    "    model.add(Melspectrogram(n_dft=512, n_hop=512, input_shape=input_shape,\n",
    "                             padding='same', sr=sr, n_mels=128,\n",
    "                             fmin=0.0, fmax=sr/2, power_melgram=1.0,\n",
    "                             return_decibel_melgram=True,trainable_fb=False,\n",
    "                             trainable_kernel=False,\n",
    "                             name='trainable_stft'))\n",
    "    # Maybe some additive white noise.\n",
    "    model.add(AdditiveNoise(power=0.1))\n",
    "    # If you wanna normalise it per-frequency\n",
    "    model.add(Normalization2D(str_axis='freq')) # or 'channel', 'time', 'batch', 'data_sample'\n",
    "    # After this, it's just a usual keras workflow. For example..\n",
    "    # Add some layers, e.g., model.add(some convolution layers..)\n",
    "   \n",
    "    # Compile the model\n",
    "    model.add(Conv2D(39, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(Conv2D(20, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\n",
    "    model.add(Conv2D(39, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(15, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\n",
    "    model.add(Conv2D(39, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(25, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\n",
    "    model.add(Conv2D(39, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(22, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\n",
    "    model.add(Conv2D(39, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(22, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\n",
    "    model.add(Conv2D(39, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(25, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\n",
    "    model.add(Conv2D(39, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\n",
    "    model.add(Conv2D(45, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\n",
    "    model.add(AveragePooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4, activation='softmax'))\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                      optimizer=keras.optimizers.adam(),metrics=['accuracy'],)\n",
    "    model.fit(X_train, y_train, batch_size=50, epochs=50, verbose=1, validation_data=(X_test, y_test), callbacks=[tensorboard_callback])\n",
    "    model.save('esna.h5')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def depth_Seprable_cnn():\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(\"logs/depth-serpable-cnn-100e\")\n",
    "    # Depth Wise CNN (DS-CNN)\n",
    "    model = Sequential()\n",
    "    # A mel-spectrogram layer\n",
    "    model.add(Melspectrogram(n_dft=512, n_hop=512, input_shape=input_shape,\n",
    "                             padding='same', sr=sr, n_mels=128,\n",
    "                             fmin=0.0, fmax=sr/2, power_melgram=1.0,\n",
    "                             return_decibel_melgram=True,trainable_fb=False,\n",
    "                             trainable_kernel=False,\n",
    "                             name='trainable_stft'))\n",
    "    # Maybe some additive white noise.\n",
    "    model.add(AdditiveNoise(power=0.1))\n",
    "    # If you wanna normalise it per-frequency\n",
    "    model.add(Normalization2D(str_axis='freq')) # or 'channel', 'time', 'batch', 'data_sample'\n",
    "    # After this, it's just a usual keras workflow. For example..\n",
    "    # Add some layers, e.g., model.add(some convolution layers..)\n",
    "    # Compile the model\n",
    "    model.add(Conv2D(64, kernel_size=(20, 8), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),dim_ordering=\"th\"))\n",
    "    model.add(Dropout(0.25))\n",
    "    ## Depth Seprable Pooling Layer - start\n",
    "    model.add(SeparableConv2D(64, kernel_size=(5, 5), activation='relu',dim_ordering=\"th\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64, kernel_size=(1, 1), activation='relu',dim_ordering=\"th\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(SeparableConv2D(64, kernel_size=(5, 5), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64, kernel_size=(1, 1), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    ## Depth Seprable pooling Layer - end\n",
    "    model.add(AveragePooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4, activation='softmax'))\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.adam(),metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, batch_size=50, epochs=50, verbose=1, validation_data=(X_test, y_test), callbacks=[tensorboard_callback])\n",
    "    model.save('dscnn.h5')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edgespeechnetd():\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(\"logs/edgespeechnet-d-100e\")\n",
    "    model = Sequential()\n",
    "    # A mel-spectrogram layer\n",
    "    model.add(Melspectrogram(n_dft=512, n_hop=512, input_shape=input_shape,\n",
    "                             padding='same', sr=sr, n_mels=128,\n",
    "                             fmin=0.0, fmax=sr/2, power_melgram=1.0,\n",
    "                             return_decibel_melgram=True,trainable_fb=False,\n",
    "                             trainable_kernel=False,\n",
    "                             name='trainable_stft'))\n",
    "    # Maybe some additive white noise.\n",
    "    model.add(AdditiveNoise(power=0.1))\n",
    "    # If you wanna normalise it per-frequency\n",
    "    model.add(Normalization2D(str_axis='freq')) # or 'channel', 'time', 'batch', 'data_sample'\n",
    "    # After this, it's just a usual keras workflow. For example..\n",
    "    # Add some layers, e.g., model.add(some convolution layers..)\n",
    "    # Compile the model\n",
    "    model.add(Conv2D(45, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(AveragePooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(30, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\n",
    "    model.add(Conv2D(45, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\n",
    "    model.add(Conv2D(33, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\n",
    "    model.add(Conv2D(45, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\n",
    "    model.add(Conv2D(35, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\n",
    "    model.add(Conv2D(45, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\n",
    "\n",
    "    model.add(AveragePooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(16))\n",
    "    model.add(Dense(4, activation='softmax'))\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.adam(),metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, batch_size=50, epochs=50, verbose=1, validation_data=(X_test, y_test), callbacks=[tensorboard_callback])\n",
    "    model.save('esnd.h5')\n",
    "    return model\n",
    "\n",
    "def edgespeechnetb():\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(\"logs/edgespeechnet-b-100e\")\n",
    "    model = Sequential()\n",
    "    # A mel-spectrogram layer\n",
    "    model.add(Melspectrogram(n_dft=512, n_hop=512, input_shape=input_shape,\n",
    "                             padding='same', sr=sr, n_mels=128,\n",
    "                             fmin=0.0, fmax=sr/2, power_melgram=1.0,\n",
    "                             return_decibel_melgram=True,trainable_fb=False,\n",
    "                             trainable_kernel=False,\n",
    "                             name='trainable_stft'))\n",
    "    # Maybe some additive white noise.\n",
    "    model.add(AdditiveNoise(power=0.1))\n",
    "    # If you wanna normalise it per-frequency\n",
    "    model.add(Normalization2D(str_axis='freq')) # or 'channel', 'time', 'batch', 'data_sample'\n",
    "    # After this, it's just a usual keras workflow. For example..\n",
    "    # Add some layers, e.g., model.add(some convolution layers..)\n",
    "    # Compile the model\n",
    "    model.add(Conv2D(30, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(Conv2D(8, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\n",
    "    model.add(Conv2D(30, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\n",
    "    model.add(Conv2D(9, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\n",
    "    model.add(Conv2D(30, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\n",
    "    model.add(Conv2D(11, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\n",
    "    model.add(Conv2D(30, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\n",
    "    model.add(Conv2D(10, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\n",
    "    model.add(Conv2D(30, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\n",
    "    model.add(Conv2D(8, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\n",
    "    model.add(Conv2D(30, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\n",
    "    model.add(Conv2D(11, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\n",
    "    model.add(Conv2D(30, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\n",
    "    model.add(Conv2D(45, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\n",
    "\n",
    "    model.add(AveragePooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    # model.add(Dense(16))\n",
    "    model.add(Dense(4, activation='softmax'))\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.adam(),metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, batch_size=50, epochs=50, verbose=1, validation_data=(X_test, y_test), callbacks=[tensorboard_callback])\n",
    "    model.save('esnb.h5')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn():\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(\"logs/cnn-100e\")\n",
    "    model = Sequential()\n",
    "    # A mel-spectrogram layer\n",
    "    model.add(Melspectrogram(n_dft=512, n_hop=512, input_shape=input_shape,\n",
    "                             padding='same', sr=sr, n_mels=128,\n",
    "                             fmin=0.0, fmax=sr/2, power_melgram=1.0,\n",
    "                             return_decibel_melgram=True,trainable_fb=False,\n",
    "                             trainable_kernel=False,\n",
    "                             name='trainable_stft'))\n",
    "    # Maybe some additive white noise.\n",
    "    model.add(AdditiveNoise(power=0.1))\n",
    "    # If you wanna normalise it per-frequency\n",
    "    model.add(Normalization2D(str_axis='freq')) # or 'channel', 'time', 'batch', 'data_sample'\n",
    "    # After this, it's just a usual keras workflow. For example..\n",
    "    # Add some layers, e.g., model.add(some convolution layers..)\n",
    "    # Compile the model\n",
    "\n",
    "    model.add(Conv2D(64, kernel_size=(20, 8), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),dim_ordering=\"th\"))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(64, kernel_size=(10, 4), activation='relu',dim_ordering=\"th\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),dim_ordering=\"th\"))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(4, activation='softmax'))\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.adam(),metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, batch_size=50, epochs=50, verbose=1, validation_data=(X_test, y_test), callbacks=[tensorboard_callback])\n",
    "    model.save('cnn.h5')\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Permute, Dropout, Flatten, Conv2D, MaxPooling2D,SeparableConv2D,BatchNormalization,AveragePooling2D,GRU,Input\n",
    "\n",
    "def crnn():\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(\"logs/crnn-50batch\")\n",
    "    model = Sequential()\n",
    "    model.add(Melspectrogram(n_dft=512, n_hop=512, input_shape=input_shape,\n",
    "                             padding='same', sr=sr, n_mels=128,\n",
    "                             fmin=0.0, fmax=sr/2, power_melgram=1.0,\n",
    "                             return_decibel_melgram=True,trainable_fb=False,\n",
    "                             trainable_kernel=False,\n",
    "                             name='trainable_stft'))\n",
    "    # Maybe some additive white noise.\n",
    "    model.add(AdditiveNoise(power=0.1))\n",
    "    # If you wanna normalise it per-frequency\n",
    "    model.add(Normalization2D(str_axis='freq'))\n",
    "    model.add(Conv2D(64, kernel_size=(20, 8), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),dim_ordering=\"th\"))\n",
    "    model.add(Dropout(0.25))\n",
    "    ## Depth Seprable Pooling Layer - start\n",
    "    model.add(SeparableConv2D(64, kernel_size=(5,5), activation='relu',dim_ordering=\"th\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64, kernel_size=(1, 1), activation='relu',dim_ordering=\"th\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(SeparableConv2D(64, kernel_size=(5,5), activation='relu',dim_ordering=\"th\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64, kernel_size=(1, 1), activation='relu',dim_ordering=\"th\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(SeparableConv2D(64, kernel_size=(5,5), activation='relu',dim_ordering=\"th\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64, kernel_size=(1, 1), activation='relu',dim_ordering=\"th\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(AveragePooling2D(pool_size=(2, 2),dim_ordering=\"th\"))\n",
    "    model.add(Reshape((320, -1)))\n",
    "    model.add(GRU(60, return_sequences=True, name='gru1'))\n",
    "    model.add(GRU(60, return_sequences=False, name='gru2'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(4, activation='softmax'))\n",
    "    model.summary()\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.adam(),metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, batch_size=50, epochs=50, verbose=1, validation_data=(X_test, y_test), callbacks=[tensorboard_callback])\n",
    "    model.save('crnn.h5')\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark Different Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:18: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:21: UserWarning: Update your `SeparableConv2D` call to the Keras 2 API: `SeparableConv2D(64, kernel_size=(5, 5), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:23: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, kernel_size=(1, 1), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:25: UserWarning: Update your `SeparableConv2D` call to the Keras 2 API: `SeparableConv2D(64, kernel_size=(5, 5), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:27: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, kernel_size=(1, 1), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:29: UserWarning: Update your `SeparableConv2D` call to the Keras 2 API: `SeparableConv2D(64, kernel_size=(5, 5), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:31: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, kernel_size=(1, 1), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:33: UserWarning: Update your `AveragePooling2D` call to the Keras 2 API: `AveragePooling2D(pool_size=(2, 2), data_format=\"channels_first\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "trainable_stft (Melspectrogr (None, 128, 94, 1)        296064    \n",
      "_________________________________________________________________\n",
      "additive_noise_1 (AdditiveNo (None, 128, 94, 1)        0         \n",
      "_________________________________________________________________\n",
      "normalization2d_1 (Normaliza (None, 128, 94, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 109, 87, 64)       10304     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 109, 43, 32)       0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 109, 43, 32)       0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_1 (Separabl (None, 64, 39, 28)        9765      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 64, 39, 28)        112       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 64, 39, 28)        4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 64, 39, 28)        112       \n",
      "_________________________________________________________________\n",
      "separable_conv2d_2 (Separabl (None, 64, 35, 24)        5760      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 64, 35, 24)        96        \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 64, 35, 24)        4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 64, 35, 24)        96        \n",
      "_________________________________________________________________\n",
      "separable_conv2d_3 (Separabl (None, 64, 31, 20)        5760      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 64, 31, 20)        80        \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 64, 31, 20)        4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 64, 31, 20)        80        \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average (None, 64, 15, 10)        0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 320, 30)           0         \n",
      "_________________________________________________________________\n",
      "gru1 (GRU)                   (None, 320, 60)           16380     \n",
      "_________________________________________________________________\n",
      "gru2 (GRU)                   (None, 60)                21780     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 244       \n",
      "=================================================================\n",
      "Total params: 379,113\n",
      "Trainable params: 82,761\n",
      "Non-trainable params: 296,352\n",
      "_________________________________________________________________\n",
      "Train on 7277 samples, validate on 3639 samples\n",
      "Epoch 1/50\n",
      "7277/7277 [==============================] - 134s 18ms/step - loss: 1.1406 - acc: 0.4748 - val_loss: 1.0159 - val_acc: 0.5532\n",
      "Epoch 2/50\n",
      "7277/7277 [==============================] - 131s 18ms/step - loss: 0.8787 - acc: 0.6178 - val_loss: 1.0025 - val_acc: 0.6271\n",
      "Epoch 3/50\n",
      "7277/7277 [==============================] - 131s 18ms/step - loss: 0.7221 - acc: 0.7116 - val_loss: 0.5807 - val_acc: 0.7818\n",
      "Epoch 4/50\n",
      "7277/7277 [==============================] - 129s 18ms/step - loss: 0.5712 - acc: 0.7943 - val_loss: 0.6134 - val_acc: 0.7785\n",
      "Epoch 5/50\n",
      "7277/7277 [==============================] - 129s 18ms/step - loss: 0.4628 - acc: 0.8381 - val_loss: 0.4717 - val_acc: 0.8285\n",
      "Epoch 6/50\n",
      "7277/7277 [==============================] - 129s 18ms/step - loss: 0.4074 - acc: 0.8565 - val_loss: 0.3793 - val_acc: 0.8621\n",
      "Epoch 7/50\n",
      "7277/7277 [==============================] - 129s 18ms/step - loss: 0.3508 - acc: 0.8793 - val_loss: 0.3002 - val_acc: 0.8978\n",
      "Epoch 8/50\n",
      "7277/7277 [==============================] - 129s 18ms/step - loss: 0.3200 - acc: 0.8897 - val_loss: 0.3885 - val_acc: 0.8626\n",
      "Epoch 9/50\n",
      "7277/7277 [==============================] - 129s 18ms/step - loss: 0.2813 - acc: 0.8989 - val_loss: 0.2547 - val_acc: 0.9101\n",
      "Epoch 10/50\n",
      "7277/7277 [==============================] - 129s 18ms/step - loss: 0.2551 - acc: 0.9123 - val_loss: 0.1949 - val_acc: 0.9346\n",
      "Epoch 11/50\n",
      "7277/7277 [==============================] - 129s 18ms/step - loss: 0.2224 - acc: 0.9235 - val_loss: 0.1837 - val_acc: 0.9384\n",
      "Epoch 12/50\n",
      "7277/7277 [==============================] - 129s 18ms/step - loss: 0.2147 - acc: 0.9254 - val_loss: 0.1532 - val_acc: 0.9453\n",
      "Epoch 13/50\n",
      "7277/7277 [==============================] - 129s 18ms/step - loss: 0.1866 - acc: 0.9357 - val_loss: 0.2535 - val_acc: 0.9057\n",
      "Epoch 14/50\n",
      "7277/7277 [==============================] - 129s 18ms/step - loss: 0.1769 - acc: 0.9402 - val_loss: 0.1031 - val_acc: 0.9656\n",
      "Epoch 15/50\n",
      "7277/7277 [==============================] - 129s 18ms/step - loss: 0.1649 - acc: 0.9445 - val_loss: 0.1044 - val_acc: 0.9656\n",
      "Epoch 16/50\n",
      "7277/7277 [==============================] - 129s 18ms/step - loss: 0.1366 - acc: 0.9531 - val_loss: 0.1135 - val_acc: 0.9571\n",
      "Epoch 17/50\n",
      "7277/7277 [==============================] - 129s 18ms/step - loss: 0.1300 - acc: 0.9547 - val_loss: 0.1964 - val_acc: 0.9269\n",
      "Epoch 18/50\n",
      "7277/7277 [==============================] - 129s 18ms/step - loss: 0.1433 - acc: 0.9529 - val_loss: 0.0656 - val_acc: 0.9810\n",
      "Epoch 19/50\n",
      "7277/7277 [==============================] - 129s 18ms/step - loss: 0.1019 - acc: 0.9672 - val_loss: 0.1640 - val_acc: 0.9360\n",
      "Epoch 20/50\n",
      "7277/7277 [==============================] - 129s 18ms/step - loss: 0.1026 - acc: 0.9656 - val_loss: 0.0590 - val_acc: 0.9805\n",
      "Epoch 21/50\n",
      "7277/7277 [==============================] - 129s 18ms/step - loss: 0.1160 - acc: 0.9595 - val_loss: 0.1679 - val_acc: 0.9437\n",
      "Epoch 22/50\n",
      "7277/7277 [==============================] - 129s 18ms/step - loss: 0.0904 - acc: 0.9705 - val_loss: 0.0764 - val_acc: 0.9747\n",
      "Epoch 23/50\n",
      "7277/7277 [==============================] - 129s 18ms/step - loss: 0.0871 - acc: 0.9696 - val_loss: 0.0645 - val_acc: 0.9788\n",
      "Epoch 24/50\n",
      "7277/7277 [==============================] - 129s 18ms/step - loss: 0.0891 - acc: 0.9696 - val_loss: 0.0784 - val_acc: 0.9739\n",
      "Epoch 25/50\n",
      "7277/7277 [==============================] - 129s 18ms/step - loss: 0.0945 - acc: 0.9692 - val_loss: 0.0845 - val_acc: 0.9728\n",
      "Epoch 26/50\n",
      "7277/7277 [==============================] - 129s 18ms/step - loss: 0.0813 - acc: 0.9731 - val_loss: 0.0545 - val_acc: 0.9824\n",
      "Epoch 27/50\n",
      "7277/7277 [==============================] - 129s 18ms/step - loss: 0.0748 - acc: 0.9747 - val_loss: 0.0585 - val_acc: 0.9799\n",
      "Epoch 28/50\n",
      "7277/7277 [==============================] - 129s 18ms/step - loss: 0.0718 - acc: 0.9772 - val_loss: 0.0382 - val_acc: 0.9876\n",
      "Epoch 29/50\n",
      "7277/7277 [==============================] - 129s 18ms/step - loss: 0.0624 - acc: 0.9783 - val_loss: 0.0445 - val_acc: 0.9860\n",
      "Epoch 30/50\n",
      "7277/7277 [==============================] - 129s 18ms/step - loss: 0.0753 - acc: 0.9761 - val_loss: 0.0576 - val_acc: 0.9813\n",
      "Epoch 31/50\n",
      "7277/7277 [==============================] - 129s 18ms/step - loss: 0.0676 - acc: 0.9784 - val_loss: 0.0199 - val_acc: 0.9937\n",
      "Epoch 32/50\n",
      "7277/7277 [==============================] - 129s 18ms/step - loss: 0.0535 - acc: 0.9831 - val_loss: 0.0949 - val_acc: 0.9654\n",
      "Epoch 33/50\n",
      "7277/7277 [==============================] - 129s 18ms/step - loss: 0.0684 - acc: 0.9779 - val_loss: 0.0548 - val_acc: 0.9835\n",
      "Epoch 34/50\n",
      "7277/7277 [==============================] - 129s 18ms/step - loss: 0.0554 - acc: 0.9806 - val_loss: 0.0356 - val_acc: 0.9882\n",
      "Epoch 35/50\n",
      "7277/7277 [==============================] - 128s 18ms/step - loss: 0.0539 - acc: 0.9836 - val_loss: 0.0428 - val_acc: 0.9874\n",
      "Epoch 36/50\n",
      "7277/7277 [==============================] - 129s 18ms/step - loss: 0.0535 - acc: 0.9832 - val_loss: 0.0475 - val_acc: 0.9827\n",
      "Epoch 37/50\n",
      "7277/7277 [==============================] - 128s 18ms/step - loss: 0.0458 - acc: 0.9853 - val_loss: 0.0384 - val_acc: 0.9882\n",
      "Epoch 38/50\n",
      "7277/7277 [==============================] - 129s 18ms/step - loss: 0.0494 - acc: 0.9830 - val_loss: 0.0278 - val_acc: 0.9890\n",
      "Epoch 39/50\n",
      "7277/7277 [==============================] - 128s 18ms/step - loss: 0.0477 - acc: 0.9861 - val_loss: 0.0274 - val_acc: 0.9907\n",
      "Epoch 40/50\n",
      "7277/7277 [==============================] - 129s 18ms/step - loss: 0.0511 - acc: 0.9849 - val_loss: 0.0382 - val_acc: 0.9871\n",
      "Epoch 41/50\n",
      "7277/7277 [==============================] - 129s 18ms/step - loss: 0.0484 - acc: 0.9842 - val_loss: 0.0287 - val_acc: 0.9896\n",
      "Epoch 42/50\n",
      "7277/7277 [==============================] - 128s 18ms/step - loss: 0.0442 - acc: 0.9849 - val_loss: 0.0304 - val_acc: 0.9887\n",
      "Epoch 43/50\n",
      "7277/7277 [==============================] - 129s 18ms/step - loss: 0.0491 - acc: 0.9830 - val_loss: 0.0309 - val_acc: 0.9907\n",
      "Epoch 44/50\n",
      "7277/7277 [==============================] - 128s 18ms/step - loss: 0.0439 - acc: 0.9863 - val_loss: 0.0418 - val_acc: 0.9857\n",
      "Epoch 45/50\n",
      "7277/7277 [==============================] - 128s 18ms/step - loss: 0.0471 - acc: 0.9845 - val_loss: 0.0264 - val_acc: 0.9904\n",
      "Epoch 46/50\n",
      "7277/7277 [==============================] - 129s 18ms/step - loss: 0.0469 - acc: 0.9845 - val_loss: 0.0408 - val_acc: 0.9876\n",
      "Epoch 47/50\n",
      "7277/7277 [==============================] - 129s 18ms/step - loss: 0.0490 - acc: 0.9830 - val_loss: 0.0135 - val_acc: 0.9970\n",
      "Epoch 48/50\n",
      "7277/7277 [==============================] - 129s 18ms/step - loss: 0.0493 - acc: 0.9825 - val_loss: 0.0307 - val_acc: 0.9887\n",
      "Epoch 49/50\n",
      "7277/7277 [==============================] - 128s 18ms/step - loss: 0.0357 - acc: 0.9885 - val_loss: 0.0207 - val_acc: 0.9940\n",
      "Epoch 50/50\n",
      "7277/7277 [==============================] - 129s 18ms/step - loss: 0.0429 - acc: 0.9864 - val_loss: 0.0132 - val_acc: 0.9970\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7f2cbb1d2cc0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:34: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(20, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:35: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(39, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:37: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(15, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:38: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(39, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:40: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(25, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:41: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(39, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:43: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(22, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:44: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(39, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:46: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(22, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:47: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(39, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:49: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(25, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:50: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(39, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:51: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(45, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7277 samples, validate on 3639 samples\n",
      "Epoch 1/50\n",
      "7277/7277 [==============================] - 10s 1ms/step - loss: 1.3753 - acc: 0.3158 - val_loss: 1.3736 - val_acc: 0.3141\n",
      "Epoch 2/50\n",
      "7277/7277 [==============================] - 8s 1ms/step - loss: 1.3734 - acc: 0.3179 - val_loss: 1.3738 - val_acc: 0.3141\n",
      "Epoch 3/50\n",
      "7277/7277 [==============================] - 8s 1ms/step - loss: 1.3735 - acc: 0.3179 - val_loss: 1.3737 - val_acc: 0.3141\n",
      "Epoch 4/50\n",
      "7277/7277 [==============================] - 8s 1ms/step - loss: 1.3725 - acc: 0.3179 - val_loss: 1.3737 - val_acc: 0.3141\n",
      "Epoch 5/50\n",
      "7277/7277 [==============================] - 8s 1ms/step - loss: 1.3729 - acc: 0.3179 - val_loss: 1.3735 - val_acc: 0.3141\n",
      "Epoch 6/50\n",
      "7277/7277 [==============================] - 8s 1ms/step - loss: 1.3727 - acc: 0.3179 - val_loss: 1.3733 - val_acc: 0.3141\n",
      "Epoch 7/50\n",
      "7277/7277 [==============================] - 8s 1ms/step - loss: 1.3727 - acc: 0.3179 - val_loss: 1.3741 - val_acc: 0.3141\n",
      "Epoch 8/50\n",
      "7277/7277 [==============================] - 8s 1ms/step - loss: 1.3726 - acc: 0.3179 - val_loss: 1.3746 - val_acc: 0.3141\n",
      "Epoch 9/50\n",
      "7277/7277 [==============================] - 8s 1ms/step - loss: 1.3727 - acc: 0.3179 - val_loss: 1.3734 - val_acc: 0.3141\n",
      "Epoch 10/50\n",
      "7277/7277 [==============================] - 8s 1ms/step - loss: 1.3725 - acc: 0.3179 - val_loss: 1.3740 - val_acc: 0.3141\n",
      "Epoch 11/50\n",
      "7277/7277 [==============================] - 8s 1ms/step - loss: 1.3726 - acc: 0.3179 - val_loss: 1.3734 - val_acc: 0.3141\n",
      "Epoch 12/50\n",
      "7277/7277 [==============================] - 8s 1ms/step - loss: 1.3728 - acc: 0.3179 - val_loss: 1.3732 - val_acc: 0.3141\n",
      "Epoch 13/50\n",
      "7277/7277 [==============================] - 8s 1ms/step - loss: 1.3727 - acc: 0.3179 - val_loss: 1.3738 - val_acc: 0.3141\n",
      "Epoch 14/50\n",
      "7277/7277 [==============================] - 8s 1ms/step - loss: 1.3724 - acc: 0.3179 - val_loss: 1.3732 - val_acc: 0.3141\n",
      "Epoch 15/50\n",
      "7277/7277 [==============================] - 8s 1ms/step - loss: 1.3722 - acc: 0.3179 - val_loss: 1.3735 - val_acc: 0.3141\n",
      "Epoch 16/50\n",
      "7277/7277 [==============================] - 8s 1ms/step - loss: 1.3726 - acc: 0.3179 - val_loss: 1.3732 - val_acc: 0.3141\n",
      "Epoch 17/50\n",
      "7277/7277 [==============================] - 8s 1ms/step - loss: 1.3728 - acc: 0.3179 - val_loss: 1.3733 - val_acc: 0.3141\n",
      "Epoch 18/50\n",
      "7277/7277 [==============================] - 8s 1ms/step - loss: 1.3726 - acc: 0.3179 - val_loss: 1.3734 - val_acc: 0.3141\n",
      "Epoch 19/50\n",
      "7277/7277 [==============================] - 8s 1ms/step - loss: 1.3725 - acc: 0.3179 - val_loss: 1.3736 - val_acc: 0.3141\n",
      "Epoch 20/50\n",
      "7277/7277 [==============================] - 8s 1ms/step - loss: 1.3727 - acc: 0.3179 - val_loss: 1.3732 - val_acc: 0.3141\n",
      "Epoch 21/50\n",
      "7277/7277 [==============================] - 8s 1ms/step - loss: 1.3723 - acc: 0.3179 - val_loss: 1.3740 - val_acc: 0.3141\n",
      "Epoch 22/50\n",
      "7277/7277 [==============================] - 8s 1ms/step - loss: 1.3725 - acc: 0.3179 - val_loss: 1.3733 - val_acc: 0.3141\n",
      "Epoch 23/50\n",
      "7277/7277 [==============================] - 8s 1ms/step - loss: 1.3722 - acc: 0.3179 - val_loss: 1.3733 - val_acc: 0.3141\n",
      "Epoch 24/50\n",
      "7277/7277 [==============================] - 8s 1ms/step - loss: 1.3725 - acc: 0.3179 - val_loss: 1.3733 - val_acc: 0.3141\n",
      "Epoch 25/50\n",
      "7277/7277 [==============================] - 8s 1ms/step - loss: 1.3722 - acc: 0.3179 - val_loss: 1.3733 - val_acc: 0.3141\n",
      "Epoch 26/50\n",
      "7277/7277 [==============================] - 8s 1ms/step - loss: 1.3729 - acc: 0.3179 - val_loss: 1.3734 - val_acc: 0.3141\n",
      "Epoch 27/50\n",
      "7277/7277 [==============================] - 8s 1ms/step - loss: 1.3724 - acc: 0.3179 - val_loss: 1.3734 - val_acc: 0.3141\n",
      "Epoch 28/50\n",
      "7277/7277 [==============================] - 8s 1ms/step - loss: 1.3723 - acc: 0.3179 - val_loss: 1.3733 - val_acc: 0.3141\n",
      "Epoch 29/50\n",
      "7277/7277 [==============================] - 8s 1ms/step - loss: 1.3722 - acc: 0.3179 - val_loss: 1.3735 - val_acc: 0.3141\n",
      "Epoch 30/50\n",
      "7277/7277 [==============================] - 8s 1ms/step - loss: 1.3724 - acc: 0.3179 - val_loss: 1.3734 - val_acc: 0.3141\n",
      "Epoch 31/50\n",
      "7277/7277 [==============================] - 8s 1ms/step - loss: 1.3723 - acc: 0.3179 - val_loss: 1.3733 - val_acc: 0.3141\n",
      "Epoch 32/50\n",
      "7277/7277 [==============================] - 8s 1ms/step - loss: 1.3721 - acc: 0.3179 - val_loss: 1.3736 - val_acc: 0.3141\n",
      "Epoch 33/50\n",
      "7277/7277 [==============================] - 8s 1ms/step - loss: 1.3723 - acc: 0.3179 - val_loss: 1.3737 - val_acc: 0.3141\n",
      "Epoch 34/50\n",
      "7277/7277 [==============================] - 8s 1ms/step - loss: 1.3724 - acc: 0.3179 - val_loss: 1.3732 - val_acc: 0.3141\n",
      "Epoch 35/50\n",
      "7277/7277 [==============================] - 8s 1ms/step - loss: 1.3722 - acc: 0.3179 - val_loss: 1.3733 - val_acc: 0.3141\n",
      "Epoch 36/50\n",
      "7277/7277 [==============================] - 8s 1ms/step - loss: 1.3722 - acc: 0.3179 - val_loss: 1.3733 - val_acc: 0.3141\n",
      "Epoch 37/50\n",
      "7277/7277 [==============================] - 8s 1ms/step - loss: 1.3724 - acc: 0.3179 - val_loss: 1.3733 - val_acc: 0.3141\n",
      "Epoch 38/50\n",
      "7277/7277 [==============================] - 8s 1ms/step - loss: 1.3723 - acc: 0.3179 - val_loss: 1.3734 - val_acc: 0.3141\n",
      "Epoch 39/50\n",
      "7277/7277 [==============================] - 8s 1ms/step - loss: 1.3723 - acc: 0.3179 - val_loss: 1.3733 - val_acc: 0.3141\n",
      "Epoch 40/50\n",
      "7277/7277 [==============================] - 8s 1ms/step - loss: 1.3722 - acc: 0.3179 - val_loss: 1.3732 - val_acc: 0.3141\n",
      "Epoch 41/50\n",
      "7277/7277 [==============================] - 8s 1ms/step - loss: 1.3723 - acc: 0.3179 - val_loss: 1.3732 - val_acc: 0.3141\n",
      "Epoch 42/50\n",
      "7277/7277 [==============================] - 8s 1ms/step - loss: 1.3722 - acc: 0.3179 - val_loss: 1.3732 - val_acc: 0.3141\n",
      "Epoch 43/50\n",
      "7277/7277 [==============================] - 8s 1ms/step - loss: 1.3721 - acc: 0.3179 - val_loss: 1.3732 - val_acc: 0.3141\n",
      "Epoch 44/50\n",
      "7277/7277 [==============================] - 8s 1ms/step - loss: 1.3721 - acc: 0.3179 - val_loss: 1.3732 - val_acc: 0.3141\n",
      "Epoch 45/50\n",
      "7277/7277 [==============================] - 8s 1ms/step - loss: 1.3721 - acc: 0.3179 - val_loss: 1.3732 - val_acc: 0.3141\n",
      "Epoch 46/50\n",
      "7277/7277 [==============================] - 8s 1ms/step - loss: 1.3721 - acc: 0.3179 - val_loss: 1.3732 - val_acc: 0.3141\n",
      "Epoch 47/50\n",
      "7277/7277 [==============================] - 8s 1ms/step - loss: 1.3723 - acc: 0.3179 - val_loss: 1.3732 - val_acc: 0.3141\n",
      "Epoch 48/50\n",
      "7277/7277 [==============================] - 8s 1ms/step - loss: 1.3721 - acc: 0.3179 - val_loss: 1.3732 - val_acc: 0.3141\n",
      "Epoch 49/50\n",
      "7277/7277 [==============================] - 8s 1ms/step - loss: 1.3720 - acc: 0.3179 - val_loss: 1.3732 - val_acc: 0.3141\n",
      "Epoch 50/50\n",
      "7277/7277 [==============================] - 8s 1ms/step - loss: 1.3720 - acc: 0.3179 - val_loss: 1.3732 - val_acc: 0.3141\n"
     ]
    }
   ],
   "source": [
    "mesna = edge_speech_neta()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:20: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:23: UserWarning: Update your `SeparableConv2D` call to the Keras 2 API: `SeparableConv2D(64, kernel_size=(5, 5), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:25: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, kernel_size=(1, 1), activation=\"relu\", data_format=\"channels_first\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7277 samples, validate on 3639 samples\n",
      "Epoch 1/50\n",
      "7277/7277 [==============================] - 12s 2ms/step - loss: 3.8681 - acc: 0.4591 - val_loss: 3.7393 - val_acc: 0.5279\n",
      "Epoch 2/50\n",
      "7277/7277 [==============================] - 10s 1ms/step - loss: 3.1851 - acc: 0.5993 - val_loss: 3.4116 - val_acc: 0.5664\n",
      "Epoch 3/50\n",
      "7277/7277 [==============================] - 10s 1ms/step - loss: 2.9196 - acc: 0.6596 - val_loss: 3.0673 - val_acc: 0.6417\n",
      "Epoch 4/50\n",
      "7277/7277 [==============================] - 10s 1ms/step - loss: 1.9776 - acc: 0.6875 - val_loss: 1.8628 - val_acc: 0.7049\n",
      "Epoch 5/50\n",
      "7277/7277 [==============================] - 10s 1ms/step - loss: 1.5307 - acc: 0.7698 - val_loss: 1.4237 - val_acc: 0.8145\n",
      "Epoch 6/50\n",
      "7277/7277 [==============================] - 10s 1ms/step - loss: 1.4489 - acc: 0.7988 - val_loss: 1.3310 - val_acc: 0.8483\n",
      "Epoch 7/50\n",
      "7277/7277 [==============================] - 10s 1ms/step - loss: 1.3998 - acc: 0.8113 - val_loss: 1.4103 - val_acc: 0.8206\n",
      "Epoch 8/50\n",
      "7277/7277 [==============================] - 10s 1ms/step - loss: 1.3401 - acc: 0.8377 - val_loss: 1.3148 - val_acc: 0.8568\n",
      "Epoch 9/50\n",
      "7277/7277 [==============================] - 10s 1ms/step - loss: 1.2957 - acc: 0.8571 - val_loss: 1.3739 - val_acc: 0.8384\n",
      "Epoch 10/50\n",
      "7277/7277 [==============================] - 10s 1ms/step - loss: 1.2908 - acc: 0.8613 - val_loss: 1.2853 - val_acc: 0.8678\n",
      "Epoch 11/50\n",
      "7277/7277 [==============================] - 10s 1ms/step - loss: 1.2362 - acc: 0.8730 - val_loss: 1.2228 - val_acc: 0.8912\n",
      "Epoch 12/50\n",
      "7277/7277 [==============================] - 10s 1ms/step - loss: 0.5027 - acc: 0.8965 - val_loss: 0.2142 - val_acc: 0.9288\n",
      "Epoch 13/50\n",
      "7277/7277 [==============================] - 10s 1ms/step - loss: 0.2557 - acc: 0.9180 - val_loss: 0.1685 - val_acc: 0.9461\n",
      "Epoch 14/50\n",
      "7277/7277 [==============================] - 10s 1ms/step - loss: 0.2363 - acc: 0.9257 - val_loss: 0.6757 - val_acc: 0.8489\n",
      "Epoch 15/50\n",
      "7277/7277 [==============================] - 10s 1ms/step - loss: 0.2094 - acc: 0.9328 - val_loss: 0.1153 - val_acc: 0.9593\n",
      "Epoch 16/50\n",
      "7277/7277 [==============================] - 10s 1ms/step - loss: 0.1397 - acc: 0.9541 - val_loss: 0.0591 - val_acc: 0.9819\n",
      "Epoch 17/50\n",
      "7277/7277 [==============================] - 10s 1ms/step - loss: 0.1143 - acc: 0.9621 - val_loss: 0.1462 - val_acc: 0.9497\n",
      "Epoch 18/50\n",
      "7277/7277 [==============================] - 10s 1ms/step - loss: 0.1186 - acc: 0.9608 - val_loss: 0.0726 - val_acc: 0.9731\n",
      "Epoch 19/50\n",
      "7277/7277 [==============================] - 10s 1ms/step - loss: 0.1179 - acc: 0.9599 - val_loss: 0.0849 - val_acc: 0.9698\n",
      "Epoch 20/50\n",
      "7277/7277 [==============================] - 10s 1ms/step - loss: 0.1193 - acc: 0.9603 - val_loss: 0.0488 - val_acc: 0.9824\n",
      "Epoch 21/50\n",
      "7277/7277 [==============================] - 10s 1ms/step - loss: 0.1275 - acc: 0.9628 - val_loss: 0.0958 - val_acc: 0.9667\n",
      "Epoch 22/50\n",
      "7277/7277 [==============================] - 10s 1ms/step - loss: 0.0967 - acc: 0.9680 - val_loss: 0.0437 - val_acc: 0.9849\n",
      "Epoch 23/50\n",
      "7277/7277 [==============================] - 10s 1ms/step - loss: 0.0728 - acc: 0.9744 - val_loss: 0.0310 - val_acc: 0.9901\n",
      "Epoch 24/50\n",
      "7277/7277 [==============================] - 10s 1ms/step - loss: 0.0919 - acc: 0.9687 - val_loss: 0.1125 - val_acc: 0.9656\n",
      "Epoch 25/50\n",
      "7277/7277 [==============================] - 10s 1ms/step - loss: 0.1189 - acc: 0.9610 - val_loss: 0.0658 - val_acc: 0.9764\n",
      "Epoch 26/50\n",
      "7277/7277 [==============================] - 10s 1ms/step - loss: 0.0773 - acc: 0.9749 - val_loss: 0.0169 - val_acc: 0.9940\n",
      "Epoch 27/50\n",
      "7277/7277 [==============================] - 10s 1ms/step - loss: 0.0715 - acc: 0.9757 - val_loss: 0.0484 - val_acc: 0.9849\n",
      "Epoch 28/50\n",
      "7277/7277 [==============================] - 10s 1ms/step - loss: 0.0673 - acc: 0.9792 - val_loss: 0.0833 - val_acc: 0.9764\n",
      "Epoch 29/50\n",
      "7277/7277 [==============================] - 10s 1ms/step - loss: 0.0563 - acc: 0.9808 - val_loss: 0.0319 - val_acc: 0.9879\n",
      "Epoch 30/50\n",
      "7277/7277 [==============================] - 10s 1ms/step - loss: 0.0542 - acc: 0.9831 - val_loss: 0.0554 - val_acc: 0.9830\n",
      "Epoch 31/50\n",
      "7277/7277 [==============================] - 10s 1ms/step - loss: 0.0640 - acc: 0.9787 - val_loss: 0.0308 - val_acc: 0.9876\n",
      "Epoch 32/50\n",
      "7277/7277 [==============================] - 10s 1ms/step - loss: 0.0656 - acc: 0.9776 - val_loss: 0.0793 - val_acc: 0.9744\n",
      "Epoch 33/50\n",
      "7277/7277 [==============================] - 10s 1ms/step - loss: 0.0482 - acc: 0.9845 - val_loss: 0.0321 - val_acc: 0.9890\n",
      "Epoch 34/50\n",
      "7277/7277 [==============================] - 10s 1ms/step - loss: 0.0492 - acc: 0.9838 - val_loss: 0.0392 - val_acc: 0.9874\n",
      "Epoch 35/50\n",
      "7277/7277 [==============================] - 10s 1ms/step - loss: 0.0730 - acc: 0.9768 - val_loss: 0.0590 - val_acc: 0.9808\n",
      "Epoch 36/50\n",
      "7277/7277 [==============================] - 10s 1ms/step - loss: 0.0965 - acc: 0.9700 - val_loss: 0.0214 - val_acc: 0.9934\n",
      "Epoch 37/50\n",
      "7277/7277 [==============================] - 10s 1ms/step - loss: 0.0542 - acc: 0.9832 - val_loss: 0.0525 - val_acc: 0.9838\n",
      "Epoch 38/50\n",
      "7277/7277 [==============================] - 10s 1ms/step - loss: 0.0559 - acc: 0.9817 - val_loss: 0.0890 - val_acc: 0.9700\n",
      "Epoch 39/50\n",
      "7277/7277 [==============================] - 10s 1ms/step - loss: 0.0699 - acc: 0.9787 - val_loss: 0.0167 - val_acc: 0.9937\n",
      "Epoch 40/50\n",
      "7277/7277 [==============================] - 10s 1ms/step - loss: 0.0479 - acc: 0.9816 - val_loss: 0.0179 - val_acc: 0.9934\n",
      "Epoch 41/50\n",
      "7277/7277 [==============================] - 10s 1ms/step - loss: 0.0405 - acc: 0.9876 - val_loss: 0.0204 - val_acc: 0.9926\n",
      "Epoch 42/50\n",
      "7277/7277 [==============================] - 10s 1ms/step - loss: 0.0326 - acc: 0.9907 - val_loss: 0.0305 - val_acc: 0.9871\n",
      "Epoch 43/50\n",
      "7277/7277 [==============================] - 10s 1ms/step - loss: 0.0405 - acc: 0.9882 - val_loss: 0.0081 - val_acc: 0.9967\n",
      "Epoch 44/50\n",
      "7277/7277 [==============================] - 10s 1ms/step - loss: 0.0296 - acc: 0.9902 - val_loss: 0.0139 - val_acc: 0.9951\n",
      "Epoch 45/50\n",
      "7277/7277 [==============================] - 10s 1ms/step - loss: 0.0505 - acc: 0.9849 - val_loss: 0.0492 - val_acc: 0.9868\n",
      "Epoch 46/50\n",
      "7277/7277 [==============================] - 10s 1ms/step - loss: 0.0339 - acc: 0.9887 - val_loss: 0.0386 - val_acc: 0.9860\n",
      "Epoch 47/50\n",
      "7277/7277 [==============================] - 10s 1ms/step - loss: 0.0437 - acc: 0.9861 - val_loss: 0.0275 - val_acc: 0.9915\n",
      "Epoch 48/50\n",
      "7277/7277 [==============================] - 10s 1ms/step - loss: 0.0279 - acc: 0.9913 - val_loss: 0.0151 - val_acc: 0.9948\n",
      "Epoch 49/50\n",
      "7277/7277 [==============================] - 10s 1ms/step - loss: 0.0270 - acc: 0.9907 - val_loss: 0.0103 - val_acc: 0.9967\n",
      "Epoch 50/50\n",
      "7277/7277 [==============================] - 10s 1ms/step - loss: 0.0343 - acc: 0.9885 - val_loss: 0.0240 - val_acc: 0.9909\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7f2beef5bef0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depth_Seprable_cnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:55: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:56: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(30, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:57: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(9, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:58: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(30, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:59: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(11, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:60: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(30, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:61: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:62: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(30, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:63: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:64: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(30, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:65: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(11, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:66: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(30, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:67: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(45, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7277 samples, validate on 3639 samples\n",
      "Epoch 1/50\n",
      "7277/7277 [==============================] - 8s 1ms/step - loss: 1.2331 - acc: 0.3945 - val_loss: 1.1772 - val_acc: 0.4520\n",
      "Epoch 2/50\n",
      "7277/7277 [==============================] - 5s 726us/step - loss: 1.0671 - acc: 0.4965 - val_loss: 0.9838 - val_acc: 0.5567\n",
      "Epoch 3/50\n",
      "7277/7277 [==============================] - 5s 728us/step - loss: 0.9389 - acc: 0.5758 - val_loss: 0.8843 - val_acc: 0.6018\n",
      "Epoch 4/50\n",
      "7277/7277 [==============================] - 5s 730us/step - loss: 0.8477 - acc: 0.6266 - val_loss: 0.8315 - val_acc: 0.6364\n",
      "Epoch 5/50\n",
      "7277/7277 [==============================] - 5s 727us/step - loss: 0.7686 - acc: 0.6782 - val_loss: 0.7639 - val_acc: 0.6834\n",
      "Epoch 6/50\n",
      "7277/7277 [==============================] - 5s 728us/step - loss: 0.7096 - acc: 0.7197 - val_loss: 0.7016 - val_acc: 0.7230\n",
      "Epoch 7/50\n",
      "7277/7277 [==============================] - 5s 727us/step - loss: 0.6571 - acc: 0.7477 - val_loss: 0.6349 - val_acc: 0.7595\n",
      "Epoch 8/50\n",
      "7277/7277 [==============================] - 5s 730us/step - loss: 0.5883 - acc: 0.7800 - val_loss: 0.5167 - val_acc: 0.8140\n",
      "Epoch 9/50\n",
      "7277/7277 [==============================] - 5s 730us/step - loss: 0.4900 - acc: 0.8205 - val_loss: 0.4394 - val_acc: 0.8296\n",
      "Epoch 10/50\n",
      "7277/7277 [==============================] - 5s 730us/step - loss: 0.4616 - acc: 0.8310 - val_loss: 0.3822 - val_acc: 0.8612\n",
      "Epoch 11/50\n",
      "7277/7277 [==============================] - 5s 727us/step - loss: 0.4066 - acc: 0.8556 - val_loss: 0.4436 - val_acc: 0.8285\n",
      "Epoch 12/50\n",
      "7277/7277 [==============================] - 5s 731us/step - loss: 0.3616 - acc: 0.8678 - val_loss: 0.3194 - val_acc: 0.8763\n",
      "Epoch 13/50\n",
      "7277/7277 [==============================] - 5s 733us/step - loss: 0.3243 - acc: 0.8832 - val_loss: 0.2823 - val_acc: 0.8961\n",
      "Epoch 14/50\n",
      "7277/7277 [==============================] - 5s 734us/step - loss: 0.3006 - acc: 0.8920 - val_loss: 0.2521 - val_acc: 0.9093\n",
      "Epoch 15/50\n",
      "7277/7277 [==============================] - 5s 731us/step - loss: 0.2579 - acc: 0.9100 - val_loss: 0.2358 - val_acc: 0.9148\n",
      "Epoch 16/50\n",
      "7277/7277 [==============================] - 5s 729us/step - loss: 0.2808 - acc: 0.8989 - val_loss: 0.2213 - val_acc: 0.9233\n",
      "Epoch 17/50\n",
      "7277/7277 [==============================] - 5s 730us/step - loss: 0.2418 - acc: 0.9160 - val_loss: 0.2047 - val_acc: 0.9239\n",
      "Epoch 18/50\n",
      "7277/7277 [==============================] - 5s 727us/step - loss: 0.2133 - acc: 0.9230 - val_loss: 0.1556 - val_acc: 0.9437\n",
      "Epoch 19/50\n",
      "7277/7277 [==============================] - 5s 727us/step - loss: 0.1982 - acc: 0.9284 - val_loss: 0.1909 - val_acc: 0.9316\n",
      "Epoch 20/50\n",
      "7277/7277 [==============================] - 5s 727us/step - loss: 0.1844 - acc: 0.9364 - val_loss: 0.1625 - val_acc: 0.9415\n",
      "Epoch 21/50\n",
      "7277/7277 [==============================] - 5s 729us/step - loss: 0.1799 - acc: 0.9376 - val_loss: 0.1570 - val_acc: 0.9450\n",
      "Epoch 22/50\n",
      "7277/7277 [==============================] - 5s 727us/step - loss: 0.1700 - acc: 0.9405 - val_loss: 0.1554 - val_acc: 0.9467\n",
      "Epoch 23/50\n",
      "7277/7277 [==============================] - 5s 727us/step - loss: 0.1560 - acc: 0.9424 - val_loss: 0.1453 - val_acc: 0.9486\n",
      "Epoch 24/50\n",
      "7277/7277 [==============================] - 5s 730us/step - loss: 0.1484 - acc: 0.9474 - val_loss: 0.1784 - val_acc: 0.9354\n",
      "Epoch 25/50\n",
      "7277/7277 [==============================] - 5s 730us/step - loss: 0.1386 - acc: 0.9504 - val_loss: 0.1257 - val_acc: 0.9558\n",
      "Epoch 26/50\n",
      "7277/7277 [==============================] - 5s 727us/step - loss: 0.1301 - acc: 0.9552 - val_loss: 0.1690 - val_acc: 0.9406\n",
      "Epoch 27/50\n",
      "7277/7277 [==============================] - 5s 728us/step - loss: 0.1443 - acc: 0.9493 - val_loss: 0.1217 - val_acc: 0.9610\n",
      "Epoch 28/50\n",
      "7277/7277 [==============================] - 5s 726us/step - loss: 0.1291 - acc: 0.9556 - val_loss: 0.0878 - val_acc: 0.9720\n",
      "Epoch 29/50\n",
      "7277/7277 [==============================] - 5s 727us/step - loss: 0.1543 - acc: 0.9453 - val_loss: 0.1254 - val_acc: 0.9569\n",
      "Epoch 30/50\n",
      "7277/7277 [==============================] - 5s 725us/step - loss: 0.1232 - acc: 0.9534 - val_loss: 0.0828 - val_acc: 0.9706\n",
      "Epoch 31/50\n",
      "7277/7277 [==============================] - 5s 726us/step - loss: 0.1001 - acc: 0.9628 - val_loss: 0.0848 - val_acc: 0.9731\n",
      "Epoch 32/50\n",
      "7277/7277 [==============================] - 5s 726us/step - loss: 0.1200 - acc: 0.9584 - val_loss: 0.1080 - val_acc: 0.9659\n",
      "Epoch 33/50\n",
      "7277/7277 [==============================] - 5s 726us/step - loss: 0.0963 - acc: 0.9699 - val_loss: 0.0691 - val_acc: 0.9769\n",
      "Epoch 34/50\n",
      "7277/7277 [==============================] - 5s 724us/step - loss: 0.1203 - acc: 0.9597 - val_loss: 0.1396 - val_acc: 0.9519\n",
      "Epoch 35/50\n",
      "7277/7277 [==============================] - 5s 730us/step - loss: 0.1052 - acc: 0.9632 - val_loss: 0.0672 - val_acc: 0.9783\n",
      "Epoch 36/50\n",
      "7277/7277 [==============================] - 5s 738us/step - loss: 0.0937 - acc: 0.9670 - val_loss: 0.0874 - val_acc: 0.9722\n",
      "Epoch 37/50\n",
      "7277/7277 [==============================] - 5s 724us/step - loss: 0.0985 - acc: 0.9663 - val_loss: 0.0634 - val_acc: 0.9805\n",
      "Epoch 38/50\n",
      "7277/7277 [==============================] - 5s 729us/step - loss: 0.0822 - acc: 0.9687 - val_loss: 0.0615 - val_acc: 0.9788\n",
      "Epoch 39/50\n",
      "7277/7277 [==============================] - 5s 732us/step - loss: 0.0698 - acc: 0.9768 - val_loss: 0.0615 - val_acc: 0.9797\n",
      "Epoch 40/50\n",
      "7277/7277 [==============================] - 5s 737us/step - loss: 0.1106 - acc: 0.9622 - val_loss: 0.2140 - val_acc: 0.9258\n",
      "Epoch 41/50\n",
      "7277/7277 [==============================] - 5s 724us/step - loss: 0.1105 - acc: 0.9615 - val_loss: 0.0509 - val_acc: 0.9827\n",
      "Epoch 42/50\n",
      "7277/7277 [==============================] - 5s 725us/step - loss: 0.0687 - acc: 0.9758 - val_loss: 0.0614 - val_acc: 0.9791\n",
      "Epoch 43/50\n",
      "7277/7277 [==============================] - 5s 727us/step - loss: 0.0620 - acc: 0.9771 - val_loss: 0.0474 - val_acc: 0.9827\n",
      "Epoch 44/50\n",
      "7277/7277 [==============================] - 5s 724us/step - loss: 0.0710 - acc: 0.9773 - val_loss: 0.0989 - val_acc: 0.9604\n",
      "Epoch 45/50\n",
      "7277/7277 [==============================] - 5s 723us/step - loss: 0.0666 - acc: 0.9775 - val_loss: 0.0691 - val_acc: 0.9755\n",
      "Epoch 46/50\n",
      "7277/7277 [==============================] - 5s 727us/step - loss: 0.0781 - acc: 0.9746 - val_loss: 0.0531 - val_acc: 0.9832\n",
      "Epoch 47/50\n",
      "7277/7277 [==============================] - 5s 724us/step - loss: 0.0671 - acc: 0.9761 - val_loss: 0.0601 - val_acc: 0.9821\n",
      "Epoch 48/50\n",
      "7277/7277 [==============================] - 5s 723us/step - loss: 0.0725 - acc: 0.9769 - val_loss: 0.0644 - val_acc: 0.9786\n",
      "Epoch 49/50\n",
      "7277/7277 [==============================] - 5s 725us/step - loss: 0.0548 - acc: 0.9809 - val_loss: 0.0478 - val_acc: 0.9854\n",
      "Epoch 50/50\n",
      "7277/7277 [==============================] - 5s 726us/step - loss: 0.0745 - acc: 0.9754 - val_loss: 0.0647 - val_acc: 0.9791\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7f2bec9efcc0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edgespeechnetb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:20: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(30, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:21: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(45, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:22: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(33, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:23: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(45, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:24: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(35, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:25: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(45, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7277 samples, validate on 3639 samples\n",
      "Epoch 1/50\n",
      "7277/7277 [==============================] - 8s 1ms/step - loss: 1.2200 - acc: 0.4124 - val_loss: 1.0442 - val_acc: 0.5128\n",
      "Epoch 2/50\n",
      "7277/7277 [==============================] - 6s 791us/step - loss: 0.9680 - acc: 0.5629 - val_loss: 0.8376 - val_acc: 0.6183\n",
      "Epoch 3/50\n",
      "7277/7277 [==============================] - 6s 794us/step - loss: 0.8434 - acc: 0.6424 - val_loss: 0.6888 - val_acc: 0.7345\n",
      "Epoch 4/50\n",
      "7277/7277 [==============================] - 6s 794us/step - loss: 0.6857 - acc: 0.7370 - val_loss: 0.5611 - val_acc: 0.7862\n",
      "Epoch 5/50\n",
      "7277/7277 [==============================] - 6s 800us/step - loss: 0.5519 - acc: 0.7947 - val_loss: 0.5102 - val_acc: 0.7903\n",
      "Epoch 6/50\n",
      "7277/7277 [==============================] - 6s 801us/step - loss: 0.4444 - acc: 0.8339 - val_loss: 0.4226 - val_acc: 0.8392\n",
      "Epoch 7/50\n",
      "7277/7277 [==============================] - 6s 794us/step - loss: 0.3872 - acc: 0.8600 - val_loss: 0.3400 - val_acc: 0.8796\n",
      "Epoch 8/50\n",
      "7277/7277 [==============================] - 6s 792us/step - loss: 0.3209 - acc: 0.8846 - val_loss: 0.2873 - val_acc: 0.8983\n",
      "Epoch 9/50\n",
      "7277/7277 [==============================] - 6s 795us/step - loss: 0.2776 - acc: 0.8978 - val_loss: 0.2237 - val_acc: 0.9211\n",
      "Epoch 10/50\n",
      "7277/7277 [==============================] - 6s 793us/step - loss: 0.2233 - acc: 0.9195 - val_loss: 0.1780 - val_acc: 0.9371\n",
      "Epoch 11/50\n",
      "7277/7277 [==============================] - 6s 791us/step - loss: 0.2155 - acc: 0.9221 - val_loss: 0.1973 - val_acc: 0.9349\n",
      "Epoch 12/50\n",
      "7277/7277 [==============================] - 6s 792us/step - loss: 0.1975 - acc: 0.9283 - val_loss: 0.1689 - val_acc: 0.9412\n",
      "Epoch 13/50\n",
      "7277/7277 [==============================] - 6s 790us/step - loss: 0.1547 - acc: 0.9437 - val_loss: 0.1598 - val_acc: 0.9412\n",
      "Epoch 14/50\n",
      "7277/7277 [==============================] - 6s 792us/step - loss: 0.1625 - acc: 0.9415 - val_loss: 0.1435 - val_acc: 0.9489\n",
      "Epoch 15/50\n",
      "7277/7277 [==============================] - 6s 790us/step - loss: 0.1588 - acc: 0.9449 - val_loss: 0.1386 - val_acc: 0.9516\n",
      "Epoch 16/50\n",
      "7277/7277 [==============================] - 6s 792us/step - loss: 0.1391 - acc: 0.9504 - val_loss: 0.0997 - val_acc: 0.9681\n",
      "Epoch 17/50\n",
      "7277/7277 [==============================] - 6s 794us/step - loss: 0.1218 - acc: 0.9614 - val_loss: 0.0987 - val_acc: 0.9640\n",
      "Epoch 18/50\n",
      "7277/7277 [==============================] - 6s 794us/step - loss: 0.1128 - acc: 0.9582 - val_loss: 0.1036 - val_acc: 0.9676\n",
      "Epoch 19/50\n",
      "7277/7277 [==============================] - 6s 799us/step - loss: 0.1012 - acc: 0.9622 - val_loss: 0.1351 - val_acc: 0.9530\n",
      "Epoch 20/50\n",
      "7277/7277 [==============================] - 6s 790us/step - loss: 0.0970 - acc: 0.9667 - val_loss: 0.0882 - val_acc: 0.9665\n",
      "Epoch 21/50\n",
      "7277/7277 [==============================] - 6s 793us/step - loss: 0.0917 - acc: 0.9691 - val_loss: 0.0769 - val_acc: 0.9747\n",
      "Epoch 22/50\n",
      "7277/7277 [==============================] - 6s 792us/step - loss: 0.0934 - acc: 0.9689 - val_loss: 0.0455 - val_acc: 0.9852\n",
      "Epoch 23/50\n",
      "7277/7277 [==============================] - 6s 795us/step - loss: 0.0718 - acc: 0.9757 - val_loss: 0.0490 - val_acc: 0.9849\n",
      "Epoch 24/50\n",
      "7277/7277 [==============================] - 6s 794us/step - loss: 0.0663 - acc: 0.9760 - val_loss: 0.0607 - val_acc: 0.9813\n",
      "Epoch 25/50\n",
      "7277/7277 [==============================] - 6s 792us/step - loss: 0.0707 - acc: 0.9761 - val_loss: 0.0762 - val_acc: 0.9753\n",
      "Epoch 26/50\n",
      "7277/7277 [==============================] - 6s 793us/step - loss: 0.0620 - acc: 0.9783 - val_loss: 0.0633 - val_acc: 0.9794\n",
      "Epoch 27/50\n",
      "7277/7277 [==============================] - 6s 796us/step - loss: 0.0644 - acc: 0.9777 - val_loss: 0.0525 - val_acc: 0.9827\n",
      "Epoch 28/50\n",
      "7277/7277 [==============================] - 6s 795us/step - loss: 0.0619 - acc: 0.9784 - val_loss: 0.0993 - val_acc: 0.9646\n",
      "Epoch 29/50\n",
      "7277/7277 [==============================] - 6s 795us/step - loss: 0.0619 - acc: 0.9777 - val_loss: 0.0473 - val_acc: 0.9846\n",
      "Epoch 30/50\n",
      "7277/7277 [==============================] - 6s 796us/step - loss: 0.0675 - acc: 0.9765 - val_loss: 0.0378 - val_acc: 0.9896\n",
      "Epoch 31/50\n",
      "7277/7277 [==============================] - 6s 799us/step - loss: 0.0476 - acc: 0.9843 - val_loss: 0.0441 - val_acc: 0.9857\n",
      "Epoch 32/50\n",
      "7277/7277 [==============================] - 6s 793us/step - loss: 0.0488 - acc: 0.9832 - val_loss: 0.0520 - val_acc: 0.9852\n",
      "Epoch 33/50\n",
      "7277/7277 [==============================] - 6s 794us/step - loss: 0.0607 - acc: 0.9802 - val_loss: 0.0454 - val_acc: 0.9857\n",
      "Epoch 34/50\n",
      "7277/7277 [==============================] - 6s 793us/step - loss: 0.0514 - acc: 0.9824 - val_loss: 0.0503 - val_acc: 0.9824\n",
      "Epoch 35/50\n",
      "7277/7277 [==============================] - 6s 792us/step - loss: 0.0699 - acc: 0.9768 - val_loss: 0.0452 - val_acc: 0.9838\n",
      "Epoch 36/50\n",
      "7277/7277 [==============================] - 6s 795us/step - loss: 0.0466 - acc: 0.9839 - val_loss: 0.0278 - val_acc: 0.9904\n",
      "Epoch 37/50\n",
      "7277/7277 [==============================] - 6s 792us/step - loss: 0.0381 - acc: 0.9863 - val_loss: 0.0298 - val_acc: 0.9904\n",
      "Epoch 38/50\n",
      "7277/7277 [==============================] - 6s 794us/step - loss: 0.0645 - acc: 0.9775 - val_loss: 0.0268 - val_acc: 0.9937\n",
      "Epoch 39/50\n",
      "7277/7277 [==============================] - 6s 793us/step - loss: 0.0270 - acc: 0.9919 - val_loss: 0.0286 - val_acc: 0.9896\n",
      "Epoch 40/50\n",
      "7277/7277 [==============================] - 6s 795us/step - loss: 0.0315 - acc: 0.9890 - val_loss: 0.0718 - val_acc: 0.9786\n",
      "Epoch 41/50\n",
      "7277/7277 [==============================] - 6s 799us/step - loss: 0.0460 - acc: 0.9850 - val_loss: 0.0224 - val_acc: 0.9937\n",
      "Epoch 42/50\n",
      "7277/7277 [==============================] - 6s 800us/step - loss: 0.0313 - acc: 0.9896 - val_loss: 0.0441 - val_acc: 0.9863\n",
      "Epoch 43/50\n",
      "7277/7277 [==============================] - 6s 794us/step - loss: 0.0473 - acc: 0.9852 - val_loss: 0.0225 - val_acc: 0.9937\n",
      "Epoch 44/50\n",
      "7277/7277 [==============================] - 6s 796us/step - loss: 0.0424 - acc: 0.9846 - val_loss: 0.0364 - val_acc: 0.9912\n",
      "Epoch 45/50\n",
      "7277/7277 [==============================] - 6s 798us/step - loss: 0.0320 - acc: 0.9894 - val_loss: 0.0251 - val_acc: 0.9912\n",
      "Epoch 46/50\n",
      "7277/7277 [==============================] - 6s 793us/step - loss: 0.0412 - acc: 0.9863 - val_loss: 0.0304 - val_acc: 0.9907\n",
      "Epoch 47/50\n",
      "7277/7277 [==============================] - 6s 797us/step - loss: 0.0307 - acc: 0.9896 - val_loss: 0.0258 - val_acc: 0.9920\n",
      "Epoch 48/50\n",
      "7277/7277 [==============================] - 6s 801us/step - loss: 0.0286 - acc: 0.9905 - val_loss: 0.0142 - val_acc: 0.9962\n",
      "Epoch 49/50\n",
      "7277/7277 [==============================] - 6s 795us/step - loss: 0.0352 - acc: 0.9891 - val_loss: 0.0247 - val_acc: 0.9918\n",
      "Epoch 50/50\n",
      "7277/7277 [==============================] - 6s 798us/step - loss: 0.0179 - acc: 0.9945 - val_loss: 0.0229 - val_acc: 0.9931\n"
     ]
    }
   ],
   "source": [
    "md = edgespeechnetd() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:20: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:22: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, kernel_size=(10, 4), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:23: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7277 samples, validate on 3639 samples\n",
      "Epoch 1/50\n",
      "7277/7277 [==============================] - 8s 1ms/step - loss: 1.2703 - acc: 0.3901 - val_loss: 1.0834 - val_acc: 0.4798\n",
      "Epoch 2/50\n",
      "7277/7277 [==============================] - 6s 826us/step - loss: 1.0297 - acc: 0.5181 - val_loss: 0.9829 - val_acc: 0.5518\n",
      "Epoch 3/50\n",
      "7277/7277 [==============================] - 6s 825us/step - loss: 0.9509 - acc: 0.5754 - val_loss: 0.8098 - val_acc: 0.6529\n",
      "Epoch 4/50\n",
      "7277/7277 [==============================] - 6s 826us/step - loss: 0.8437 - acc: 0.6486 - val_loss: 0.7185 - val_acc: 0.6928\n",
      "Epoch 5/50\n",
      "7277/7277 [==============================] - 6s 824us/step - loss: 0.7264 - acc: 0.7015 - val_loss: 0.6188 - val_acc: 0.7420\n",
      "Epoch 6/50\n",
      "7277/7277 [==============================] - 6s 826us/step - loss: 0.6216 - acc: 0.7579 - val_loss: 0.4975 - val_acc: 0.8206\n",
      "Epoch 7/50\n",
      "7277/7277 [==============================] - 6s 839us/step - loss: 0.5312 - acc: 0.8034 - val_loss: 0.3866 - val_acc: 0.8673\n",
      "Epoch 8/50\n",
      "7277/7277 [==============================] - 6s 832us/step - loss: 0.4651 - acc: 0.8270 - val_loss: 0.3631 - val_acc: 0.8725\n",
      "Epoch 9/50\n",
      "7277/7277 [==============================] - 6s 830us/step - loss: 0.4511 - acc: 0.8285 - val_loss: 0.3730 - val_acc: 0.8662\n",
      "Epoch 10/50\n",
      "7277/7277 [==============================] - 6s 824us/step - loss: 0.4071 - acc: 0.8510 - val_loss: 0.3009 - val_acc: 0.8895\n",
      "Epoch 11/50\n",
      "7277/7277 [==============================] - 6s 824us/step - loss: 0.3877 - acc: 0.8561 - val_loss: 0.2838 - val_acc: 0.9002\n",
      "Epoch 12/50\n",
      "7277/7277 [==============================] - 6s 826us/step - loss: 0.3695 - acc: 0.8633 - val_loss: 0.2429 - val_acc: 0.9151\n",
      "Epoch 13/50\n",
      "7277/7277 [==============================] - 6s 825us/step - loss: 0.3531 - acc: 0.8701 - val_loss: 0.2147 - val_acc: 0.9231\n",
      "Epoch 14/50\n",
      "7277/7277 [==============================] - 6s 826us/step - loss: 0.3199 - acc: 0.8839 - val_loss: 0.2124 - val_acc: 0.9209\n",
      "Epoch 15/50\n",
      "7277/7277 [==============================] - 6s 825us/step - loss: 0.3070 - acc: 0.8875 - val_loss: 0.1866 - val_acc: 0.9351\n",
      "Epoch 16/50\n",
      "7277/7277 [==============================] - 6s 828us/step - loss: 0.2851 - acc: 0.8973 - val_loss: 0.1908 - val_acc: 0.9349\n",
      "Epoch 17/50\n",
      "7277/7277 [==============================] - 6s 830us/step - loss: 0.2764 - acc: 0.8993 - val_loss: 0.1811 - val_acc: 0.9428\n",
      "Epoch 18/50\n",
      "7277/7277 [==============================] - 6s 827us/step - loss: 0.2643 - acc: 0.9042 - val_loss: 0.1579 - val_acc: 0.9445\n",
      "Epoch 19/50\n",
      "7277/7277 [==============================] - 6s 832us/step - loss: 0.2514 - acc: 0.9119 - val_loss: 0.1697 - val_acc: 0.9426\n",
      "Epoch 20/50\n",
      "7277/7277 [==============================] - 6s 832us/step - loss: 0.2305 - acc: 0.9148 - val_loss: 0.1368 - val_acc: 0.9563\n",
      "Epoch 21/50\n",
      "7277/7277 [==============================] - 6s 829us/step - loss: 0.2181 - acc: 0.9224 - val_loss: 0.1199 - val_acc: 0.9599\n",
      "Epoch 22/50\n",
      "7277/7277 [==============================] - 6s 827us/step - loss: 0.2036 - acc: 0.9283 - val_loss: 0.1373 - val_acc: 0.9577\n",
      "Epoch 23/50\n",
      "7277/7277 [==============================] - 6s 825us/step - loss: 0.2100 - acc: 0.9265 - val_loss: 0.1242 - val_acc: 0.9582\n",
      "Epoch 24/50\n",
      "7277/7277 [==============================] - 6s 825us/step - loss: 0.1992 - acc: 0.9291 - val_loss: 0.1097 - val_acc: 0.9646\n",
      "Epoch 25/50\n",
      "7277/7277 [==============================] - 6s 824us/step - loss: 0.1754 - acc: 0.9394 - val_loss: 0.0898 - val_acc: 0.9722\n",
      "Epoch 26/50\n",
      "7277/7277 [==============================] - 6s 825us/step - loss: 0.1567 - acc: 0.9441 - val_loss: 0.1073 - val_acc: 0.9582\n",
      "Epoch 27/50\n",
      "7277/7277 [==============================] - 6s 826us/step - loss: 0.1577 - acc: 0.9457 - val_loss: 0.0736 - val_acc: 0.9780\n",
      "Epoch 28/50\n",
      "7277/7277 [==============================] - 6s 825us/step - loss: 0.1500 - acc: 0.9481 - val_loss: 0.0842 - val_acc: 0.9728\n",
      "Epoch 29/50\n",
      "7277/7277 [==============================] - 6s 828us/step - loss: 0.1553 - acc: 0.9467 - val_loss: 0.0680 - val_acc: 0.9830\n",
      "Epoch 30/50\n",
      "7277/7277 [==============================] - 6s 826us/step - loss: 0.1558 - acc: 0.9439 - val_loss: 0.0850 - val_acc: 0.9731\n",
      "Epoch 31/50\n",
      "7277/7277 [==============================] - 6s 828us/step - loss: 0.1360 - acc: 0.9553 - val_loss: 0.0635 - val_acc: 0.9835\n",
      "Epoch 32/50\n",
      "7277/7277 [==============================] - 6s 827us/step - loss: 0.1395 - acc: 0.9537 - val_loss: 0.0615 - val_acc: 0.9824\n",
      "Epoch 33/50\n",
      "7277/7277 [==============================] - 6s 828us/step - loss: 0.1362 - acc: 0.9514 - val_loss: 0.0636 - val_acc: 0.9816\n",
      "Epoch 34/50\n",
      "7277/7277 [==============================] - 6s 829us/step - loss: 0.1407 - acc: 0.9507 - val_loss: 0.0502 - val_acc: 0.9868\n",
      "Epoch 35/50\n",
      "7277/7277 [==============================] - 6s 825us/step - loss: 0.1654 - acc: 0.9426 - val_loss: 0.0623 - val_acc: 0.9843\n",
      "Epoch 36/50\n",
      "7277/7277 [==============================] - 6s 829us/step - loss: 0.1274 - acc: 0.9534 - val_loss: 0.0430 - val_acc: 0.9896\n",
      "Epoch 37/50\n",
      "7277/7277 [==============================] - 6s 830us/step - loss: 0.1135 - acc: 0.9600 - val_loss: 0.0508 - val_acc: 0.9827\n",
      "Epoch 38/50\n",
      "7277/7277 [==============================] - 6s 826us/step - loss: 0.1252 - acc: 0.9575 - val_loss: 0.0464 - val_acc: 0.9868\n",
      "Epoch 39/50\n",
      "7277/7277 [==============================] - 6s 829us/step - loss: 0.1245 - acc: 0.9566 - val_loss: 0.0525 - val_acc: 0.9821\n",
      "Epoch 40/50\n",
      "7277/7277 [==============================] - 6s 826us/step - loss: 0.1050 - acc: 0.9639 - val_loss: 0.0460 - val_acc: 0.9849\n",
      "Epoch 41/50\n",
      "7277/7277 [==============================] - 6s 833us/step - loss: 0.1125 - acc: 0.9634 - val_loss: 0.0362 - val_acc: 0.9904\n",
      "Epoch 42/50\n",
      "7277/7277 [==============================] - 6s 826us/step - loss: 0.0947 - acc: 0.9652 - val_loss: 0.0447 - val_acc: 0.9863\n",
      "Epoch 43/50\n",
      "7277/7277 [==============================] - 6s 825us/step - loss: 0.1195 - acc: 0.9593 - val_loss: 0.0439 - val_acc: 0.9860\n",
      "Epoch 44/50\n",
      "7277/7277 [==============================] - 6s 825us/step - loss: 0.1007 - acc: 0.9655 - val_loss: 0.0288 - val_acc: 0.9896\n",
      "Epoch 45/50\n",
      "7277/7277 [==============================] - 6s 825us/step - loss: 0.1275 - acc: 0.9590 - val_loss: 0.0366 - val_acc: 0.9909\n",
      "Epoch 46/50\n",
      "7277/7277 [==============================] - 6s 826us/step - loss: 0.0877 - acc: 0.9700 - val_loss: 0.0278 - val_acc: 0.9929\n",
      "Epoch 47/50\n",
      "7277/7277 [==============================] - 6s 829us/step - loss: 0.1018 - acc: 0.9677 - val_loss: 0.0319 - val_acc: 0.9893\n",
      "Epoch 48/50\n",
      "7277/7277 [==============================] - 6s 824us/step - loss: 0.0899 - acc: 0.9677 - val_loss: 0.0289 - val_acc: 0.9912\n",
      "Epoch 49/50\n",
      "7277/7277 [==============================] - 6s 827us/step - loss: 0.0925 - acc: 0.9673 - val_loss: 0.0267 - val_acc: 0.9907\n",
      "Epoch 50/50\n",
      "7277/7277 [==============================] - 6s 826us/step - loss: 0.0801 - acc: 0.9733 - val_loss: 0.0229 - val_acc: 0.9945\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "trainable_stft (Melspectrogr (None, 128, 94, 1)        296064    \n",
      "_________________________________________________________________\n",
      "additive_noise_6 (AdditiveNo (None, 128, 94, 1)        0         \n",
      "_________________________________________________________________\n",
      "normalization2d_6 (Normaliza (None, 128, 94, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_43 (Conv2D)           (None, 109, 87, 64)       10304     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 109, 43, 32)       0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 109, 43, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_44 (Conv2D)           (None, 64, 34, 29)        279104    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 64, 17, 14)        0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 64, 17, 14)        0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 15232)             0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               1949824   \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 2,535,812\n",
      "Trainable params: 2,239,748\n",
      "Non-trainable params: 296,064\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7f2bea145518>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__notebook__.ipynb  cnn.h5   dscnn.h5  esnb.h5\tlogs\r\n",
      "__output__.json     crnn.h5  esna.h5   esnd.h5\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int_axis=1 passed but is ignored, str_axis is used instead.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "from keras.utils import CustomObjectScope\n",
    "model = None\n",
    "with CustomObjectScope({'Melspectrogram': Melspectrogram,'Normalization2D': Normalization2D,'AdditiveNoise':AdditiveNoise}):\n",
    "    model = load_model('esna.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pred = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = confusion_matrix(y_val.argmax(axis=1), x_pred.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.multiclass import unique_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n",
      "[[0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(y_val.argmax(axis=1), x_pred.argmax(axis=1), classes=['bacho', 'background', 'help', 'unknown'], normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainig on pretrained models (Speech comand dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -rf models\n",
    "# !git clone \"https://ipuresults:9818484049as@github.com/ipuresults/pretrained.git\" models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ls models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import load_model\n",
    "# from keras.utils import CustomObjectScope\n",
    "# pretrainedmodel = None\n",
    "# with CustomObjectScope({'Melspectrogram': Melspectrogram,'Normalization2D': Normalization2D,'AdditiveNoise':AdditiveNoise}):\n",
    "#     model = load_model('models/tl2.h5')\n",
    "#     print(model.input.op.name)\n",
    "#     print(model.output.op.name)\n",
    "#     model.summary()\n",
    "#     pretrainedmodel = model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorboard_callback = tf.keras.callbacks.TensorBoard(\"logs/tl2\")\n",
    "# pretrainedmodel.compile(loss=keras.losses.categorical_crossentropy,\n",
    "#                   optimizer=keras.optimizers.adam(),metrics=['accuracy'])\n",
    "# pretrainedmodel.fit(X_train, y_train, batch_size=50, epochs=50, verbose=1, validation_data=(X_test, y_test), callbacks=[tensorboard_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
