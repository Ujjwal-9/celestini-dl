{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "import librosa\n",
    "import random\n",
    "\n",
    "# Any results you write to the current directory are saved as output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roll(data):\n",
    "    data_roll = np.roll(data, 5000)\n",
    "    return data_roll\n",
    "def stretch(data, rate=2):\n",
    "    input_length = 16000*3\n",
    "    data = librosa.effects.time_stretch(data, rate)\n",
    "    if len(data)>input_length:\n",
    "        data = data[:input_length]\n",
    "    else:\n",
    "        data = np.pad(data, (0, max(0, input_length - len(data))), \"constant\")\n",
    "\n",
    "    return data\n",
    "\n",
    "def wnoise(data):\n",
    "    wn = np.random.randn(len(data))\n",
    "    data_wn = data + 0.005*wn\n",
    "    return data_wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'dataset'...\r\n",
      "remote: Enumerating objects: 147, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (147/147), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (146/146), done.\u001b[K\r\n",
      "remote: Total 1245 (delta 1), reused 146 (delta 1), pack-reused 1098\u001b[K\r\n",
      "Receiving objects: 100% (1245/1245), 83.34 MiB | 22.49 MiB/s, done.\r\n",
      "Resolving deltas: 100% (40/40), done.\r\n"
     ]
    }
   ],
   "source": [
    "# put dataset in folder named dataset folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def get_all_files(datapath, dataset_type=\"keyword\"):\n",
    "    data_dir = datapath\n",
    "    data = []\n",
    "    all_files = os.listdir(data_dir)\n",
    "    all_files.remove('.DS_Store')\n",
    "    labels = set()\n",
    "    for file in all_files:\n",
    "        filelabels = file.split(\"-\")[:3]\n",
    "        data_dict = {\n",
    "            \"filepath\": data_dir + file,\n",
    "            \"stress\": filelabels[2],\n",
    "            \"environment\": filelabels[1],\n",
    "            \"keyword\":filelabels[0]\n",
    "        }\n",
    "        labels.add(data_dict[dataset_type])\n",
    "        data.append(data_dict)\n",
    "\n",
    "    return data,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "class AudioFeatureDataset():\n",
    "\n",
    "    ''' To create audio dataset\n",
    "        @param dataset_type = ( keyword | stress | environment   )\n",
    "    '''\n",
    "\n",
    "    def __init__(self,datapath, samplingrate=16000, dt=\"keyword\"):\n",
    "        print(dt)\n",
    "        datafiles, labels = get_all_files(datapath,dataset_type=dt)\n",
    "        self.datafiles = datafiles\n",
    "        self.samplingrate = samplingrate\n",
    "        self.target_labels = list(labels)\n",
    "        self.dataset_type = dt\n",
    "\n",
    "    def process(self, file, max_len=16000):\n",
    "        ''' extracts raw audio  and returns samps '''\n",
    "        try:\n",
    "            samps, sr = librosa.load(file, mono=True, sr=None)\n",
    "            pad_len = max_len - samps.shape[0]\n",
    "            if pad_len >= 0:\n",
    "                samps = np.pad(samps, (0, pad_len), 'constant')\n",
    "            return np.array(samps[:max_len])\n",
    "        except:\n",
    "            print(file)\n",
    "\n",
    "    def get_dataset(self, include_background=False):\n",
    "        labels = []\n",
    "        features = []\n",
    "        for file_data in tqdm(self.datafiles):\n",
    "            labels.append(file_data[self.dataset_type])\n",
    "            samps = self.process(file_data[\"filepath\"], self.samplingrate * 3)\n",
    "            features.append(samps)\n",
    "            # with roll\n",
    "            labels.append(file_data[self.dataset_type])\n",
    "            features.append(roll(samps)) \n",
    "            # with strech\n",
    "            labels.append(file_data[self.dataset_type])\n",
    "            features.append(stretch(samps)) \n",
    "            # white noise\n",
    "            labels.append(file_data[self.dataset_type])\n",
    "            features.append(wnoise(samps)) \n",
    "        labels = np.array(labels)\n",
    "        features = np.array(features)\n",
    "        return features, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword\n"
     ]
    }
   ],
   "source": [
    "a = AudioFeatureDataset(datapath=\"dataset/data/\",dt=\"keyword\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1177/1177 [02:15<00:00,  5.10it/s]\n"
     ]
    }
   ],
   "source": [
    "features,labels = a.get_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(features)\n",
    "Y = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "class_weights = class_weight.compute_class_weight('balanced',np.unique(Y),Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4708, 48000)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.reshape(x.shape[0], 1, 16000 * 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "background    1284\n",
      "unknown       1240\n",
      "bacho         1124\n",
      "help          1060\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.Series(Y)\n",
    "target_count = df.value_counts()\n",
    "print(target_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "labelencoder = LabelEncoder()\n",
    "Y = labelencoder.fit_transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def get_train_test(split_ratio=0.7, random_state=42):\n",
    "    return train_test_split(x, Y, test_size= (1 - split_ratio), random_state=random_state, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = get_train_test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\"logs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<!-- JUPYTER_TENSORBOARD_TEST_MARKER -->\n",
       "<script>\n",
       "    const req = {\n",
       "        method: 'POST',\n",
       "        contentType: 'application/json',\n",
       "        body: JSON.stringify({ 'logdir': 'logs' }),\n",
       "        headers: { 'Content-Type': 'application/json' }\n",
       "    };\n",
       "\n",
       "    const baseUrl = Jupyter.notebook.base_url;\n",
       "\n",
       "    fetch(baseUrl + 'api/tensorboard', req)\n",
       "        .then(res => res.json())\n",
       "        .then(res => {\n",
       "            const iframe = document.getElementById('tensorboard-78df6d09-d603-4055-9093-4060de2f15d7');\n",
       "            iframe.src = baseUrl + 'tensorboard/' + res.name;\n",
       "            iframe.style.display = 'block';\n",
       "        });\n",
       "</script>\n",
       "\n",
       "<iframe\n",
       "    id=\"tensorboard-78df6d09-d603-4055-9093-4060de2f15d7\"\n",
       "    style=\"width: 100%; height: 620px; display: none;\"\n",
       "    frameBorder=\"0\">\n",
       "</iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard.notebook\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bacho': 0, 'background': 1, 'help': 2, 'unknown': 3}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_train = labelencoder.fit_transform(y_train)\n",
    "mapping = dict(zip(labelencoder.classes_, range(len(labelencoder.classes_))))\n",
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = to_categorical(y_test)\n",
    "y_train = to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kapre\r\n",
      "  Downloading https://files.pythonhosted.org/packages/3f/2e/f540d1d1f05c764686163fdb5bb1e5c703f1528076d2829bfc3900683f06/kapre-0.1.4-py3-none-any.whl\r\n",
      "Requirement already satisfied: numpy>=1.8.0 in /opt/conda/lib/python3.6/site-packages (from kapre) (1.16.4)\r\n",
      "Requirement already satisfied: keras>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from kapre) (2.2.4)\r\n",
      "Requirement already satisfied: librosa>=0.5 in /opt/conda/lib/python3.6/site-packages (from kapre) (0.6.3)\r\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.6/site-packages (from kapre) (0.17.1)\r\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /opt/conda/lib/python3.6/site-packages (from keras>=2.0.0->kapre) (1.0.8)\r\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.6/site-packages (from keras>=2.0.0->kapre) (1.1.0)\r\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.6/site-packages (from keras>=2.0.0->kapre) (1.12.0)\r\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.6/site-packages (from keras>=2.0.0->kapre) (2.9.0)\r\n",
      "Requirement already satisfied: scipy>=0.14 in /opt/conda/lib/python3.6/site-packages (from keras>=2.0.0->kapre) (1.3.0)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.6/site-packages (from keras>=2.0.0->kapre) (5.1)\r\n",
      "Requirement already satisfied: joblib>=0.12 in /opt/conda/lib/python3.6/site-packages (from librosa>=0.5->kapre) (0.13.2)\r\n",
      "Requirement already satisfied: decorator>=3.0.0 in /opt/conda/lib/python3.6/site-packages (from librosa>=0.5->kapre) (4.4.0)\r\n",
      "Requirement already satisfied: audioread>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from librosa>=0.5->kapre) (2.1.8)\r\n",
      "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /opt/conda/lib/python3.6/site-packages (from librosa>=0.5->kapre) (0.21.2)\r\n",
      "Requirement already satisfied: numba>=0.38.0 in /opt/conda/lib/python3.6/site-packages (from librosa>=0.5->kapre) (0.38.0)\r\n",
      "Requirement already satisfied: resampy>=0.2.0 in /opt/conda/lib/python3.6/site-packages (from librosa>=0.5->kapre) (0.2.1)\r\n",
      "Requirement already satisfied: llvmlite>=0.23.0dev0 in /opt/conda/lib/python3.6/site-packages (from numba>=0.38.0->librosa>=0.5->kapre) (0.29.0)\r\n",
      "Installing collected packages: kapre\r\n",
      "Successfully installed kapre-0.1.4\r\n"
     ]
    }
   ],
   "source": [
    "!pip install kapre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, Dense, Dropout, Flatten, Conv2D, MaxPooling2D,SeparableConv2D,BatchNormalization,LSTM,Reshape,TimeDistributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import kapre\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,AveragePooling2D\n",
    "from kapre.time_frequency import Melspectrogram\n",
    "from kapre.utils import Normalization2D\n",
    "from kapre.augmentation import AdditiveNoise\n",
    "\n",
    "# 6 channels (!), maybe 1-sec audio signal, for an example.\n",
    "\n",
    "sr = 16000\n",
    "input_shape = (1,sr*3)\n",
    "\n",
    "\n",
    "def edge_speech_neta():\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(\"logs/esna-100e\")\n",
    "    model = Sequential()\n",
    "    # A mel-spectrogram layer\n",
    "    model.add(Melspectrogram(n_dft=512, n_hop=512, input_shape=input_shape,\n",
    "                             padding='same', sr=sr, n_mels=128,\n",
    "                             fmin=0.0, fmax=sr/2, power_melgram=1.0,\n",
    "                             return_decibel_melgram=True,trainable_fb=False,\n",
    "                             trainable_kernel=False,\n",
    "                             name='trainable_stft'))\n",
    "    # Maybe some additive white noise.\n",
    "    model.add(AdditiveNoise(power=0.1))\n",
    "    # If you wanna normalise it per-frequency\n",
    "    model.add(Normalization2D(str_axis='freq')) # or 'channel', 'time', 'batch', 'data_sample'\n",
    "    # After this, it's just a usual keras workflow. For example..\n",
    "    # Add some layers, e.g., model.add(some convolution layers..)\n",
    "   \n",
    "    # Compile the model\n",
    "    model.add(Conv2D(39, kernel_size=(3, 3), activation='relu', input_shape=(20, 35, 1)))\n",
    "    model.add(Conv2D(20, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\n",
    "    model.add(Conv2D(39, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(15, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\n",
    "    model.add(Conv2D(39, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(25, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\n",
    "    model.add(Conv2D(39, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(22, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\n",
    "    model.add(Conv2D(39, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(22, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\n",
    "    model.add(Conv2D(39, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(25, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\n",
    "    model.add(Conv2D(39, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\n",
    "    model.add(Conv2D(45, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\n",
    "    model.add(AveragePooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4, activation='softmax'))\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                      optimizer=keras.optimizers.adam(),metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, batch_size=50, epochs=100, verbose=1, validation_data=(X_test, y_test), callbacks=[tensorboard_callback])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def depth_Seprable_cnn():\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(\"logs/depth-serpable-cnn-100e\")\n",
    "    # Depth Wise CNN (DS-CNN)\n",
    "    model = Sequential()\n",
    "    # A mel-spectrogram layer\n",
    "    model.add(Melspectrogram(n_dft=512, n_hop=512, input_shape=input_shape,\n",
    "                             padding='same', sr=sr, n_mels=128,\n",
    "                             fmin=0.0, fmax=sr/2, power_melgram=1.0,\n",
    "                             return_decibel_melgram=True,trainable_fb=False,\n",
    "                             trainable_kernel=False,\n",
    "                             name='trainable_stft'))\n",
    "    # Maybe some additive white noise.\n",
    "    model.add(AdditiveNoise(power=0.1))\n",
    "    # If you wanna normalise it per-frequency\n",
    "    model.add(Normalization2D(str_axis='freq')) # or 'channel', 'time', 'batch', 'data_sample'\n",
    "    # After this, it's just a usual keras workflow. For example..\n",
    "    # Add some layers, e.g., model.add(some convolution layers..)\n",
    "    # Compile the model\n",
    "    model.add(Conv2D(64, kernel_size=(20, 8), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),dim_ordering=\"th\"))\n",
    "    model.add(Dropout(0.25))\n",
    "    ## Depth Seprable Pooling Layer - start\n",
    "    model.add(SeparableConv2D(64, kernel_size=(5, 5), activation='relu',dim_ordering=\"th\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64, kernel_size=(1, 1), activation='relu',dim_ordering=\"th\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(SeparableConv2D(64, kernel_size=(5, 5), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64, kernel_size=(1, 1), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    ## Depth Seprable pooling Layer - end\n",
    "    model.add(AveragePooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4, activation='softmax'))\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.adam(),metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, batch_size=50, epochs=100, verbose=1, validation_data=(X_test, y_test), callbacks=[tensorboard_callback])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edgespeechnetd():\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(\"logs/edgespeechnet-d-100e\")\n",
    "    model = Sequential()\n",
    "    # A mel-spectrogram layer\n",
    "    model.add(Melspectrogram(n_dft=512, n_hop=512, input_shape=input_shape,\n",
    "                             padding='same', sr=sr, n_mels=128,\n",
    "                             fmin=0.0, fmax=sr/2, power_melgram=1.0,\n",
    "                             return_decibel_melgram=True,trainable_fb=False,\n",
    "                             trainable_kernel=False,\n",
    "                             name='trainable_stft'))\n",
    "    # Maybe some additive white noise.\n",
    "    model.add(AdditiveNoise(power=0.1))\n",
    "    # If you wanna normalise it per-frequency\n",
    "    model.add(Normalization2D(str_axis='freq')) # or 'channel', 'time', 'batch', 'data_sample'\n",
    "    # After this, it's just a usual keras workflow. For example..\n",
    "    # Add some layers, e.g., model.add(some convolution layers..)\n",
    "    # Compile the model\n",
    "    model.add(Conv2D(45, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(AveragePooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(30, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\n",
    "    model.add(Conv2D(45, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\n",
    "    model.add(Conv2D(33, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\n",
    "    model.add(Conv2D(45, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\n",
    "    model.add(Conv2D(35, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\n",
    "    model.add(Conv2D(45, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\n",
    "\n",
    "    model.add(AveragePooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(16))\n",
    "    model.add(Dense(4, activation='softmax'))\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.adam(),metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, batch_size=50, epochs=50, verbose=1, validation_data=(X_test, y_test), callbacks=[tensorboard_callback])\n",
    "    return model\n",
    "\n",
    "def edgespeechnetb():\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(\"logs/edgespeechnet-b-100e\")\n",
    "    model = Sequential()\n",
    "    # A mel-spectrogram layer\n",
    "    model.add(Melspectrogram(n_dft=512, n_hop=512, input_shape=input_shape,\n",
    "                             padding='same', sr=sr, n_mels=128,\n",
    "                             fmin=0.0, fmax=sr/2, power_melgram=1.0,\n",
    "                             return_decibel_melgram=True,trainable_fb=False,\n",
    "                             trainable_kernel=False,\n",
    "                             name='trainable_stft'))\n",
    "    # Maybe some additive white noise.\n",
    "    model.add(AdditiveNoise(power=0.1))\n",
    "    # If you wanna normalise it per-frequency\n",
    "    model.add(Normalization2D(str_axis='freq')) # or 'channel', 'time', 'batch', 'data_sample'\n",
    "    # After this, it's just a usual keras workflow. For example..\n",
    "    # Add some layers, e.g., model.add(some convolution layers..)\n",
    "    # Compile the model\n",
    "    model.add(Conv2D(30, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(Conv2D(8, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\n",
    "    model.add(Conv2D(30, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\n",
    "    model.add(Conv2D(9, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\n",
    "    model.add(Conv2D(30, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\n",
    "    model.add(Conv2D(11, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\n",
    "    model.add(Conv2D(30, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\n",
    "    model.add(Conv2D(10, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\n",
    "    model.add(Conv2D(30, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\n",
    "    model.add(Conv2D(8, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\n",
    "    model.add(Conv2D(30, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\n",
    "    model.add(Conv2D(11, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\n",
    "    model.add(Conv2D(30, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\n",
    "    model.add(Conv2D(45, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\n",
    "\n",
    "    model.add(AveragePooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    # model.add(Dense(16))\n",
    "    model.add(Dense(4, activation='softmax'))\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.adam(),metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, batch_size=50, epochs=50, verbose=1, validation_data=(X_test, y_test), callbacks=[tensorboard_callback])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn():\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(\"logs/cnn-100e\")\n",
    "    model = Sequential()\n",
    "    # A mel-spectrogram layer\n",
    "    model.add(Melspectrogram(n_dft=512, n_hop=512, input_shape=input_shape,\n",
    "                             padding='same', sr=sr, n_mels=128,\n",
    "                             fmin=0.0, fmax=sr/2, power_melgram=1.0,\n",
    "                             return_decibel_melgram=True,trainable_fb=False,\n",
    "                             trainable_kernel=False,\n",
    "                             name='trainable_stft'))\n",
    "    # Maybe some additive white noise.\n",
    "    model.add(AdditiveNoise(power=0.1))\n",
    "    # If you wanna normalise it per-frequency\n",
    "    model.add(Normalization2D(str_axis='freq')) # or 'channel', 'time', 'batch', 'data_sample'\n",
    "    # After this, it's just a usual keras workflow. For example..\n",
    "    # Add some layers, e.g., model.add(some convolution layers..)\n",
    "    # Compile the model\n",
    "\n",
    "    model.add(Conv2D(64, kernel_size=(20, 8), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),dim_ordering=\"th\"))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(64, kernel_size=(10, 4), activation='relu',dim_ordering=\"th\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),dim_ordering=\"th\"))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(4, activation='softmax'))\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.adam(),metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, batch_size=50, epochs=50, verbose=1, validation_data=(X_test, y_test), callbacks=[tensorboard_callback])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Permute, Dropout, Flatten, Conv2D, MaxPooling2D,SeparableConv2D,BatchNormalization,AveragePooling2D,GRU,Input\n",
    "\n",
    "def crnn():\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(\"logs/crnn-50batch\")\n",
    "    model = Sequential()\n",
    "    model.add(Melspectrogram(n_dft=512, n_hop=512, input_shape=input_shape,\n",
    "                             padding='same', sr=sr, n_mels=128,\n",
    "                             fmin=0.0, fmax=sr/2, power_melgram=1.0,\n",
    "                             return_decibel_melgram=True,trainable_fb=False,\n",
    "                             trainable_kernel=False,\n",
    "                             name='trainable_stft'))\n",
    "    # Maybe some additive white noise.\n",
    "    model.add(AdditiveNoise(power=0.1))\n",
    "    # If you wanna normalise it per-frequency\n",
    "    model.add(Normalization2D(str_axis='freq'))\n",
    "    model.add(Conv2D(64, kernel_size=(20, 8), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),dim_ordering=\"th\"))\n",
    "    model.add(Dropout(0.25))\n",
    "    ## Depth Seprable Pooling Layer - start\n",
    "    model.add(SeparableConv2D(64, kernel_size=(5,5), activation='relu',dim_ordering=\"th\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64, kernel_size=(1, 1), activation='relu',dim_ordering=\"th\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(SeparableConv2D(64, kernel_size=(5,5), activation='relu',dim_ordering=\"th\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64, kernel_size=(1, 1), activation='relu',dim_ordering=\"th\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(SeparableConv2D(64, kernel_size=(5,5), activation='relu',dim_ordering=\"th\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64, kernel_size=(1, 1), activation='relu',dim_ordering=\"th\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(AveragePooling2D(pool_size=(2, 2),dim_ordering=\"th\"))\n",
    "    model.add(Reshape((320, -1)))\n",
    "    model.add(GRU(60, return_sequences=True, name='gru1'))\n",
    "    model.add(GRU(60, return_sequences=False, name='gru2'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(4, activation='softmax'))\n",
    "    model.summary()\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.adam(),metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, batch_size=50, epochs=50, verbose=1, validation_data=(X_test, y_test), callbacks=[tensorboard_callback])\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:18: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:21: UserWarning: Update your `SeparableConv2D` call to the Keras 2 API: `SeparableConv2D(64, kernel_size=(5, 5), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:23: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, kernel_size=(1, 1), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:25: UserWarning: Update your `SeparableConv2D` call to the Keras 2 API: `SeparableConv2D(64, kernel_size=(5, 5), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:27: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, kernel_size=(1, 1), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:29: UserWarning: Update your `SeparableConv2D` call to the Keras 2 API: `SeparableConv2D(64, kernel_size=(5, 5), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:31: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, kernel_size=(1, 1), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:33: UserWarning: Update your `AveragePooling2D` call to the Keras 2 API: `AveragePooling2D(pool_size=(2, 2), data_format=\"channels_first\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "trainable_stft (Melspectrogr (None, 128, 94, 1)        296064    \n",
      "_________________________________________________________________\n",
      "additive_noise_1 (AdditiveNo (None, 128, 94, 1)        0         \n",
      "_________________________________________________________________\n",
      "normalization2d_1 (Normaliza (None, 128, 94, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 109, 87, 64)       10304     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 109, 43, 32)       0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 109, 43, 32)       0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_1 (Separabl (None, 64, 39, 28)        9765      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 64, 39, 28)        112       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 64, 39, 28)        4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 64, 39, 28)        112       \n",
      "_________________________________________________________________\n",
      "separable_conv2d_2 (Separabl (None, 64, 35, 24)        5760      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 64, 35, 24)        96        \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 64, 35, 24)        4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 64, 35, 24)        96        \n",
      "_________________________________________________________________\n",
      "separable_conv2d_3 (Separabl (None, 64, 31, 20)        5760      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 64, 31, 20)        80        \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 64, 31, 20)        4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 64, 31, 20)        80        \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average (None, 64, 15, 10)        0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 320, 30)           0         \n",
      "_________________________________________________________________\n",
      "gru1 (GRU)                   (None, 320, 60)           16380     \n",
      "_________________________________________________________________\n",
      "gru2 (GRU)                   (None, 60)                21780     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 244       \n",
      "=================================================================\n",
      "Total params: 379,113\n",
      "Trainable params: 82,761\n",
      "Non-trainable params: 296,352\n",
      "_________________________________________________________________\n",
      "Train on 3295 samples, validate on 1413 samples\n",
      "Epoch 1/50\n",
      "3295/3295 [==============================] - 63s 19ms/step - loss: 1.1899 - acc: 0.4255 - val_loss: 1.0984 - val_acc: 0.4890\n",
      "Epoch 2/50\n",
      "3295/3295 [==============================] - 58s 18ms/step - loss: 0.9553 - acc: 0.5873 - val_loss: 1.2287 - val_acc: 0.4643\n",
      "Epoch 3/50\n",
      "3295/3295 [==============================] - 58s 18ms/step - loss: 0.7511 - acc: 0.7020 - val_loss: 1.1404 - val_acc: 0.5301\n",
      "Epoch 4/50\n",
      "3295/3295 [==============================] - 58s 18ms/step - loss: 0.6351 - acc: 0.7633 - val_loss: 0.6383 - val_acc: 0.7537\n",
      "Epoch 5/50\n",
      "3295/3295 [==============================] - 58s 18ms/step - loss: 0.5483 - acc: 0.8058 - val_loss: 0.6044 - val_acc: 0.7742\n",
      "Epoch 6/50\n",
      "3295/3295 [==============================] - 58s 18ms/step - loss: 0.5043 - acc: 0.8255 - val_loss: 0.7758 - val_acc: 0.7176\n",
      "Epoch 7/50\n",
      "3295/3295 [==============================] - 58s 18ms/step - loss: 0.4528 - acc: 0.8443 - val_loss: 0.4781 - val_acc: 0.8217\n",
      "Epoch 8/50\n",
      "3295/3295 [==============================] - 58s 18ms/step - loss: 0.4334 - acc: 0.8531 - val_loss: 0.5461 - val_acc: 0.7863\n",
      "Epoch 9/50\n",
      "3295/3295 [==============================] - 58s 18ms/step - loss: 0.3859 - acc: 0.8649 - val_loss: 0.4329 - val_acc: 0.8422\n",
      "Epoch 10/50\n",
      "3295/3295 [==============================] - 58s 17ms/step - loss: 0.3714 - acc: 0.8674 - val_loss: 0.4885 - val_acc: 0.8209\n",
      "Epoch 11/50\n",
      "3295/3295 [==============================] - 57s 17ms/step - loss: 0.3518 - acc: 0.8756 - val_loss: 0.6799 - val_acc: 0.7657\n",
      "Epoch 12/50\n",
      "3295/3295 [==============================] - 58s 17ms/step - loss: 0.3235 - acc: 0.8835 - val_loss: 0.5251 - val_acc: 0.8004\n",
      "Epoch 13/50\n",
      "3295/3295 [==============================] - 58s 18ms/step - loss: 0.3031 - acc: 0.8923 - val_loss: 0.3658 - val_acc: 0.8684\n",
      "Epoch 14/50\n",
      "3295/3295 [==============================] - 57s 17ms/step - loss: 0.2669 - acc: 0.9077 - val_loss: 0.3785 - val_acc: 0.8698\n",
      "Epoch 15/50\n",
      "3295/3295 [==============================] - 57s 17ms/step - loss: 0.2563 - acc: 0.9068 - val_loss: 0.6616 - val_acc: 0.7820\n",
      "Epoch 16/50\n",
      "3295/3295 [==============================] - 57s 17ms/step - loss: 0.2400 - acc: 0.9126 - val_loss: 0.3723 - val_acc: 0.8712\n",
      "Epoch 17/50\n",
      "3295/3295 [==============================] - 57s 17ms/step - loss: 0.2244 - acc: 0.9208 - val_loss: 0.4170 - val_acc: 0.8507\n",
      "Epoch 18/50\n",
      "3295/3295 [==============================] - 57s 17ms/step - loss: 0.1964 - acc: 0.9341 - val_loss: 0.3130 - val_acc: 0.8783\n",
      "Epoch 19/50\n",
      "3295/3295 [==============================] - 58s 17ms/step - loss: 0.1853 - acc: 0.9344 - val_loss: 0.3569 - val_acc: 0.8712\n",
      "Epoch 20/50\n",
      "3295/3295 [==============================] - 57s 17ms/step - loss: 0.1639 - acc: 0.9451 - val_loss: 0.2692 - val_acc: 0.8967\n",
      "Epoch 21/50\n",
      "3295/3295 [==============================] - 58s 18ms/step - loss: 0.1333 - acc: 0.9560 - val_loss: 0.3565 - val_acc: 0.8804\n",
      "Epoch 22/50\n",
      "3295/3295 [==============================] - 58s 17ms/step - loss: 0.1704 - acc: 0.9417 - val_loss: 0.2854 - val_acc: 0.9130\n",
      "Epoch 23/50\n",
      "3295/3295 [==============================] - 57s 17ms/step - loss: 0.1351 - acc: 0.9520 - val_loss: 0.2754 - val_acc: 0.9122\n",
      "Epoch 24/50\n",
      "3295/3295 [==============================] - 57s 17ms/step - loss: 0.1281 - acc: 0.9587 - val_loss: 0.2493 - val_acc: 0.9158\n",
      "Epoch 25/50\n",
      "3295/3295 [==============================] - 57s 17ms/step - loss: 0.1069 - acc: 0.9660 - val_loss: 0.2030 - val_acc: 0.9321\n",
      "Epoch 26/50\n",
      "3295/3295 [==============================] - 57s 17ms/step - loss: 0.1224 - acc: 0.9630 - val_loss: 0.2786 - val_acc: 0.9087\n",
      "Epoch 27/50\n",
      "3295/3295 [==============================] - 57s 17ms/step - loss: 0.1433 - acc: 0.9520 - val_loss: 0.2511 - val_acc: 0.9193\n",
      "Epoch 28/50\n",
      "3295/3295 [==============================] - 57s 17ms/step - loss: 0.1062 - acc: 0.9642 - val_loss: 0.2644 - val_acc: 0.9080\n",
      "Epoch 29/50\n",
      "3295/3295 [==============================] - 57s 17ms/step - loss: 0.0693 - acc: 0.9769 - val_loss: 0.1809 - val_acc: 0.9370\n",
      "Epoch 30/50\n",
      "3295/3295 [==============================] - 57s 17ms/step - loss: 0.0877 - acc: 0.9727 - val_loss: 0.3412 - val_acc: 0.8974\n",
      "Epoch 31/50\n",
      "3295/3295 [==============================] - 57s 17ms/step - loss: 0.1174 - acc: 0.9557 - val_loss: 0.3626 - val_acc: 0.8953\n",
      "Epoch 32/50\n",
      "3295/3295 [==============================] - 57s 17ms/step - loss: 0.1035 - acc: 0.9672 - val_loss: 0.1877 - val_acc: 0.9328\n",
      "Epoch 33/50\n",
      "3295/3295 [==============================] - 57s 17ms/step - loss: 0.0810 - acc: 0.9709 - val_loss: 0.2139 - val_acc: 0.9363\n",
      "Epoch 34/50\n",
      "3295/3295 [==============================] - 57s 17ms/step - loss: 0.0981 - acc: 0.9645 - val_loss: 0.3173 - val_acc: 0.8953\n",
      "Epoch 35/50\n",
      "3295/3295 [==============================] - 58s 18ms/step - loss: 0.0894 - acc: 0.9697 - val_loss: 0.1877 - val_acc: 0.9413\n",
      "Epoch 36/50\n",
      "3295/3295 [==============================] - 58s 17ms/step - loss: 0.0964 - acc: 0.9654 - val_loss: 0.2342 - val_acc: 0.9236\n",
      "Epoch 37/50\n",
      "3295/3295 [==============================] - 58s 18ms/step - loss: 0.0742 - acc: 0.9751 - val_loss: 0.2230 - val_acc: 0.9342\n",
      "Epoch 38/50\n",
      "3295/3295 [==============================] - 58s 18ms/step - loss: 0.0741 - acc: 0.9775 - val_loss: 0.2572 - val_acc: 0.9087\n",
      "Epoch 39/50\n",
      "3295/3295 [==============================] - 58s 18ms/step - loss: 0.0517 - acc: 0.9827 - val_loss: 0.2201 - val_acc: 0.9349\n",
      "Epoch 40/50\n",
      "3295/3295 [==============================] - 58s 18ms/step - loss: 0.0512 - acc: 0.9830 - val_loss: 0.2868 - val_acc: 0.9101\n",
      "Epoch 41/50\n",
      "3295/3295 [==============================] - 58s 18ms/step - loss: 0.0527 - acc: 0.9830 - val_loss: 0.2805 - val_acc: 0.9165\n",
      "Epoch 42/50\n",
      "3295/3295 [==============================] - 58s 18ms/step - loss: 0.0894 - acc: 0.9693 - val_loss: 0.2483 - val_acc: 0.9179\n",
      "Epoch 43/50\n",
      "3295/3295 [==============================] - 58s 18ms/step - loss: 0.0566 - acc: 0.9836 - val_loss: 0.2676 - val_acc: 0.9271\n",
      "Epoch 44/50\n",
      "3295/3295 [==============================] - 58s 18ms/step - loss: 0.0579 - acc: 0.9809 - val_loss: 0.2887 - val_acc: 0.9193\n",
      "Epoch 45/50\n",
      "3295/3295 [==============================] - 58s 18ms/step - loss: 0.0756 - acc: 0.9730 - val_loss: 0.2267 - val_acc: 0.9342\n",
      "Epoch 46/50\n",
      "3295/3295 [==============================] - 59s 18ms/step - loss: 0.0575 - acc: 0.9812 - val_loss: 0.2281 - val_acc: 0.9391\n",
      "Epoch 47/50\n",
      "3295/3295 [==============================] - 59s 18ms/step - loss: 0.0426 - acc: 0.9866 - val_loss: 0.2603 - val_acc: 0.9314\n",
      "Epoch 48/50\n",
      "3295/3295 [==============================] - 58s 18ms/step - loss: 0.0451 - acc: 0.9845 - val_loss: 0.2624 - val_acc: 0.9306\n",
      "Epoch 49/50\n",
      "3295/3295 [==============================] - 58s 18ms/step - loss: 0.0366 - acc: 0.9873 - val_loss: 0.3339 - val_acc: 0.9144\n",
      "Epoch 50/50\n",
      "3295/3295 [==============================] - 58s 18ms/step - loss: 0.0682 - acc: 0.9788 - val_loss: 0.3290 - val_acc: 0.9038\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7f3f62bc5668>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:34: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(20, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:35: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(39, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:37: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(15, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:38: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(39, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:40: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(25, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:41: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(39, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:43: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(22, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:44: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(39, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:46: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(22, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:47: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(39, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:49: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(25, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:50: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(39, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:51: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(45, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3295 samples, validate on 1413 samples\n",
      "Epoch 1/100\n",
      "3295/3295 [==============================] - 6s 2ms/step - loss: 1.3050 - acc: 0.3363 - val_loss: 1.1813 - val_acc: 0.3970\n",
      "Epoch 2/100\n",
      "3295/3295 [==============================] - 4s 1ms/step - loss: 1.0744 - acc: 0.4971 - val_loss: 1.0256 - val_acc: 0.5159\n",
      "Epoch 3/100\n",
      "3295/3295 [==============================] - 4s 1ms/step - loss: 1.0486 - acc: 0.4950 - val_loss: 1.0677 - val_acc: 0.5046\n",
      "Epoch 4/100\n",
      "3295/3295 [==============================] - 4s 1ms/step - loss: 1.0687 - acc: 0.5014 - val_loss: 1.0202 - val_acc: 0.5258\n",
      "Epoch 5/100\n",
      "3295/3295 [==============================] - 4s 1ms/step - loss: 0.9966 - acc: 0.5426 - val_loss: 1.0084 - val_acc: 0.5159\n",
      "Epoch 6/100\n",
      "3295/3295 [==============================] - 4s 1ms/step - loss: 0.9531 - acc: 0.5848 - val_loss: 0.8983 - val_acc: 0.6178\n",
      "Epoch 7/100\n",
      "3295/3295 [==============================] - 4s 1ms/step - loss: 0.8613 - acc: 0.6282 - val_loss: 0.8381 - val_acc: 0.6716\n",
      "Epoch 8/100\n",
      "3295/3295 [==============================] - 4s 1ms/step - loss: 0.8545 - acc: 0.6467 - val_loss: 0.8416 - val_acc: 0.6610\n",
      "Epoch 9/100\n",
      "3295/3295 [==============================] - 3s 1ms/step - loss: 0.8036 - acc: 0.6841 - val_loss: 0.7236 - val_acc: 0.7389\n",
      "Epoch 10/100\n",
      "3295/3295 [==============================] - 3s 1ms/step - loss: 0.6987 - acc: 0.7414 - val_loss: 0.6358 - val_acc: 0.7643\n",
      "Epoch 11/100\n",
      "3295/3295 [==============================] - 3s 1ms/step - loss: 0.6267 - acc: 0.7748 - val_loss: 0.7724 - val_acc: 0.7360\n",
      "Epoch 12/100\n",
      "3295/3295 [==============================] - 3s 1ms/step - loss: 0.6006 - acc: 0.7757 - val_loss: 0.5931 - val_acc: 0.7919\n",
      "Epoch 13/100\n",
      "3295/3295 [==============================] - 3s 1ms/step - loss: 0.5713 - acc: 0.7882 - val_loss: 0.6437 - val_acc: 0.7721\n",
      "Epoch 14/100\n",
      "3295/3295 [==============================] - 3s 1ms/step - loss: 0.5223 - acc: 0.8121 - val_loss: 0.5302 - val_acc: 0.8202\n",
      "Epoch 15/100\n",
      "3295/3295 [==============================] - 3s 1ms/step - loss: 0.4479 - acc: 0.8401 - val_loss: 0.5190 - val_acc: 0.8139\n",
      "Epoch 16/100\n",
      "3295/3295 [==============================] - 3s 1ms/step - loss: 0.4165 - acc: 0.8537 - val_loss: 0.5461 - val_acc: 0.8266\n",
      "Epoch 17/100\n",
      "3295/3295 [==============================] - 3s 1ms/step - loss: 0.4074 - acc: 0.8510 - val_loss: 0.5204 - val_acc: 0.8202\n",
      "Epoch 18/100\n",
      "3295/3295 [==============================] - 3s 1ms/step - loss: 0.3723 - acc: 0.8656 - val_loss: 0.4622 - val_acc: 0.8471\n",
      "Epoch 19/100\n",
      "3295/3295 [==============================] - 3s 1ms/step - loss: 0.3380 - acc: 0.8762 - val_loss: 0.4527 - val_acc: 0.8493\n",
      "Epoch 20/100\n",
      "3295/3295 [==============================] - 3s 1ms/step - loss: 0.3577 - acc: 0.8737 - val_loss: 0.5421 - val_acc: 0.8231\n",
      "Epoch 21/100\n",
      "3295/3295 [==============================] - 3s 1ms/step - loss: 0.3257 - acc: 0.8841 - val_loss: 0.4483 - val_acc: 0.8386\n",
      "Epoch 22/100\n",
      "3295/3295 [==============================] - 3s 1ms/step - loss: 0.3012 - acc: 0.8929 - val_loss: 0.4310 - val_acc: 0.8485\n",
      "Epoch 23/100\n",
      "3295/3295 [==============================] - 3s 1ms/step - loss: 0.2992 - acc: 0.9008 - val_loss: 0.4469 - val_acc: 0.8500\n",
      "Epoch 24/100\n",
      "3295/3295 [==============================] - 3s 1ms/step - loss: 0.2567 - acc: 0.9099 - val_loss: 0.4443 - val_acc: 0.8457\n",
      "Epoch 25/100\n",
      "3295/3295 [==============================] - 3s 1ms/step - loss: 0.2668 - acc: 0.9008 - val_loss: 0.4331 - val_acc: 0.8634\n",
      "Epoch 26/100\n",
      "3295/3295 [==============================] - 3s 1ms/step - loss: 0.1954 - acc: 0.9329 - val_loss: 0.4246 - val_acc: 0.8627\n",
      "Epoch 27/100\n",
      "3295/3295 [==============================] - 3s 1ms/step - loss: 0.2171 - acc: 0.9269 - val_loss: 0.3600 - val_acc: 0.8662\n",
      "Epoch 28/100\n",
      "3295/3295 [==============================] - 3s 1ms/step - loss: 0.1937 - acc: 0.9347 - val_loss: 0.6395 - val_acc: 0.8358\n",
      "Epoch 29/100\n",
      "3295/3295 [==============================] - 3s 1ms/step - loss: 0.2045 - acc: 0.9278 - val_loss: 0.3668 - val_acc: 0.8776\n",
      "Epoch 30/100\n",
      "3295/3295 [==============================] - 3s 1ms/step - loss: 0.1878 - acc: 0.9317 - val_loss: 0.3570 - val_acc: 0.8790\n",
      "Epoch 31/100\n",
      "3295/3295 [==============================] - 3s 1ms/step - loss: 0.1759 - acc: 0.9363 - val_loss: 0.3625 - val_acc: 0.8896\n",
      "Epoch 32/100\n",
      "3295/3295 [==============================] - 3s 1ms/step - loss: 0.1502 - acc: 0.9530 - val_loss: 0.4215 - val_acc: 0.8896\n",
      "Epoch 33/100\n",
      "3295/3295 [==============================] - 3s 1ms/step - loss: 0.1741 - acc: 0.9423 - val_loss: 0.4988 - val_acc: 0.8577\n",
      "Epoch 34/100\n",
      "3295/3295 [==============================] - 3s 1ms/step - loss: 0.1486 - acc: 0.9490 - val_loss: 0.3860 - val_acc: 0.8868\n",
      "Epoch 35/100\n",
      "3295/3295 [==============================] - 3s 1ms/step - loss: 0.1705 - acc: 0.9448 - val_loss: 0.4503 - val_acc: 0.8762\n",
      "Epoch 36/100\n",
      "3295/3295 [==============================] - 3s 1ms/step - loss: 0.1314 - acc: 0.9563 - val_loss: 0.4328 - val_acc: 0.8846\n",
      "Epoch 37/100\n",
      "3295/3295 [==============================] - 3s 1ms/step - loss: 0.1334 - acc: 0.9548 - val_loss: 0.3616 - val_acc: 0.8861\n",
      "Epoch 38/100\n",
      "3295/3295 [==============================] - 3s 1ms/step - loss: 0.1332 - acc: 0.9557 - val_loss: 0.3676 - val_acc: 0.8946\n",
      "Epoch 39/100\n",
      "3295/3295 [==============================] - 4s 1ms/step - loss: 0.1220 - acc: 0.9575 - val_loss: 0.4368 - val_acc: 0.8712\n",
      "Epoch 40/100\n",
      "3295/3295 [==============================] - 4s 1ms/step - loss: 0.1140 - acc: 0.9593 - val_loss: 0.3544 - val_acc: 0.9094\n",
      "Epoch 41/100\n",
      "3295/3295 [==============================] - 4s 1ms/step - loss: 0.1130 - acc: 0.9615 - val_loss: 0.4231 - val_acc: 0.8946\n",
      "Epoch 42/100\n",
      "3295/3295 [==============================] - 4s 1ms/step - loss: 0.1311 - acc: 0.9563 - val_loss: 0.4049 - val_acc: 0.9045\n",
      "Epoch 43/100\n",
      "3295/3295 [==============================] - 4s 1ms/step - loss: 0.1111 - acc: 0.9605 - val_loss: 0.3850 - val_acc: 0.9066\n",
      "Epoch 44/100\n",
      "3295/3295 [==============================] - 4s 1ms/step - loss: 0.1075 - acc: 0.9642 - val_loss: 0.4984 - val_acc: 0.8762\n",
      "Epoch 45/100\n",
      "3295/3295 [==============================] - 4s 1ms/step - loss: 0.1001 - acc: 0.9651 - val_loss: 0.2997 - val_acc: 0.9023\n",
      "Epoch 46/100\n",
      "3295/3295 [==============================] - 4s 1ms/step - loss: 0.0735 - acc: 0.9769 - val_loss: 0.3635 - val_acc: 0.9122\n",
      "Epoch 47/100\n",
      "3295/3295 [==============================] - 4s 1ms/step - loss: 0.1338 - acc: 0.9566 - val_loss: 0.3598 - val_acc: 0.8953\n",
      "Epoch 48/100\n",
      "3295/3295 [==============================] - 4s 1ms/step - loss: 0.0836 - acc: 0.9706 - val_loss: 0.4290 - val_acc: 0.9002\n",
      "Epoch 49/100\n",
      "3295/3295 [==============================] - 4s 1ms/step - loss: 0.1091 - acc: 0.9672 - val_loss: 0.3524 - val_acc: 0.9030\n",
      "Epoch 50/100\n",
      "3295/3295 [==============================] - 4s 1ms/step - loss: 0.0962 - acc: 0.9675 - val_loss: 0.5049 - val_acc: 0.8917\n",
      "Epoch 51/100\n",
      "3295/3295 [==============================] - 4s 1ms/step - loss: 0.0673 - acc: 0.9751 - val_loss: 0.3402 - val_acc: 0.9023\n",
      "Epoch 52/100\n",
      "3295/3295 [==============================] - 4s 1ms/step - loss: 0.0810 - acc: 0.9718 - val_loss: 0.3786 - val_acc: 0.9023\n",
      "Epoch 53/100\n",
      "3295/3295 [==============================] - 4s 1ms/step - loss: 0.1072 - acc: 0.9654 - val_loss: 0.5005 - val_acc: 0.8797\n",
      "Epoch 54/100\n",
      "3295/3295 [==============================] - 4s 1ms/step - loss: 0.0752 - acc: 0.9775 - val_loss: 0.3902 - val_acc: 0.8910\n",
      "Epoch 55/100\n",
      "3295/3295 [==============================] - 4s 1ms/step - loss: 0.0789 - acc: 0.9754 - val_loss: 0.4170 - val_acc: 0.9016\n",
      "Epoch 56/100\n",
      "3295/3295 [==============================] - 4s 1ms/step - loss: 0.0576 - acc: 0.9815 - val_loss: 0.3734 - val_acc: 0.9080\n",
      "Epoch 57/100\n",
      "3295/3295 [==============================] - 4s 1ms/step - loss: 0.0794 - acc: 0.9733 - val_loss: 0.3470 - val_acc: 0.9059\n",
      "Epoch 58/100\n",
      "3295/3295 [==============================] - 4s 1ms/step - loss: 0.0685 - acc: 0.9742 - val_loss: 0.4054 - val_acc: 0.9045\n",
      "Epoch 59/100\n",
      "3295/3295 [==============================] - 4s 1ms/step - loss: 0.0711 - acc: 0.9781 - val_loss: 0.3328 - val_acc: 0.8917\n",
      "Epoch 60/100\n",
      "3295/3295 [==============================] - 4s 1ms/step - loss: 0.0886 - acc: 0.9697 - val_loss: 0.3796 - val_acc: 0.9038\n",
      "Epoch 61/100\n",
      "3295/3295 [==============================] - 4s 1ms/step - loss: 0.0951 - acc: 0.9715 - val_loss: 0.2913 - val_acc: 0.9052\n",
      "Epoch 62/100\n",
      "3295/3295 [==============================] - 4s 1ms/step - loss: 0.0744 - acc: 0.9736 - val_loss: 0.3289 - val_acc: 0.9137\n",
      "Epoch 63/100\n",
      "3295/3295 [==============================] - 4s 1ms/step - loss: 0.0550 - acc: 0.9800 - val_loss: 0.3399 - val_acc: 0.9094\n",
      "Epoch 64/100\n",
      "3295/3295 [==============================] - 4s 1ms/step - loss: 0.0701 - acc: 0.9775 - val_loss: 0.3328 - val_acc: 0.9087\n",
      "Epoch 65/100\n",
      "3295/3295 [==============================] - 4s 1ms/step - loss: 0.0671 - acc: 0.9769 - val_loss: 0.3903 - val_acc: 0.9094\n",
      "Epoch 66/100\n",
      "3295/3295 [==============================] - 4s 1ms/step - loss: 0.0565 - acc: 0.9809 - val_loss: 0.3876 - val_acc: 0.9179\n",
      "Epoch 67/100\n",
      "3295/3295 [==============================] - 4s 1ms/step - loss: 0.0564 - acc: 0.9809 - val_loss: 0.3547 - val_acc: 0.9214\n",
      "Epoch 68/100\n",
      "3295/3295 [==============================] - 4s 1ms/step - loss: 0.0514 - acc: 0.9830 - val_loss: 0.4155 - val_acc: 0.9080\n",
      "Epoch 69/100\n",
      "3295/3295 [==============================] - 4s 1ms/step - loss: 0.0436 - acc: 0.9866 - val_loss: 0.4347 - val_acc: 0.9179\n",
      "Epoch 70/100\n",
      "3295/3295 [==============================] - 4s 1ms/step - loss: 0.0636 - acc: 0.9806 - val_loss: 0.2707 - val_acc: 0.9186\n",
      "Epoch 71/100\n",
      "3295/3295 [==============================] - 4s 1ms/step - loss: 0.0735 - acc: 0.9751 - val_loss: 0.3167 - val_acc: 0.9186\n",
      "Epoch 72/100\n",
      "3295/3295 [==============================] - 4s 1ms/step - loss: 0.0457 - acc: 0.9842 - val_loss: 0.4092 - val_acc: 0.9137\n",
      "Epoch 73/100\n",
      "3295/3295 [==============================] - 4s 1ms/step - loss: 0.0465 - acc: 0.9818 - val_loss: 0.3393 - val_acc: 0.9207\n",
      "Epoch 74/100\n",
      "3295/3295 [==============================] - 4s 1ms/step - loss: 0.0403 - acc: 0.9854 - val_loss: 0.3629 - val_acc: 0.9094\n",
      "Epoch 75/100\n",
      "3295/3295 [==============================] - 4s 1ms/step - loss: 0.0368 - acc: 0.9869 - val_loss: 0.4564 - val_acc: 0.9222\n",
      "Epoch 76/100\n",
      "3295/3295 [==============================] - 4s 1ms/step - loss: 0.0856 - acc: 0.9730 - val_loss: 0.4408 - val_acc: 0.8938\n",
      "Epoch 77/100\n",
      "3295/3295 [==============================] - 4s 1ms/step - loss: 0.0555 - acc: 0.9806 - val_loss: 0.3675 - val_acc: 0.9165\n",
      "Epoch 78/100\n",
      "3295/3295 [==============================] - 4s 1ms/step - loss: 0.0842 - acc: 0.9781 - val_loss: 0.3342 - val_acc: 0.8988\n",
      "Epoch 79/100\n",
      "3295/3295 [==============================] - 4s 1ms/step - loss: 0.0675 - acc: 0.9785 - val_loss: 0.3966 - val_acc: 0.9137\n",
      "Epoch 80/100\n",
      "3295/3295 [==============================] - 4s 1ms/step - loss: 0.0446 - acc: 0.9857 - val_loss: 0.3829 - val_acc: 0.9151\n",
      "Epoch 81/100\n",
      "3295/3295 [==============================] - 4s 1ms/step - loss: 0.0294 - acc: 0.9915 - val_loss: 0.4267 - val_acc: 0.9236\n",
      "Epoch 82/100\n",
      "3295/3295 [==============================] - 4s 1ms/step - loss: 0.0371 - acc: 0.9891 - val_loss: 0.4487 - val_acc: 0.9137\n",
      "Epoch 83/100\n",
      "3295/3295 [==============================] - 4s 1ms/step - loss: 0.0378 - acc: 0.9882 - val_loss: 0.4290 - val_acc: 0.9016\n",
      "Epoch 84/100\n",
      "3295/3295 [==============================] - 4s 1ms/step - loss: 0.0414 - acc: 0.9857 - val_loss: 0.4329 - val_acc: 0.9144\n",
      "Epoch 85/100\n",
      "3295/3295 [==============================] - 4s 1ms/step - loss: 0.0219 - acc: 0.9927 - val_loss: 0.4528 - val_acc: 0.9165\n",
      "Epoch 86/100\n",
      "3295/3295 [==============================] - 4s 1ms/step - loss: 0.0485 - acc: 0.9827 - val_loss: 0.4430 - val_acc: 0.9144\n",
      "Epoch 87/100\n",
      "3295/3295 [==============================] - 4s 1ms/step - loss: 0.0583 - acc: 0.9809 - val_loss: 0.4070 - val_acc: 0.8910\n",
      "Epoch 88/100\n",
      "3295/3295 [==============================] - 4s 1ms/step - loss: 0.0512 - acc: 0.9839 - val_loss: 0.4328 - val_acc: 0.9094\n",
      "Epoch 89/100\n",
      "3295/3295 [==============================] - 4s 1ms/step - loss: 0.0273 - acc: 0.9918 - val_loss: 0.5108 - val_acc: 0.9002\n",
      "Epoch 90/100\n",
      "3295/3295 [==============================] - 4s 1ms/step - loss: 0.0384 - acc: 0.9866 - val_loss: 0.4332 - val_acc: 0.9122\n",
      "Epoch 91/100\n",
      "3295/3295 [==============================] - 4s 1ms/step - loss: 0.0536 - acc: 0.9827 - val_loss: 0.3827 - val_acc: 0.9038\n",
      "Epoch 92/100\n",
      "3295/3295 [==============================] - 4s 1ms/step - loss: 0.0423 - acc: 0.9854 - val_loss: 0.3657 - val_acc: 0.9207\n",
      "Epoch 93/100\n",
      "3295/3295 [==============================] - 4s 1ms/step - loss: 0.1074 - acc: 0.9645 - val_loss: 0.3427 - val_acc: 0.9066\n",
      "Epoch 94/100\n",
      "3295/3295 [==============================] - 4s 1ms/step - loss: 0.0476 - acc: 0.9833 - val_loss: 0.4645 - val_acc: 0.9151\n",
      "Epoch 95/100\n",
      "3295/3295 [==============================] - 4s 1ms/step - loss: 0.0745 - acc: 0.9757 - val_loss: 0.4077 - val_acc: 0.9066\n",
      "Epoch 96/100\n",
      "3295/3295 [==============================] - 4s 1ms/step - loss: 0.0268 - acc: 0.9918 - val_loss: 0.4702 - val_acc: 0.9130\n",
      "Epoch 97/100\n",
      "3295/3295 [==============================] - 4s 1ms/step - loss: 0.0494 - acc: 0.9848 - val_loss: 0.4239 - val_acc: 0.9179\n",
      "Epoch 98/100\n",
      "3295/3295 [==============================] - 4s 1ms/step - loss: 0.0340 - acc: 0.9915 - val_loss: 0.3837 - val_acc: 0.9186\n",
      "Epoch 99/100\n",
      "3295/3295 [==============================] - 4s 1ms/step - loss: 0.0422 - acc: 0.9873 - val_loss: 0.3608 - val_acc: 0.9137\n",
      "Epoch 100/100\n",
      "3295/3295 [==============================] - 4s 1ms/step - loss: 0.0207 - acc: 0.9915 - val_loss: 0.5096 - val_acc: 0.9229\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7f3f62bc5358>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_speech_neta()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:20: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:23: UserWarning: Update your `SeparableConv2D` call to the Keras 2 API: `SeparableConv2D(64, kernel_size=(5, 5), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:25: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, kernel_size=(1, 1), activation=\"relu\", data_format=\"channels_first\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3295 samples, validate on 1413 samples\n",
      "Epoch 1/100\n",
      "3295/3295 [==============================] - 7s 2ms/step - loss: 2.4717 - acc: 0.4710 - val_loss: 2.6356 - val_acc: 0.4798\n",
      "Epoch 2/100\n",
      "3295/3295 [==============================] - 5s 2ms/step - loss: 1.5875 - acc: 0.5821 - val_loss: 1.1882 - val_acc: 0.5938\n",
      "Epoch 3/100\n",
      "3295/3295 [==============================] - 5s 1ms/step - loss: 1.0617 - acc: 0.6340 - val_loss: 1.0758 - val_acc: 0.6695\n",
      "Epoch 4/100\n",
      "3295/3295 [==============================] - 5s 2ms/step - loss: 0.8090 - acc: 0.7129 - val_loss: 0.9479 - val_acc: 0.7431\n",
      "Epoch 5/100\n",
      "3295/3295 [==============================] - 5s 1ms/step - loss: 0.7288 - acc: 0.7527 - val_loss: 0.9240 - val_acc: 0.7516\n",
      "Epoch 6/100\n",
      "3295/3295 [==============================] - 5s 2ms/step - loss: 0.5959 - acc: 0.7933 - val_loss: 0.6571 - val_acc: 0.8266\n",
      "Epoch 7/100\n",
      "3295/3295 [==============================] - 5s 1ms/step - loss: 0.4767 - acc: 0.8458 - val_loss: 0.6050 - val_acc: 0.8266\n",
      "Epoch 8/100\n",
      "3295/3295 [==============================] - 5s 2ms/step - loss: 0.4043 - acc: 0.8643 - val_loss: 0.5579 - val_acc: 0.8528\n",
      "Epoch 9/100\n",
      "3295/3295 [==============================] - 5s 1ms/step - loss: 0.3125 - acc: 0.9038 - val_loss: 0.5678 - val_acc: 0.8528\n",
      "Epoch 10/100\n",
      "3295/3295 [==============================] - 5s 2ms/step - loss: 0.2867 - acc: 0.9093 - val_loss: 0.6301 - val_acc: 0.8344\n",
      "Epoch 11/100\n",
      "3295/3295 [==============================] - 5s 2ms/step - loss: 0.2978 - acc: 0.9059 - val_loss: 0.6807 - val_acc: 0.8301\n",
      "Epoch 12/100\n",
      "3295/3295 [==============================] - 5s 1ms/step - loss: 0.1843 - acc: 0.9381 - val_loss: 0.5759 - val_acc: 0.8485\n",
      "Epoch 13/100\n",
      "3295/3295 [==============================] - 5s 1ms/step - loss: 0.1740 - acc: 0.9423 - val_loss: 0.5270 - val_acc: 0.8754\n",
      "Epoch 14/100\n",
      "3295/3295 [==============================] - 5s 1ms/step - loss: 0.1800 - acc: 0.9451 - val_loss: 0.6912 - val_acc: 0.8301\n",
      "Epoch 15/100\n",
      "3295/3295 [==============================] - 5s 1ms/step - loss: 0.1490 - acc: 0.9451 - val_loss: 0.5817 - val_acc: 0.8684\n",
      "Epoch 16/100\n",
      "3295/3295 [==============================] - 5s 1ms/step - loss: 0.1609 - acc: 0.9451 - val_loss: 0.5749 - val_acc: 0.8811\n",
      "Epoch 17/100\n",
      "3295/3295 [==============================] - 5s 2ms/step - loss: 0.1280 - acc: 0.9596 - val_loss: 0.5789 - val_acc: 0.8783\n",
      "Epoch 18/100\n",
      "3295/3295 [==============================] - 5s 2ms/step - loss: 0.1234 - acc: 0.9551 - val_loss: 0.6273 - val_acc: 0.8691\n",
      "Epoch 19/100\n",
      "3295/3295 [==============================] - 5s 2ms/step - loss: 0.0937 - acc: 0.9709 - val_loss: 0.4426 - val_acc: 0.9023\n",
      "Epoch 20/100\n",
      "3295/3295 [==============================] - 5s 2ms/step - loss: 0.0855 - acc: 0.9712 - val_loss: 0.5360 - val_acc: 0.8931\n",
      "Epoch 21/100\n",
      "3295/3295 [==============================] - 5s 1ms/step - loss: 0.0925 - acc: 0.9684 - val_loss: 0.5338 - val_acc: 0.8938\n",
      "Epoch 22/100\n",
      "3295/3295 [==============================] - 5s 1ms/step - loss: 0.0853 - acc: 0.9727 - val_loss: 0.4469 - val_acc: 0.9016\n",
      "Epoch 23/100\n",
      "3295/3295 [==============================] - 5s 1ms/step - loss: 0.0720 - acc: 0.9751 - val_loss: 0.4808 - val_acc: 0.8974\n",
      "Epoch 24/100\n",
      "3295/3295 [==============================] - 5s 1ms/step - loss: 0.0391 - acc: 0.9879 - val_loss: 0.5274 - val_acc: 0.9016\n",
      "Epoch 25/100\n",
      "3295/3295 [==============================] - 5s 1ms/step - loss: 0.0434 - acc: 0.9842 - val_loss: 0.4992 - val_acc: 0.9023\n",
      "Epoch 26/100\n",
      "3295/3295 [==============================] - 5s 1ms/step - loss: 0.0310 - acc: 0.9903 - val_loss: 0.5425 - val_acc: 0.8896\n",
      "Epoch 27/100\n",
      "3295/3295 [==============================] - 5s 1ms/step - loss: 0.0458 - acc: 0.9866 - val_loss: 0.4849 - val_acc: 0.9052\n",
      "Epoch 28/100\n",
      "3295/3295 [==============================] - 5s 1ms/step - loss: 0.0655 - acc: 0.9757 - val_loss: 0.6950 - val_acc: 0.8606\n",
      "Epoch 29/100\n",
      "3295/3295 [==============================] - 5s 1ms/step - loss: 0.0653 - acc: 0.9775 - val_loss: 0.7323 - val_acc: 0.8613\n",
      "Epoch 30/100\n",
      "3295/3295 [==============================] - 5s 1ms/step - loss: 0.0710 - acc: 0.9745 - val_loss: 0.6348 - val_acc: 0.8762\n",
      "Epoch 31/100\n",
      "3295/3295 [==============================] - 5s 2ms/step - loss: 0.0711 - acc: 0.9763 - val_loss: 0.5893 - val_acc: 0.8924\n",
      "Epoch 32/100\n",
      "3295/3295 [==============================] - 5s 1ms/step - loss: 0.0447 - acc: 0.9833 - val_loss: 0.4926 - val_acc: 0.9080\n",
      "Epoch 33/100\n",
      "3295/3295 [==============================] - 5s 2ms/step - loss: 0.0560 - acc: 0.9821 - val_loss: 0.6306 - val_acc: 0.8839\n",
      "Epoch 34/100\n",
      "3295/3295 [==============================] - 5s 1ms/step - loss: 0.0380 - acc: 0.9845 - val_loss: 0.6023 - val_acc: 0.8917\n",
      "Epoch 35/100\n",
      "3295/3295 [==============================] - 5s 1ms/step - loss: 0.0419 - acc: 0.9863 - val_loss: 0.5226 - val_acc: 0.9144\n",
      "Epoch 36/100\n",
      "3295/3295 [==============================] - 5s 1ms/step - loss: 0.0585 - acc: 0.9818 - val_loss: 0.5052 - val_acc: 0.9158\n",
      "Epoch 37/100\n",
      "3295/3295 [==============================] - 5s 2ms/step - loss: 0.0241 - acc: 0.9903 - val_loss: 0.5687 - val_acc: 0.9108\n",
      "Epoch 38/100\n",
      "3295/3295 [==============================] - 5s 1ms/step - loss: 0.0409 - acc: 0.9882 - val_loss: 0.5396 - val_acc: 0.9137\n",
      "Epoch 39/100\n",
      "3295/3295 [==============================] - 5s 2ms/step - loss: 0.0359 - acc: 0.9869 - val_loss: 0.6037 - val_acc: 0.8938\n",
      "Epoch 40/100\n",
      "3295/3295 [==============================] - 5s 2ms/step - loss: 0.0334 - acc: 0.9885 - val_loss: 0.4739 - val_acc: 0.9186\n",
      "Epoch 41/100\n",
      "3295/3295 [==============================] - 5s 1ms/step - loss: 0.0366 - acc: 0.9863 - val_loss: 0.6137 - val_acc: 0.9038\n",
      "Epoch 42/100\n",
      "3295/3295 [==============================] - 5s 2ms/step - loss: 0.0448 - acc: 0.9863 - val_loss: 0.6697 - val_acc: 0.8960\n",
      "Epoch 43/100\n",
      "3295/3295 [==============================] - 5s 1ms/step - loss: 0.0419 - acc: 0.9857 - val_loss: 0.6688 - val_acc: 0.9002\n",
      "Epoch 44/100\n",
      "3295/3295 [==============================] - 5s 1ms/step - loss: 0.0366 - acc: 0.9894 - val_loss: 0.6012 - val_acc: 0.9094\n",
      "Epoch 45/100\n",
      "3295/3295 [==============================] - 5s 1ms/step - loss: 0.0521 - acc: 0.9836 - val_loss: 0.6178 - val_acc: 0.9151\n",
      "Epoch 46/100\n",
      "3295/3295 [==============================] - 5s 1ms/step - loss: 0.0523 - acc: 0.9827 - val_loss: 0.6773 - val_acc: 0.8995\n",
      "Epoch 47/100\n",
      "3295/3295 [==============================] - 5s 1ms/step - loss: 0.0351 - acc: 0.9863 - val_loss: 0.6583 - val_acc: 0.9009\n",
      "Epoch 48/100\n",
      "3295/3295 [==============================] - 5s 1ms/step - loss: 0.0366 - acc: 0.9903 - val_loss: 0.5921 - val_acc: 0.9108\n",
      "Epoch 49/100\n",
      "3295/3295 [==============================] - 5s 1ms/step - loss: 0.0414 - acc: 0.9894 - val_loss: 0.6342 - val_acc: 0.9108\n",
      "Epoch 50/100\n",
      "3295/3295 [==============================] - 5s 1ms/step - loss: 0.0226 - acc: 0.9951 - val_loss: 0.6569 - val_acc: 0.8988\n",
      "Epoch 51/100\n",
      "3295/3295 [==============================] - 5s 1ms/step - loss: 0.0298 - acc: 0.9924 - val_loss: 0.6032 - val_acc: 0.9158\n",
      "Epoch 52/100\n",
      "3295/3295 [==============================] - 5s 1ms/step - loss: 0.0322 - acc: 0.9891 - val_loss: 0.6744 - val_acc: 0.9137\n",
      "Epoch 53/100\n",
      "3295/3295 [==============================] - 5s 1ms/step - loss: 0.0245 - acc: 0.9912 - val_loss: 0.6781 - val_acc: 0.9094\n",
      "Epoch 54/100\n",
      "3295/3295 [==============================] - 5s 1ms/step - loss: 0.0994 - acc: 0.9736 - val_loss: 0.8132 - val_acc: 0.8903\n",
      "Epoch 55/100\n",
      "3295/3295 [==============================] - 5s 1ms/step - loss: 0.1047 - acc: 0.9730 - val_loss: 0.7261 - val_acc: 0.8967\n",
      "Epoch 56/100\n",
      "3295/3295 [==============================] - 5s 1ms/step - loss: 0.0614 - acc: 0.9836 - val_loss: 0.8642 - val_acc: 0.8889\n",
      "Epoch 57/100\n",
      "3295/3295 [==============================] - 5s 2ms/step - loss: 0.0643 - acc: 0.9821 - val_loss: 0.7196 - val_acc: 0.9030\n",
      "Epoch 58/100\n",
      "3295/3295 [==============================] - 5s 1ms/step - loss: 0.0221 - acc: 0.9918 - val_loss: 0.7505 - val_acc: 0.9038\n",
      "Epoch 59/100\n",
      "3295/3295 [==============================] - 5s 1ms/step - loss: 0.0356 - acc: 0.9903 - val_loss: 0.6700 - val_acc: 0.9094\n",
      "Epoch 60/100\n",
      "3295/3295 [==============================] - 5s 2ms/step - loss: 0.0185 - acc: 0.9951 - val_loss: 0.6948 - val_acc: 0.9130\n",
      "Epoch 61/100\n",
      "3295/3295 [==============================] - 5s 1ms/step - loss: 0.0390 - acc: 0.9873 - val_loss: 0.6788 - val_acc: 0.9108\n",
      "Epoch 62/100\n",
      "3295/3295 [==============================] - 5s 1ms/step - loss: 0.0165 - acc: 0.9948 - val_loss: 0.7385 - val_acc: 0.8974\n",
      "Epoch 63/100\n",
      "3295/3295 [==============================] - 5s 1ms/step - loss: 0.0252 - acc: 0.9921 - val_loss: 0.7204 - val_acc: 0.9101\n",
      "Epoch 64/100\n",
      "3295/3295 [==============================] - 5s 1ms/step - loss: 0.0316 - acc: 0.9906 - val_loss: 0.7624 - val_acc: 0.9009\n",
      "Epoch 65/100\n",
      "3295/3295 [==============================] - 5s 2ms/step - loss: 0.0256 - acc: 0.9918 - val_loss: 0.7382 - val_acc: 0.8995\n",
      "Epoch 66/100\n",
      "3295/3295 [==============================] - 5s 1ms/step - loss: 0.0141 - acc: 0.9936 - val_loss: 0.6813 - val_acc: 0.9087\n",
      "Epoch 67/100\n",
      "3295/3295 [==============================] - 5s 2ms/step - loss: 0.0096 - acc: 0.9964 - val_loss: 0.6746 - val_acc: 0.9158\n",
      "Epoch 68/100\n",
      "3295/3295 [==============================] - 5s 2ms/step - loss: 0.0091 - acc: 0.9970 - val_loss: 0.6118 - val_acc: 0.9165\n",
      "Epoch 69/100\n",
      "3295/3295 [==============================] - 5s 2ms/step - loss: 0.0126 - acc: 0.9954 - val_loss: 0.6818 - val_acc: 0.9151\n",
      "Epoch 70/100\n",
      "3295/3295 [==============================] - 5s 2ms/step - loss: 0.0196 - acc: 0.9945 - val_loss: 0.6504 - val_acc: 0.9165\n",
      "Epoch 71/100\n",
      "3295/3295 [==============================] - 5s 1ms/step - loss: 0.0142 - acc: 0.9954 - val_loss: 0.5949 - val_acc: 0.9243\n",
      "Epoch 72/100\n",
      "3295/3295 [==============================] - 5s 2ms/step - loss: 0.0198 - acc: 0.9930 - val_loss: 0.6703 - val_acc: 0.9186\n",
      "Epoch 73/100\n",
      "3295/3295 [==============================] - 5s 1ms/step - loss: 0.0243 - acc: 0.9933 - val_loss: 0.7226 - val_acc: 0.8938\n",
      "Epoch 74/100\n",
      "3295/3295 [==============================] - 5s 1ms/step - loss: 0.0619 - acc: 0.9842 - val_loss: 0.7785 - val_acc: 0.9009\n",
      "Epoch 75/100\n",
      "3295/3295 [==============================] - 5s 2ms/step - loss: 0.0691 - acc: 0.9839 - val_loss: 0.8457 - val_acc: 0.8981\n",
      "Epoch 76/100\n",
      "3295/3295 [==============================] - 5s 2ms/step - loss: 0.0518 - acc: 0.9863 - val_loss: 0.7388 - val_acc: 0.9158\n",
      "Epoch 77/100\n",
      "3295/3295 [==============================] - 5s 1ms/step - loss: 0.0473 - acc: 0.9866 - val_loss: 0.8299 - val_acc: 0.9101\n",
      "Epoch 78/100\n",
      "3295/3295 [==============================] - 5s 2ms/step - loss: 0.0512 - acc: 0.9885 - val_loss: 0.7542 - val_acc: 0.9165\n",
      "Epoch 79/100\n",
      "3295/3295 [==============================] - 5s 1ms/step - loss: 0.0458 - acc: 0.9879 - val_loss: 0.7931 - val_acc: 0.9108\n",
      "Epoch 80/100\n",
      "3295/3295 [==============================] - 5s 2ms/step - loss: 0.0388 - acc: 0.9897 - val_loss: 0.6431 - val_acc: 0.9229\n",
      "Epoch 81/100\n",
      "3295/3295 [==============================] - 5s 2ms/step - loss: 0.0372 - acc: 0.9915 - val_loss: 0.7494 - val_acc: 0.9144\n",
      "Epoch 82/100\n",
      "3295/3295 [==============================] - 5s 2ms/step - loss: 0.0239 - acc: 0.9930 - val_loss: 0.8303 - val_acc: 0.9094\n",
      "Epoch 83/100\n",
      "3295/3295 [==============================] - 5s 1ms/step - loss: 0.0222 - acc: 0.9945 - val_loss: 0.6596 - val_acc: 0.9151\n",
      "Epoch 84/100\n",
      "3295/3295 [==============================] - 5s 1ms/step - loss: 0.0289 - acc: 0.9936 - val_loss: 0.6955 - val_acc: 0.9137\n",
      "Epoch 85/100\n",
      "3295/3295 [==============================] - 5s 1ms/step - loss: 0.0180 - acc: 0.9939 - val_loss: 0.6870 - val_acc: 0.9200\n",
      "Epoch 86/100\n",
      "3295/3295 [==============================] - 5s 1ms/step - loss: 0.0104 - acc: 0.9970 - val_loss: 0.7067 - val_acc: 0.9186\n",
      "Epoch 87/100\n",
      "3295/3295 [==============================] - 5s 1ms/step - loss: 0.0122 - acc: 0.9954 - val_loss: 0.7169 - val_acc: 0.9137\n",
      "Epoch 88/100\n",
      "3295/3295 [==============================] - 5s 1ms/step - loss: 0.0059 - acc: 0.9979 - val_loss: 0.6487 - val_acc: 0.9264\n",
      "Epoch 89/100\n",
      "3295/3295 [==============================] - 5s 1ms/step - loss: 0.0076 - acc: 0.9979 - val_loss: 0.6999 - val_acc: 0.9122\n",
      "Epoch 90/100\n",
      "3295/3295 [==============================] - 5s 1ms/step - loss: 0.0218 - acc: 0.9933 - val_loss: 0.7931 - val_acc: 0.9094\n",
      "Epoch 91/100\n",
      "3295/3295 [==============================] - 5s 1ms/step - loss: 0.0266 - acc: 0.9930 - val_loss: 1.1229 - val_acc: 0.8698\n",
      "Epoch 92/100\n",
      "3295/3295 [==============================] - 5s 1ms/step - loss: 0.0567 - acc: 0.9866 - val_loss: 0.8277 - val_acc: 0.9080\n",
      "Epoch 93/100\n",
      "3295/3295 [==============================] - 5s 2ms/step - loss: 0.0247 - acc: 0.9921 - val_loss: 0.7545 - val_acc: 0.9066\n",
      "Epoch 94/100\n",
      "3295/3295 [==============================] - 5s 1ms/step - loss: 0.0145 - acc: 0.9958 - val_loss: 0.8134 - val_acc: 0.9101\n",
      "Epoch 95/100\n",
      "3295/3295 [==============================] - 5s 2ms/step - loss: 0.0224 - acc: 0.9939 - val_loss: 0.8457 - val_acc: 0.9094\n",
      "Epoch 96/100\n",
      "3295/3295 [==============================] - 5s 1ms/step - loss: 0.0297 - acc: 0.9936 - val_loss: 0.8995 - val_acc: 0.9038\n",
      "Epoch 97/100\n",
      "3295/3295 [==============================] - 5s 1ms/step - loss: 0.0316 - acc: 0.9903 - val_loss: 0.7748 - val_acc: 0.9108\n",
      "Epoch 98/100\n",
      "3295/3295 [==============================] - 5s 1ms/step - loss: 0.0194 - acc: 0.9936 - val_loss: 0.7529 - val_acc: 0.9066\n",
      "Epoch 99/100\n",
      "3295/3295 [==============================] - 5s 1ms/step - loss: 0.0219 - acc: 0.9951 - val_loss: 0.7897 - val_acc: 0.9087\n",
      "Epoch 100/100\n",
      "3295/3295 [==============================] - 5s 1ms/step - loss: 0.0128 - acc: 0.9964 - val_loss: 0.7492 - val_acc: 0.9130\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7f3b35751da0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depth_Seprable_cnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:54: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:55: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(30, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:56: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(9, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:57: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(30, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:58: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(11, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:59: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(30, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:60: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:61: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(30, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:62: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:63: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(30, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:64: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(11, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:65: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(30, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:66: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(45, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3295 samples, validate on 1413 samples\n",
      "Epoch 1/50\n",
      "3295/3295 [==============================] - 5s 1ms/step - loss: 1.3826 - acc: 0.2816 - val_loss: 1.3660 - val_acc: 0.2626\n",
      "Epoch 2/50\n",
      "3295/3295 [==============================] - 2s 742us/step - loss: 1.3439 - acc: 0.2713 - val_loss: 1.3844 - val_acc: 0.2689\n",
      "Epoch 3/50\n",
      "3295/3295 [==============================] - 2s 731us/step - loss: 1.3845 - acc: 0.2695 - val_loss: 1.3845 - val_acc: 0.2689\n",
      "Epoch 4/50\n",
      "3295/3295 [==============================] - 2s 734us/step - loss: 1.3837 - acc: 0.2744 - val_loss: 1.3847 - val_acc: 0.2689\n",
      "Epoch 5/50\n",
      "3295/3295 [==============================] - 2s 736us/step - loss: 1.3838 - acc: 0.2616 - val_loss: 1.3843 - val_acc: 0.2689\n",
      "Epoch 6/50\n",
      "3295/3295 [==============================] - 2s 739us/step - loss: 1.3834 - acc: 0.2744 - val_loss: 1.3852 - val_acc: 0.2689\n",
      "Epoch 7/50\n",
      "3295/3295 [==============================] - 2s 734us/step - loss: 1.3836 - acc: 0.2601 - val_loss: 1.3844 - val_acc: 0.2689\n",
      "Epoch 8/50\n",
      "3295/3295 [==============================] - 2s 735us/step - loss: 1.3834 - acc: 0.2744 - val_loss: 1.3845 - val_acc: 0.2689\n",
      "Epoch 9/50\n",
      "3295/3295 [==============================] - 2s 735us/step - loss: 1.3838 - acc: 0.2744 - val_loss: 1.3844 - val_acc: 0.2689\n",
      "Epoch 10/50\n",
      "3295/3295 [==============================] - 2s 733us/step - loss: 1.3836 - acc: 0.2744 - val_loss: 1.3844 - val_acc: 0.2689\n",
      "Epoch 11/50\n",
      "3295/3295 [==============================] - 2s 735us/step - loss: 1.3834 - acc: 0.2744 - val_loss: 1.3844 - val_acc: 0.2689\n",
      "Epoch 12/50\n",
      "3295/3295 [==============================] - 2s 734us/step - loss: 1.3834 - acc: 0.2744 - val_loss: 1.3845 - val_acc: 0.2689\n",
      "Epoch 13/50\n",
      "3295/3295 [==============================] - 2s 743us/step - loss: 1.3835 - acc: 0.2744 - val_loss: 1.3847 - val_acc: 0.2689\n",
      "Epoch 14/50\n",
      "3295/3295 [==============================] - 2s 738us/step - loss: 1.3833 - acc: 0.2744 - val_loss: 1.3844 - val_acc: 0.2689\n",
      "Epoch 15/50\n",
      "3295/3295 [==============================] - 2s 741us/step - loss: 1.3834 - acc: 0.2744 - val_loss: 1.3847 - val_acc: 0.2689\n",
      "Epoch 16/50\n",
      "3295/3295 [==============================] - 2s 737us/step - loss: 1.3835 - acc: 0.2628 - val_loss: 1.3845 - val_acc: 0.2689\n",
      "Epoch 17/50\n",
      "3295/3295 [==============================] - 2s 738us/step - loss: 1.3835 - acc: 0.2744 - val_loss: 1.3844 - val_acc: 0.2689\n",
      "Epoch 18/50\n",
      "3295/3295 [==============================] - 2s 741us/step - loss: 1.3835 - acc: 0.2744 - val_loss: 1.3845 - val_acc: 0.2689\n",
      "Epoch 19/50\n",
      "3295/3295 [==============================] - 2s 740us/step - loss: 1.3834 - acc: 0.2744 - val_loss: 1.3844 - val_acc: 0.2689\n",
      "Epoch 20/50\n",
      "3295/3295 [==============================] - 2s 734us/step - loss: 1.3835 - acc: 0.2744 - val_loss: 1.3844 - val_acc: 0.2689\n",
      "Epoch 21/50\n",
      "3295/3295 [==============================] - 2s 737us/step - loss: 1.3832 - acc: 0.2744 - val_loss: 1.3847 - val_acc: 0.2689\n",
      "Epoch 22/50\n",
      "3295/3295 [==============================] - 2s 737us/step - loss: 1.3833 - acc: 0.2744 - val_loss: 1.3847 - val_acc: 0.2689\n",
      "Epoch 23/50\n",
      "3295/3295 [==============================] - 2s 742us/step - loss: 1.3833 - acc: 0.2744 - val_loss: 1.3846 - val_acc: 0.2689\n",
      "Epoch 24/50\n",
      "3295/3295 [==============================] - 2s 738us/step - loss: 1.3835 - acc: 0.2744 - val_loss: 1.3847 - val_acc: 0.2689\n",
      "Epoch 25/50\n",
      "3295/3295 [==============================] - 2s 738us/step - loss: 1.3833 - acc: 0.2744 - val_loss: 1.3844 - val_acc: 0.2689\n",
      "Epoch 26/50\n",
      "3295/3295 [==============================] - 2s 736us/step - loss: 1.3833 - acc: 0.2744 - val_loss: 1.3846 - val_acc: 0.2689\n",
      "Epoch 27/50\n",
      "3295/3295 [==============================] - 2s 739us/step - loss: 1.3832 - acc: 0.2744 - val_loss: 1.3845 - val_acc: 0.2689\n",
      "Epoch 28/50\n",
      "3295/3295 [==============================] - 2s 736us/step - loss: 1.3834 - acc: 0.2744 - val_loss: 1.3844 - val_acc: 0.2689\n",
      "Epoch 29/50\n",
      "3295/3295 [==============================] - 2s 735us/step - loss: 1.3832 - acc: 0.2744 - val_loss: 1.3845 - val_acc: 0.2689\n",
      "Epoch 30/50\n",
      "3295/3295 [==============================] - 2s 738us/step - loss: 1.3833 - acc: 0.2744 - val_loss: 1.3848 - val_acc: 0.2689\n",
      "Epoch 31/50\n",
      "3295/3295 [==============================] - 2s 739us/step - loss: 1.3833 - acc: 0.2744 - val_loss: 1.3846 - val_acc: 0.2689\n",
      "Epoch 32/50\n",
      "3295/3295 [==============================] - 2s 734us/step - loss: 1.3834 - acc: 0.2744 - val_loss: 1.3843 - val_acc: 0.2689\n",
      "Epoch 33/50\n",
      "3295/3295 [==============================] - 2s 735us/step - loss: 1.3832 - acc: 0.2744 - val_loss: 1.3846 - val_acc: 0.2689\n",
      "Epoch 34/50\n",
      "3295/3295 [==============================] - 2s 737us/step - loss: 1.3832 - acc: 0.2744 - val_loss: 1.3845 - val_acc: 0.2689\n",
      "Epoch 35/50\n",
      "3295/3295 [==============================] - 2s 738us/step - loss: 1.3833 - acc: 0.2744 - val_loss: 1.3845 - val_acc: 0.2689\n",
      "Epoch 36/50\n",
      "3295/3295 [==============================] - 2s 736us/step - loss: 1.3832 - acc: 0.2744 - val_loss: 1.3845 - val_acc: 0.2689\n",
      "Epoch 37/50\n",
      "3295/3295 [==============================] - 2s 741us/step - loss: 1.3834 - acc: 0.2744 - val_loss: 1.3845 - val_acc: 0.2689\n",
      "Epoch 38/50\n",
      "3295/3295 [==============================] - 2s 736us/step - loss: 1.3833 - acc: 0.2744 - val_loss: 1.3846 - val_acc: 0.2689\n",
      "Epoch 39/50\n",
      "3295/3295 [==============================] - 2s 738us/step - loss: 1.3833 - acc: 0.2744 - val_loss: 1.3845 - val_acc: 0.2689\n",
      "Epoch 40/50\n",
      "3295/3295 [==============================] - 2s 756us/step - loss: 1.3832 - acc: 0.2744 - val_loss: 1.3846 - val_acc: 0.2689\n",
      "Epoch 41/50\n",
      "3295/3295 [==============================] - 2s 751us/step - loss: 1.3832 - acc: 0.2744 - val_loss: 1.3844 - val_acc: 0.2689\n",
      "Epoch 42/50\n",
      "3295/3295 [==============================] - 2s 752us/step - loss: 1.3832 - acc: 0.2744 - val_loss: 1.3846 - val_acc: 0.2689\n",
      "Epoch 43/50\n",
      "3295/3295 [==============================] - 2s 751us/step - loss: 1.3835 - acc: 0.2744 - val_loss: 1.3845 - val_acc: 0.2689\n",
      "Epoch 44/50\n",
      "3295/3295 [==============================] - 2s 745us/step - loss: 1.3832 - acc: 0.2744 - val_loss: 1.3846 - val_acc: 0.2689\n",
      "Epoch 45/50\n",
      "3295/3295 [==============================] - 2s 736us/step - loss: 1.3832 - acc: 0.2744 - val_loss: 1.3846 - val_acc: 0.2689\n",
      "Epoch 46/50\n",
      "3295/3295 [==============================] - 2s 738us/step - loss: 1.3832 - acc: 0.2744 - val_loss: 1.3845 - val_acc: 0.2689\n",
      "Epoch 47/50\n",
      "3295/3295 [==============================] - 2s 738us/step - loss: 1.3832 - acc: 0.2744 - val_loss: 1.3845 - val_acc: 0.2689\n",
      "Epoch 48/50\n",
      "3295/3295 [==============================] - 2s 742us/step - loss: 1.3832 - acc: 0.2744 - val_loss: 1.3846 - val_acc: 0.2689\n",
      "Epoch 49/50\n",
      "3295/3295 [==============================] - 2s 742us/step - loss: 1.3833 - acc: 0.2744 - val_loss: 1.3845 - val_acc: 0.2689\n",
      "Epoch 50/50\n",
      "3295/3295 [==============================] - 2s 736us/step - loss: 1.3832 - acc: 0.2744 - val_loss: 1.3845 - val_acc: 0.2689\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7f3f62bc5278>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edgespeechnetb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:20: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(30, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:21: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(45, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:22: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(33, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:23: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(45, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:24: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(35, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:25: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(45, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3295 samples, validate on 1413 samples\n",
      "Epoch 1/50\n",
      "3295/3295 [==============================] - 5s 1ms/step - loss: 1.2184 - acc: 0.4076 - val_loss: 1.0761 - val_acc: 0.4317\n",
      "Epoch 2/50\n",
      "3295/3295 [==============================] - 3s 801us/step - loss: 0.9549 - acc: 0.5624 - val_loss: 0.9161 - val_acc: 0.5924\n",
      "Epoch 3/50\n",
      "3295/3295 [==============================] - 3s 797us/step - loss: 0.8727 - acc: 0.6231 - val_loss: 0.8135 - val_acc: 0.6617\n",
      "Epoch 4/50\n",
      "3295/3295 [==============================] - 3s 796us/step - loss: 0.7863 - acc: 0.6744 - val_loss: 0.8460 - val_acc: 0.6992\n",
      "Epoch 5/50\n",
      "3295/3295 [==============================] - 3s 796us/step - loss: 0.6516 - acc: 0.7539 - val_loss: 0.6051 - val_acc: 0.7849\n",
      "Epoch 6/50\n",
      "3295/3295 [==============================] - 3s 796us/step - loss: 0.5468 - acc: 0.8036 - val_loss: 0.5859 - val_acc: 0.7757\n",
      "Epoch 7/50\n",
      "3295/3295 [==============================] - 3s 797us/step - loss: 0.4808 - acc: 0.8252 - val_loss: 0.6021 - val_acc: 0.8125\n",
      "Epoch 8/50\n",
      "3295/3295 [==============================] - 3s 795us/step - loss: 0.4384 - acc: 0.8434 - val_loss: 0.4861 - val_acc: 0.8139\n",
      "Epoch 9/50\n",
      "3295/3295 [==============================] - 3s 800us/step - loss: 0.3479 - acc: 0.8734 - val_loss: 0.4050 - val_acc: 0.8592\n",
      "Epoch 10/50\n",
      "3295/3295 [==============================] - 3s 797us/step - loss: 0.3562 - acc: 0.8777 - val_loss: 0.5307 - val_acc: 0.8323\n",
      "Epoch 11/50\n",
      "3295/3295 [==============================] - 3s 799us/step - loss: 0.3450 - acc: 0.8734 - val_loss: 0.3666 - val_acc: 0.8705\n",
      "Epoch 12/50\n",
      "3295/3295 [==============================] - 3s 794us/step - loss: 0.3018 - acc: 0.8844 - val_loss: 0.3871 - val_acc: 0.8648\n",
      "Epoch 13/50\n",
      "3295/3295 [==============================] - 3s 796us/step - loss: 0.2641 - acc: 0.9050 - val_loss: 0.3492 - val_acc: 0.8712\n",
      "Epoch 14/50\n",
      "3295/3295 [==============================] - 3s 810us/step - loss: 0.2319 - acc: 0.9126 - val_loss: 0.4088 - val_acc: 0.8556\n",
      "Epoch 15/50\n",
      "3295/3295 [==============================] - 3s 810us/step - loss: 0.1959 - acc: 0.9305 - val_loss: 0.3662 - val_acc: 0.8868\n",
      "Epoch 16/50\n",
      "3295/3295 [==============================] - 3s 795us/step - loss: 0.2122 - acc: 0.9278 - val_loss: 0.3293 - val_acc: 0.8967\n",
      "Epoch 17/50\n",
      "3295/3295 [==============================] - 3s 794us/step - loss: 0.1618 - acc: 0.9423 - val_loss: 0.3219 - val_acc: 0.8946\n",
      "Epoch 18/50\n",
      "3295/3295 [==============================] - 3s 799us/step - loss: 0.1545 - acc: 0.9472 - val_loss: 0.2903 - val_acc: 0.8960\n",
      "Epoch 19/50\n",
      "3295/3295 [==============================] - 3s 797us/step - loss: 0.1444 - acc: 0.9530 - val_loss: 0.3183 - val_acc: 0.9066\n",
      "Epoch 20/50\n",
      "3295/3295 [==============================] - 3s 841us/step - loss: 0.1649 - acc: 0.9442 - val_loss: 0.3182 - val_acc: 0.8981\n",
      "Epoch 21/50\n",
      "3295/3295 [==============================] - 3s 888us/step - loss: 0.1458 - acc: 0.9514 - val_loss: 0.3521 - val_acc: 0.9016\n",
      "Epoch 22/50\n",
      "3295/3295 [==============================] - 3s 798us/step - loss: 0.1239 - acc: 0.9602 - val_loss: 0.3134 - val_acc: 0.9087\n",
      "Epoch 23/50\n",
      "3295/3295 [==============================] - 3s 791us/step - loss: 0.1145 - acc: 0.9605 - val_loss: 0.2807 - val_acc: 0.9023\n",
      "Epoch 24/50\n",
      "3295/3295 [==============================] - 3s 796us/step - loss: 0.1026 - acc: 0.9654 - val_loss: 0.3093 - val_acc: 0.9101\n",
      "Epoch 25/50\n",
      "3295/3295 [==============================] - 3s 792us/step - loss: 0.0970 - acc: 0.9687 - val_loss: 0.2932 - val_acc: 0.9073\n",
      "Epoch 26/50\n",
      "3295/3295 [==============================] - 3s 798us/step - loss: 0.1172 - acc: 0.9621 - val_loss: 0.3095 - val_acc: 0.9023\n",
      "Epoch 27/50\n",
      "3295/3295 [==============================] - 3s 801us/step - loss: 0.0969 - acc: 0.9678 - val_loss: 0.2835 - val_acc: 0.9200\n",
      "Epoch 28/50\n",
      "3295/3295 [==============================] - 3s 798us/step - loss: 0.0688 - acc: 0.9797 - val_loss: 0.3090 - val_acc: 0.9130\n",
      "Epoch 29/50\n",
      "3295/3295 [==============================] - 3s 798us/step - loss: 0.0705 - acc: 0.9757 - val_loss: 0.2819 - val_acc: 0.9165\n",
      "Epoch 30/50\n",
      "3295/3295 [==============================] - 3s 797us/step - loss: 0.0638 - acc: 0.9794 - val_loss: 0.2920 - val_acc: 0.9335\n",
      "Epoch 31/50\n",
      "3295/3295 [==============================] - 3s 795us/step - loss: 0.0791 - acc: 0.9797 - val_loss: 0.3181 - val_acc: 0.9052\n",
      "Epoch 32/50\n",
      "3295/3295 [==============================] - 3s 801us/step - loss: 0.0903 - acc: 0.9666 - val_loss: 0.5110 - val_acc: 0.8995\n",
      "Epoch 33/50\n",
      "3295/3295 [==============================] - 3s 795us/step - loss: 0.0746 - acc: 0.9766 - val_loss: 0.3433 - val_acc: 0.9016\n",
      "Epoch 34/50\n",
      "3295/3295 [==============================] - 3s 796us/step - loss: 0.0557 - acc: 0.9833 - val_loss: 0.3184 - val_acc: 0.9016\n",
      "Epoch 35/50\n",
      "3295/3295 [==============================] - 3s 798us/step - loss: 0.0627 - acc: 0.9785 - val_loss: 0.2758 - val_acc: 0.9299\n",
      "Epoch 36/50\n",
      "3295/3295 [==============================] - 3s 796us/step - loss: 0.0395 - acc: 0.9903 - val_loss: 0.2176 - val_acc: 0.9349\n",
      "Epoch 37/50\n",
      "3295/3295 [==============================] - 3s 794us/step - loss: 0.0808 - acc: 0.9760 - val_loss: 0.2630 - val_acc: 0.9193\n",
      "Epoch 38/50\n",
      "3295/3295 [==============================] - 3s 798us/step - loss: 0.0658 - acc: 0.9775 - val_loss: 0.2575 - val_acc: 0.9335\n",
      "Epoch 39/50\n",
      "3295/3295 [==============================] - 3s 792us/step - loss: 0.0469 - acc: 0.9876 - val_loss: 0.2910 - val_acc: 0.9236\n",
      "Epoch 40/50\n",
      "3295/3295 [==============================] - 3s 798us/step - loss: 0.0643 - acc: 0.9781 - val_loss: 0.3109 - val_acc: 0.9243\n",
      "Epoch 41/50\n",
      "3295/3295 [==============================] - 3s 797us/step - loss: 0.0573 - acc: 0.9827 - val_loss: 0.3241 - val_acc: 0.9186\n",
      "Epoch 42/50\n",
      "3295/3295 [==============================] - 3s 796us/step - loss: 0.0407 - acc: 0.9860 - val_loss: 0.3144 - val_acc: 0.9257\n",
      "Epoch 43/50\n",
      "3295/3295 [==============================] - 3s 795us/step - loss: 0.0392 - acc: 0.9879 - val_loss: 0.4051 - val_acc: 0.9193\n",
      "Epoch 44/50\n",
      "3295/3295 [==============================] - 3s 794us/step - loss: 0.0455 - acc: 0.9839 - val_loss: 0.3183 - val_acc: 0.9250\n",
      "Epoch 45/50\n",
      "3295/3295 [==============================] - 3s 796us/step - loss: 0.0622 - acc: 0.9781 - val_loss: 0.2992 - val_acc: 0.9130\n",
      "Epoch 46/50\n",
      "3295/3295 [==============================] - 3s 794us/step - loss: 0.0456 - acc: 0.9863 - val_loss: 0.2393 - val_acc: 0.9285\n",
      "Epoch 47/50\n",
      "3295/3295 [==============================] - 3s 794us/step - loss: 0.0257 - acc: 0.9930 - val_loss: 0.3155 - val_acc: 0.9335\n",
      "Epoch 48/50\n",
      "3295/3295 [==============================] - 3s 797us/step - loss: 0.0367 - acc: 0.9885 - val_loss: 0.2802 - val_acc: 0.9321\n",
      "Epoch 49/50\n",
      "3295/3295 [==============================] - 3s 799us/step - loss: 0.0411 - acc: 0.9857 - val_loss: 0.3756 - val_acc: 0.9285\n",
      "Epoch 50/50\n",
      "3295/3295 [==============================] - 3s 812us/step - loss: 0.0435 - acc: 0.9860 - val_loss: 0.3349 - val_acc: 0.9130\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7f3b2ed4fb00>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edgespeechnetd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:20: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:22: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, kernel_size=(10, 4), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:23: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3295 samples, validate on 1413 samples\n",
      "Epoch 1/50\n",
      "3295/3295 [==============================] - 5s 1ms/step - loss: 1.2302 - acc: 0.4291 - val_loss: 1.0426 - val_acc: 0.5032\n",
      "Epoch 2/50\n",
      "3295/3295 [==============================] - 3s 812us/step - loss: 0.9511 - acc: 0.5642 - val_loss: 0.9083 - val_acc: 0.6001\n",
      "Epoch 3/50\n",
      "3295/3295 [==============================] - 3s 818us/step - loss: 0.9162 - acc: 0.5839 - val_loss: 0.9229 - val_acc: 0.6051\n",
      "Epoch 4/50\n",
      "3295/3295 [==============================] - 3s 810us/step - loss: 0.9210 - acc: 0.5833 - val_loss: 0.9572 - val_acc: 0.5718\n",
      "Epoch 5/50\n",
      "3295/3295 [==============================] - 3s 812us/step - loss: 0.8565 - acc: 0.6303 - val_loss: 0.8060 - val_acc: 0.6752\n",
      "Epoch 6/50\n",
      "3295/3295 [==============================] - 3s 811us/step - loss: 0.7428 - acc: 0.6874 - val_loss: 0.6987 - val_acc: 0.7431\n",
      "Epoch 7/50\n",
      "3295/3295 [==============================] - 3s 814us/step - loss: 0.6401 - acc: 0.7469 - val_loss: 0.6390 - val_acc: 0.7466\n",
      "Epoch 8/50\n",
      "3295/3295 [==============================] - 3s 810us/step - loss: 0.5725 - acc: 0.7803 - val_loss: 0.5630 - val_acc: 0.7665\n",
      "Epoch 9/50\n",
      "3295/3295 [==============================] - 3s 809us/step - loss: 0.5127 - acc: 0.8109 - val_loss: 0.5055 - val_acc: 0.8004\n",
      "Epoch 10/50\n",
      "3295/3295 [==============================] - 3s 811us/step - loss: 0.4647 - acc: 0.8352 - val_loss: 0.4825 - val_acc: 0.8160\n",
      "Epoch 11/50\n",
      "3295/3295 [==============================] - 3s 813us/step - loss: 0.3917 - acc: 0.8528 - val_loss: 0.4283 - val_acc: 0.8323\n",
      "Epoch 12/50\n",
      "3295/3295 [==============================] - 3s 815us/step - loss: 0.3339 - acc: 0.8750 - val_loss: 0.4334 - val_acc: 0.8450\n",
      "Epoch 13/50\n",
      "3295/3295 [==============================] - 3s 812us/step - loss: 0.3153 - acc: 0.8862 - val_loss: 0.4110 - val_acc: 0.8372\n",
      "Epoch 14/50\n",
      "3295/3295 [==============================] - 3s 819us/step - loss: 0.3159 - acc: 0.8895 - val_loss: 0.4072 - val_acc: 0.8549\n",
      "Epoch 15/50\n",
      "3295/3295 [==============================] - 3s 818us/step - loss: 0.2955 - acc: 0.8956 - val_loss: 0.3391 - val_acc: 0.8811\n",
      "Epoch 16/50\n",
      "3295/3295 [==============================] - 3s 816us/step - loss: 0.2389 - acc: 0.9190 - val_loss: 0.3421 - val_acc: 0.8846\n",
      "Epoch 17/50\n",
      "3295/3295 [==============================] - 3s 809us/step - loss: 0.2257 - acc: 0.9214 - val_loss: 0.3565 - val_acc: 0.8776\n",
      "Epoch 18/50\n",
      "3295/3295 [==============================] - 3s 808us/step - loss: 0.1873 - acc: 0.9357 - val_loss: 0.3099 - val_acc: 0.9045\n",
      "Epoch 19/50\n",
      "3295/3295 [==============================] - 3s 808us/step - loss: 0.2137 - acc: 0.9235 - val_loss: 0.3364 - val_acc: 0.8769\n",
      "Epoch 20/50\n",
      "3295/3295 [==============================] - 3s 810us/step - loss: 0.1672 - acc: 0.9369 - val_loss: 0.3158 - val_acc: 0.9080\n",
      "Epoch 21/50\n",
      "3295/3295 [==============================] - 3s 810us/step - loss: 0.1619 - acc: 0.9454 - val_loss: 0.3291 - val_acc: 0.8931\n",
      "Epoch 22/50\n",
      "3295/3295 [==============================] - 3s 812us/step - loss: 0.1490 - acc: 0.9514 - val_loss: 0.2972 - val_acc: 0.9087\n",
      "Epoch 23/50\n",
      "3295/3295 [==============================] - 3s 809us/step - loss: 0.1198 - acc: 0.9587 - val_loss: 0.3036 - val_acc: 0.8981\n",
      "Epoch 24/50\n",
      "3295/3295 [==============================] - 3s 809us/step - loss: 0.1326 - acc: 0.9551 - val_loss: 0.3979 - val_acc: 0.8776\n",
      "Epoch 25/50\n",
      "3295/3295 [==============================] - 3s 813us/step - loss: 0.1594 - acc: 0.9472 - val_loss: 0.3169 - val_acc: 0.8967\n",
      "Epoch 26/50\n",
      "3295/3295 [==============================] - 3s 808us/step - loss: 0.1072 - acc: 0.9624 - val_loss: 0.3220 - val_acc: 0.8995\n",
      "Epoch 27/50\n",
      "3295/3295 [==============================] - 3s 810us/step - loss: 0.1104 - acc: 0.9566 - val_loss: 0.3338 - val_acc: 0.8981\n",
      "Epoch 28/50\n",
      "3295/3295 [==============================] - 3s 808us/step - loss: 0.1012 - acc: 0.9624 - val_loss: 0.2936 - val_acc: 0.9122\n",
      "Epoch 29/50\n",
      "3295/3295 [==============================] - 3s 808us/step - loss: 0.0992 - acc: 0.9675 - val_loss: 0.4272 - val_acc: 0.8839\n",
      "Epoch 30/50\n",
      "3295/3295 [==============================] - 3s 808us/step - loss: 0.1138 - acc: 0.9648 - val_loss: 0.3432 - val_acc: 0.8953\n",
      "Epoch 31/50\n",
      "3295/3295 [==============================] - 3s 809us/step - loss: 0.0746 - acc: 0.9760 - val_loss: 0.2946 - val_acc: 0.9172\n",
      "Epoch 32/50\n",
      "3295/3295 [==============================] - 3s 810us/step - loss: 0.1065 - acc: 0.9666 - val_loss: 0.3326 - val_acc: 0.9115\n",
      "Epoch 33/50\n",
      "3295/3295 [==============================] - 3s 808us/step - loss: 0.0850 - acc: 0.9690 - val_loss: 0.4287 - val_acc: 0.8974\n",
      "Epoch 34/50\n",
      "3295/3295 [==============================] - 3s 811us/step - loss: 0.0745 - acc: 0.9754 - val_loss: 0.3334 - val_acc: 0.9073\n",
      "Epoch 35/50\n",
      "3295/3295 [==============================] - 3s 813us/step - loss: 0.0784 - acc: 0.9739 - val_loss: 0.3290 - val_acc: 0.9151\n",
      "Epoch 36/50\n",
      "3295/3295 [==============================] - 3s 812us/step - loss: 0.0494 - acc: 0.9836 - val_loss: 0.3695 - val_acc: 0.9059\n",
      "Epoch 37/50\n",
      "3295/3295 [==============================] - 3s 812us/step - loss: 0.0560 - acc: 0.9797 - val_loss: 0.3894 - val_acc: 0.9052\n",
      "Epoch 38/50\n",
      "3295/3295 [==============================] - 3s 812us/step - loss: 0.0609 - acc: 0.9769 - val_loss: 0.3958 - val_acc: 0.9073\n",
      "Epoch 39/50\n",
      "3295/3295 [==============================] - 3s 808us/step - loss: 0.0529 - acc: 0.9803 - val_loss: 0.3192 - val_acc: 0.9200\n",
      "Epoch 40/50\n",
      "3295/3295 [==============================] - 3s 808us/step - loss: 0.0368 - acc: 0.9894 - val_loss: 0.3819 - val_acc: 0.9122\n",
      "Epoch 41/50\n",
      "3295/3295 [==============================] - 3s 808us/step - loss: 0.0888 - acc: 0.9721 - val_loss: 0.3171 - val_acc: 0.9052\n",
      "Epoch 42/50\n",
      "3295/3295 [==============================] - 3s 809us/step - loss: 0.0905 - acc: 0.9657 - val_loss: 0.3621 - val_acc: 0.9130\n",
      "Epoch 43/50\n",
      "3295/3295 [==============================] - 3s 809us/step - loss: 0.0738 - acc: 0.9721 - val_loss: 0.3644 - val_acc: 0.9073\n",
      "Epoch 44/50\n",
      "3295/3295 [==============================] - 3s 812us/step - loss: 0.0671 - acc: 0.9760 - val_loss: 0.3410 - val_acc: 0.9200\n",
      "Epoch 45/50\n",
      "3295/3295 [==============================] - 3s 810us/step - loss: 0.0776 - acc: 0.9739 - val_loss: 0.3549 - val_acc: 0.9045\n",
      "Epoch 46/50\n",
      "3295/3295 [==============================] - 3s 809us/step - loss: 0.0832 - acc: 0.9724 - val_loss: 0.3679 - val_acc: 0.9087\n",
      "Epoch 47/50\n",
      "3295/3295 [==============================] - 3s 814us/step - loss: 0.0562 - acc: 0.9815 - val_loss: 0.4341 - val_acc: 0.9038\n",
      "Epoch 48/50\n",
      "3295/3295 [==============================] - 3s 810us/step - loss: 0.1085 - acc: 0.9684 - val_loss: 0.3257 - val_acc: 0.9094\n",
      "Epoch 49/50\n",
      "3295/3295 [==============================] - 3s 810us/step - loss: 0.1128 - acc: 0.9621 - val_loss: 0.3403 - val_acc: 0.9094\n",
      "Epoch 50/50\n",
      "3295/3295 [==============================] - 3s 808us/step - loss: 0.0644 - acc: 0.9788 - val_loss: 0.3406 - val_acc: 0.9186\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "trainable_stft (Melspectrogr (None, 128, 94, 1)        296064    \n",
      "_________________________________________________________________\n",
      "additive_noise_6 (AdditiveNo (None, 128, 94, 1)        0         \n",
      "_________________________________________________________________\n",
      "normalization2d_6 (Normaliza (None, 128, 94, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_43 (Conv2D)           (None, 109, 87, 64)       10304     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 109, 43, 32)       0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 109, 43, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_44 (Conv2D)           (None, 64, 34, 29)        279104    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 64, 17, 14)        0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 64, 17, 14)        0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 15232)             0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               1949824   \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 2,535,812\n",
      "Trainable params: 2,239,748\n",
      "Non-trainable params: 296,064\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7f3b2d428c50>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__notebook__.ipynb  __output__.json  logs\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__notebook__.ipynb  __output__.json\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'modl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-bc088353b3da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'modl' is not defined"
     ]
    }
   ],
   "source": [
    "print(modl)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
