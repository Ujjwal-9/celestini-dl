{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\nfrom os.path import isdir, join\nimport librosa\nfrom tqdm import tqdm\n# Any results you write to the current directory are saved as output.\nimport tensorflow as tf\nif tf.test.gpu_device_name():\n    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\nelse:\n    print(\"Please install GPU version of TF\")","execution_count":2,"outputs":[{"output_type":"stream","text":"['train', 'sample_submission.csv']\nDefault GPU Device: /device:GPU:0\n","name":"stdout"}]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# os.listdir(\"../input/dataasdfasd/\")\n# audio_file_path = \"../input/dataasdfasd/output.wav\"\n# os.linesep()\n# samps,sr = librosa.load(audio_file_path, mono=True, sr=None)\n# mfcc = librosa.feature.mfcc(samps, sr = sr)z\n# pad_width = max_pad - mfcc.shape[1]\n# mfcc = np.pad(mfcc, pad_width=((0, 0), (0, pad_width)), mode='constant')\naudio_path = \"../input/train/audio/\"","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# all audio dirs\ndirs = [f for f in os.listdir(audio_path) if os.path.isdir(join(audio_path, f))]\ndirs.sort()","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(dirs)","execution_count":5,"outputs":[{"output_type":"stream","text":"['_background_noise_', 'bed', 'bird', 'cat', 'dog', 'down', 'eight', 'five', 'four', 'go', 'happy', 'house', 'left', 'marvin', 'nine', 'no', 'off', 'on', 'one', 'right', 'seven', 'sheila', 'six', 'stop', 'three', 'tree', 'two', 'up', 'wow', 'yes', 'zero']\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import librosa.display","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import matplotlib.pyplot as plt\n# plt.figure(figsize=(10, 4))\n# librosa.display.specshow(mfcc, x_axis='time')\n# plt.colorbar()\n# plt.title('MFCC')\n# plt.tight_layout()","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport librosa\nimport numpy as np\nclass AudioFeatureDataset():\n    def __init__(self,file_path):\n        self.file_path = file_path\n        self.labels = os.listdir(self.file_path)\n        self.labels.remove('_background_noise_')\n        self.target_labels = ['no', 'left', 'right', 'up', 'yes', 'down', 'stop', 'go', 'on', 'off','silence','unknown']\n        self.data_dict = {}\n        for tl in self.labels:\n            files_dir = os.path.join(file_path,tl)\n            all_audio_fp_s =[ os.path.join(files_dir,f) for f in os.listdir(files_dir)]\n            self.data_dict[tl] = all_audio_fp_s\n    \n    def process(self,file,max_pad = 32):\n        try:\n            samps,sr = librosa.load(file, mono=True, sr=None)\n            pad_len = 16000 - samps.shape[0]\n            if pad_len  >= 0:\n                samps= np.pad(samps,(0,pad_len),'constant')\n            return np.array(samps[:16000])\n        except:\n            print(file)\n\n\n    def get_dataset(self, include_background = False):\n        labels =  []\n        features = []\n        for t in tqdm(self.labels):\n            if (t == \"_background_noise_\"):\n                pass\n            if( t not in self.target_labels):\n                for fp in self.data_dict[t]:\n                    labels.append('unknown')\n                    features.append(self.process(fp))\n            else:\n                 for fp in self.data_dict[t]:\n                    labels.append(t)\n                    features.append(self.process(fp))\n        if include_background:\n            _dir_path = (audio_path + \"/_background_noise_\")\n            all_files_in_dir = os.listdir(_dir_path)\n            all_files_in_dir.remove('README.md')\n            all_sound_path = [ (audio_path + \"/_background_noise_/\" + x) for x in all_files_in_dir]\n            all_sound_path\n            all_samps = []\n            for file in all_sound_path:\n                samps,sr = librosa.load(file, mono=True, sr=None)\n                k = int(samps.shape[0]/16000) * 16000\n                samps =samps[:k].reshape(int(samps.shape[0]/16000),16000)\n                for s in tqdm(range(len(samps))):\n                    all_samps.append(samps[s])\n                    labels.append('silence')\n                    features.append(samps[s])\n            all_samps = np.array(all_samps)\n            \n        return labels, features","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a = AudioFeatureDataset(audio_path)","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y,x = a.get_dataset(True)","execution_count":10,"outputs":[{"output_type":"stream","text":"100%|██████████| 30/30 [02:23<00:00,  4.52s/it]\n100%|██████████| 60/60 [00:00<00:00, 64165.79it/s]\n100%|██████████| 61/61 [00:00<00:00, 197112.90it/s]\n100%|██████████| 95/95 [00:00<00:00, 242077.08it/s]\n100%|██████████| 61/61 [00:00<00:00, 196055.59it/s]\n100%|██████████| 61/61 [00:00<00:00, 79260.39it/s]\n100%|██████████| 60/60 [00:00<00:00, 83220.32it/s]\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = np.array(x)\nY = np.array(Y)","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del a","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.utils import class_weight\nclass_weights = class_weight.compute_class_weight('balanced',np.unique(Y),Y)","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class_weights","execution_count":15,"outputs":[{"output_type":"execute_result","execution_count":15,"data":{"text/plain":"array([ 2.30037445,  2.287767  ,  2.30624026,  2.28487719,  2.3023264 ,\n        2.29259963,  2.29259963, 13.63463149,  2.28007703,  0.13222991,\n        2.28487719,  2.2829547 ])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for i in range(len(x)):\n#     pad_len = 16000 - x[i].shape[0]\n#     x[i] = np.pad(x[i],(0,pad_len),'constant')","execution_count":16,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = x.reshape(x.shape[0], 1, 16000) ","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"z  = [[1,2],[1,2]]\nz = np.array(z)","execution_count":18,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x.shape","execution_count":19,"outputs":[{"output_type":"execute_result","execution_count":19,"data":{"text/plain":"(65119, 1, 16000)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ndef get_train_test(split_ratio=0.6, random_state=42):\n    return train_test_split(x, Y, test_size= (1 - split_ratio), random_state=random_state, shuffle=True)","execution_count":20,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = get_train_test()","execution_count":21,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del x","execution_count":22,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import matplotlib.pyplot as plt\n# plt.figure(figsize=(10, 4))\n# librosa.display.specshow(X_train[3], x_axis='time')\n# plt.colorbar()\n# plt.title('MFCC')\n# plt.tight_layout()","execution_count":23,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.utils.np_utils import to_categorical","execution_count":24,"outputs":[{"output_type":"stream","text":"Using TensorFlow backend.\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"del Y","execution_count":25,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nlabelencoder = LabelEncoder()","execution_count":26,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labelencoder.fit_transform(y_test)","execution_count":27,"outputs":[{"output_type":"execute_result","execution_count":27,"data":{"text/plain":"array([ 4,  9,  0, ...,  9,  9, 11])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"mapping = dict(zip(labelencoder.classes_, range(len(labelencoder.classes_))))","execution_count":28,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mapping","execution_count":29,"outputs":[{"output_type":"execute_result","execution_count":29,"data":{"text/plain":"{'down': 0,\n 'go': 1,\n 'left': 2,\n 'no': 3,\n 'off': 4,\n 'on': 5,\n 'right': 6,\n 'silence': 7,\n 'stop': 8,\n 'unknown': 9,\n 'up': 10,\n 'yes': 11}"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test = labelencoder.fit_transform(y_test)\nmapping = dict(zip(labelencoder.classes_, range(len(labelencoder.classes_))))","execution_count":30,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mapping","execution_count":31,"outputs":[{"output_type":"execute_result","execution_count":31,"data":{"text/plain":"{'down': 0,\n 'go': 1,\n 'left': 2,\n 'no': 3,\n 'off': 4,\n 'on': 5,\n 'right': 6,\n 'silence': 7,\n 'stop': 8,\n 'unknown': 9,\n 'up': 10,\n 'yes': 11}"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test","execution_count":32,"outputs":[{"output_type":"execute_result","execution_count":32,"data":{"text/plain":"array([ 4,  9,  0, ...,  9,  9, 11])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = labelencoder.fit_transform(y_train)\nmapping = dict(zip(labelencoder.classes_, range(len(labelencoder.classes_))))","execution_count":33,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install kapre","execution_count":34,"outputs":[{"output_type":"stream","text":"Collecting kapre\n  Downloading https://files.pythonhosted.org/packages/3f/2e/f540d1d1f05c764686163fdb5bb1e5c703f1528076d2829bfc3900683f06/kapre-0.1.4-py3-none-any.whl\nRequirement already satisfied: keras>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from kapre) (2.2.4)\nRequirement already satisfied: future in /opt/conda/lib/python3.6/site-packages (from kapre) (0.17.1)\nRequirement already satisfied: numpy>=1.8.0 in /opt/conda/lib/python3.6/site-packages (from kapre) (1.16.3)\nRequirement already satisfied: librosa>=0.5 in /opt/conda/lib/python3.6/site-packages (from kapre) (0.6.3)\nRequirement already satisfied: keras-applications>=1.0.6 in /opt/conda/lib/python3.6/site-packages (from keras>=2.0.0->kapre) (1.0.7)\nRequirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.6/site-packages (from keras>=2.0.0->kapre) (1.0.9)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.6/site-packages (from keras>=2.0.0->kapre) (3.12)\nRequirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.6/site-packages (from keras>=2.0.0->kapre) (1.12.0)\nRequirement already satisfied: scipy>=0.14 in /opt/conda/lib/python3.6/site-packages (from keras>=2.0.0->kapre) (1.1.0)\nRequirement already satisfied: h5py in /opt/conda/lib/python3.6/site-packages (from keras>=2.0.0->kapre) (2.9.0)\nRequirement already satisfied: numba>=0.38.0 in /opt/conda/lib/python3.6/site-packages (from librosa>=0.5->kapre) (0.38.0)\nRequirement already satisfied: resampy>=0.2.0 in /opt/conda/lib/python3.6/site-packages (from librosa>=0.5->kapre) (0.2.1)\nRequirement already satisfied: decorator>=3.0.0 in /opt/conda/lib/python3.6/site-packages (from librosa>=0.5->kapre) (4.3.0)\nRequirement already satisfied: audioread>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from librosa>=0.5->kapre) (2.1.6)\nRequirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /opt/conda/lib/python3.6/site-packages (from librosa>=0.5->kapre) (0.20.3)\nRequirement already satisfied: joblib>=0.12 in /opt/conda/lib/python3.6/site-packages (from librosa>=0.5->kapre) (0.13.2)\nRequirement already satisfied: llvmlite>=0.23.0dev0 in /opt/conda/lib/python3.6/site-packages (from numba>=0.38.0->librosa>=0.5->kapre) (0.23.1)\nInstalling collected packages: kapre\nSuccessfully installed kapre-0.1.4\n\u001b[33mYou are using pip version 19.0.3, however version 19.1.1 is available.\nYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D","execution_count":35,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\nimport kapre\nfrom keras.models import Sequential\nfrom keras.layers import Dense,AveragePooling2D,BatchNormalization,SeparableConv2D\nfrom kapre.time_frequency import Melspectrogram\nfrom kapre.utils import Normalization2D\nfrom kapre.augmentation import AdditiveNoise\n\n# 6 channels (!), maybe 1-sec audio signal, for an example.\ninput_shape = (1,16000)\nsr = 16000\nmodel = Sequential()\n# A mel-spectrogram layer\nmodel.add(Melspectrogram(n_dft=512, n_hop=512, input_shape=input_shape,\n                         padding='same', sr=sr, n_mels=128,\n                         fmin=0.0, fmax=sr/2, power_melgram=1.0,\n                         return_decibel_melgram=True,trainable_fb=False,\n                         trainable_kernel=False,\n                         name='trainable_stft'))\n# Maybe some additive white noise.\nmodel.add(AdditiveNoise(power=0.1))\n# If you wanna normalise it per-frequency\nmodel.add(Normalization2D(str_axis='freq')) # or 'channel', 'time', 'batch', 'data_sample'\n# After this, it's just a usual keras workflow. For example..\n# Add some layers, e.g., model.add(some convolution layers..)\n# Compile the model\nmodel.add(Conv2D(64, kernel_size=(20, 8), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2),dim_ordering=\"th\"))\nmodel.add(Dropout(0.25))\n## Depth Seprable Pooling Layer - start\nmodel.add(SeparableConv2D(64, kernel_size=(5, 5), activation='relu',dim_ordering=\"th\"))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(64, kernel_size=(1, 1), activation='relu',dim_ordering=\"th\"))\nmodel.add(BatchNormalization())\nmodel.add(SeparableConv2D(64, kernel_size=(5, 5), activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(64, kernel_size=(1, 1), activation='relu'))\nmodel.add(BatchNormalization())\n## Depth Seprable pooling Layer - end\nmodel.add(AveragePooling2D(pool_size=(2, 2)))\nmodel.add(Flatten())\nmodel.add(Dense(12, activation='softmax'))\nmodel.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=keras.optimizers.adam(),metrics=['accuracy'])\nmodel.summary() ","execution_count":44,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:28: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\")`\n/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:31: UserWarning: Update your `SeparableConv2D` call to the Keras 2 API: `SeparableConv2D(64, kernel_size=(5, 5), activation=\"relu\", data_format=\"channels_first\")`\n/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:33: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, kernel_size=(1, 1), activation=\"relu\", data_format=\"channels_first\")`\n","name":"stderr"},{"output_type":"stream","text":"_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ntrainable_stft (Melspectrogr (None, 128, 32, 1)        296064    \n_________________________________________________________________\nadditive_noise_2 (AdditiveNo (None, 128, 32, 1)        0         \n_________________________________________________________________\nnormalization2d_2 (Normaliza (None, 128, 32, 1)        0         \n_________________________________________________________________\nconv2d_4 (Conv2D)            (None, 109, 25, 64)       10304     \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 109, 12, 32)       0         \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 109, 12, 32)       0         \n_________________________________________________________________\nseparable_conv2d_3 (Separabl (None, 64, 8, 28)         9765      \n_________________________________________________________________\nbatch_normalization_5 (Batch (None, 64, 8, 28)         112       \n_________________________________________________________________\nconv2d_5 (Conv2D)            (None, 64, 8, 28)         4160      \n_________________________________________________________________\nbatch_normalization_6 (Batch (None, 64, 8, 28)         112       \n_________________________________________________________________\nseparable_conv2d_4 (Separabl (None, 60, 4, 64)         2556      \n_________________________________________________________________\nbatch_normalization_7 (Batch (None, 60, 4, 64)         256       \n_________________________________________________________________\nconv2d_6 (Conv2D)            (None, 60, 4, 64)         4160      \n_________________________________________________________________\nbatch_normalization_8 (Batch (None, 60, 4, 64)         256       \n_________________________________________________________________\naverage_pooling2d_2 (Average (None, 30, 2, 64)         0         \n_________________________________________________________________\nflatten_2 (Flatten)          (None, 3840)              0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 12)                46092     \n=================================================================\nTotal params: 373,837\nTrainable params: 77,405\nNon-trainable params: 296,432\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.utils import to_categorical\ny_test = to_categorical(y_test)\ny_train = to_categorical(y_train)","execution_count":37,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# X_train.reshape(-1,13062,16000).shape","execution_count":38,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# X_test = X_test.reshape(X_test.shape[0], 20, 32, 1)","execution_count":39,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# a = X_train[0].reshape(1,16000)","execution_count":40,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model.predict(np.array([a]))","execution_count":41,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.optimizers import Optimizer\nfrom keras import backend as K\nimport six\nimport copy\nfrom six.moves import zip\nfrom keras.utils.generic_utils import serialize_keras_object\nfrom keras.utils.generic_utils import deserialize_keras_object\nfrom keras.legacy import interfaces\nclass AdamW(Optimizer):\n    \"\"\"Adam optimizer.\n    Default parameters follow those provided in the original paper.\n    # Arguments\n        lr: float >= 0. Learning rate.\n        beta_1: float, 0 < beta < 1. Generally close to 1.\n        beta_2: float, 0 < beta < 1. Generally close to 1.\n        epsilon: float >= 0. Fuzz factor.\n        decay: float >= 0. Learning rate decay over each update.\n        weight_decay: float >= 0. Decoupled weight decay over each update.\n    # References\n        - [Adam - A Method for Stochastic Optimization](http://arxiv.org/abs/1412.6980v8)\n        - [Optimization for Deep Learning Highlights in 2017](http://ruder.io/deep-learning-optimization-2017/index.html)\n        - [Fixing Weight Decay Regularization in Adam](https://arxiv.org/abs/1711.05101)\n    \"\"\"\n\n    def __init__(self, lr=0.001, beta_1=0.9, beta_2=0.999, weight_decay=1e-4,  # decoupled weight decay (1/6)\n                 epsilon=1e-8, decay=0., **kwargs):\n        super(AdamW, self).__init__(**kwargs)\n        with K.name_scope(self.__class__.__name__):\n            self.iterations = K.variable(0, dtype='int64', name='iterations')\n            self.lr = K.variable(lr, name='lr')\n            self.init_lr = lr # decoupled weight decay (2/6)\n            self.beta_1 = K.variable(beta_1, name='beta_1')\n            self.beta_2 = K.variable(beta_2, name='beta_2')\n            self.decay = K.variable(decay, name='decay')\n            self.wd = K.variable(weight_decay, name='weight_decay') # decoupled weight decay (3/6)\n        self.epsilon = epsilon\n        self.initial_decay = decay\n\n    @interfaces.legacy_get_updates_support\n    def get_updates(self, loss, params):\n        grads = self.get_gradients(loss, params)\n        self.updates = [K.update_add(self.iterations, 1)]\n        wd = self.wd # decoupled weight decay (4/6)\n\n        lr = self.lr\n        if self.initial_decay > 0:\n            lr *= (1. / (1. + self.decay * K.cast(self.iterations,\n                                                  K.dtype(self.decay))))\n        eta_t = lr / self.init_lr # decoupled weight decay (5/6)\n\n        t = K.cast(self.iterations, K.floatx()) + 1\n        lr_t = lr * (K.sqrt(1. - K.pow(self.beta_2, t)) /\n                     (1. - K.pow(self.beta_1, t)))\n\n        ms = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n        vs = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n        self.weights = [self.iterations] + ms + vs\n\n        for p, g, m, v in zip(params, grads, ms, vs):\n            m_t = (self.beta_1 * m) + (1. - self.beta_1) * g\n            v_t = (self.beta_2 * v) + (1. - self.beta_2) * K.square(g)\n            p_t = p - lr_t * m_t / (K.sqrt(v_t) + self.epsilon) - eta_t * wd * p # decoupled weight decay (6/6)\n\n            self.updates.append(K.update(m, m_t))\n            self.updates.append(K.update(v, v_t))\n            new_p = p_t\n\n            # Apply constraints.\n            if getattr(p, 'constraint', None) is not None:\n                new_p = p.constraint(new_p)\n\n            self.updates.append(K.update(p, new_p))\n        return self.updates\n\n    def get_config(self):\n        config = {'lr': float(K.get_value(self.lr)),\n                  'beta_1': float(K.get_value(self.beta_1)),\n                  'beta_2': float(K.get_value(self.beta_2)),\n                  'decay': float(K.get_value(self.decay)),\n                  'weight_decay': float(K.get_value(self.wd)),\n                  'epsilon': self.epsilon}\n        base_config = super(AdamW, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))","execution_count":42,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(X_train, y_train, batch_size=100, epochs=50, verbose=1, validation_data=(X_test, y_test),shuffle=True)","execution_count":45,"outputs":[{"output_type":"stream","text":"Train on 39071 samples, validate on 26048 samples\nEpoch 1/50\n39071/39071 [==============================] - 14s 350us/step - loss: 0.9909 - acc: 0.7033 - val_loss: 0.6511 - val_acc: 0.7791\nEpoch 2/50\n39071/39071 [==============================] - 12s 313us/step - loss: 0.5565 - acc: 0.8177 - val_loss: 0.4704 - val_acc: 0.8425\nEpoch 3/50\n39071/39071 [==============================] - 12s 314us/step - loss: 0.4362 - acc: 0.8566 - val_loss: 0.3751 - val_acc: 0.8780\nEpoch 4/50\n39071/39071 [==============================] - 12s 314us/step - loss: 0.3569 - acc: 0.8822 - val_loss: 0.3378 - val_acc: 0.8910\nEpoch 5/50\n39071/39071 [==============================] - 12s 315us/step - loss: 0.3144 - acc: 0.8983 - val_loss: 0.3056 - val_acc: 0.9041\nEpoch 6/50\n39071/39071 [==============================] - 12s 319us/step - loss: 0.2867 - acc: 0.9049 - val_loss: 0.3020 - val_acc: 0.9050\nEpoch 7/50\n39071/39071 [==============================] - 12s 314us/step - loss: 0.2642 - acc: 0.9124 - val_loss: 0.2827 - val_acc: 0.9110\nEpoch 8/50\n39071/39071 [==============================] - 12s 313us/step - loss: 0.2378 - acc: 0.9215 - val_loss: 0.2751 - val_acc: 0.9154\nEpoch 9/50\n39071/39071 [==============================] - 12s 314us/step - loss: 0.2249 - acc: 0.9255 - val_loss: 0.2733 - val_acc: 0.9129\nEpoch 10/50\n39071/39071 [==============================] - 12s 315us/step - loss: 0.2110 - acc: 0.9305 - val_loss: 0.2822 - val_acc: 0.9135\nEpoch 11/50\n39071/39071 [==============================] - 12s 313us/step - loss: 0.1981 - acc: 0.9342 - val_loss: 0.2710 - val_acc: 0.9188\nEpoch 12/50\n39071/39071 [==============================] - 12s 313us/step - loss: 0.1841 - acc: 0.9393 - val_loss: 0.3023 - val_acc: 0.9114\nEpoch 13/50\n39071/39071 [==============================] - 12s 313us/step - loss: 0.1778 - acc: 0.9417 - val_loss: 0.2502 - val_acc: 0.9251\nEpoch 14/50\n39071/39071 [==============================] - 12s 313us/step - loss: 0.1656 - acc: 0.9443 - val_loss: 0.2618 - val_acc: 0.9270\nEpoch 15/50\n39071/39071 [==============================] - 12s 314us/step - loss: 0.1597 - acc: 0.9469 - val_loss: 0.2467 - val_acc: 0.9250\nEpoch 16/50\n39071/39071 [==============================] - 12s 314us/step - loss: 0.1466 - acc: 0.9501 - val_loss: 0.2680 - val_acc: 0.9256\nEpoch 17/50\n39071/39071 [==============================] - 12s 313us/step - loss: 0.1399 - acc: 0.9525 - val_loss: 0.2689 - val_acc: 0.9223\nEpoch 18/50\n39071/39071 [==============================] - 12s 314us/step - loss: 0.1396 - acc: 0.9533 - val_loss: 0.2580 - val_acc: 0.9276\nEpoch 19/50\n39071/39071 [==============================] - 12s 315us/step - loss: 0.1254 - acc: 0.9579 - val_loss: 0.2691 - val_acc: 0.9225\nEpoch 20/50\n39071/39071 [==============================] - 12s 315us/step - loss: 0.1275 - acc: 0.9560 - val_loss: 0.2522 - val_acc: 0.9261\nEpoch 21/50\n39071/39071 [==============================] - 12s 315us/step - loss: 0.1217 - acc: 0.9588 - val_loss: 0.2544 - val_acc: 0.9282\nEpoch 22/50\n39071/39071 [==============================] - 12s 314us/step - loss: 0.1161 - acc: 0.9602 - val_loss: 0.2445 - val_acc: 0.9322\nEpoch 23/50\n39071/39071 [==============================] - 12s 315us/step - loss: 0.1112 - acc: 0.9614 - val_loss: 0.2612 - val_acc: 0.9276\nEpoch 24/50\n39071/39071 [==============================] - 12s 315us/step - loss: 0.1034 - acc: 0.9649 - val_loss: 0.2841 - val_acc: 0.9222\nEpoch 25/50\n39071/39071 [==============================] - 12s 316us/step - loss: 0.0995 - acc: 0.9661 - val_loss: 0.2600 - val_acc: 0.9299\nEpoch 26/50\n39071/39071 [==============================] - 12s 314us/step - loss: 0.0998 - acc: 0.9655 - val_loss: 0.2712 - val_acc: 0.9300\nEpoch 27/50\n39071/39071 [==============================] - 12s 315us/step - loss: 0.0983 - acc: 0.9660 - val_loss: 0.2550 - val_acc: 0.9295\nEpoch 28/50\n39071/39071 [==============================] - 13s 321us/step - loss: 0.0866 - acc: 0.9701 - val_loss: 0.2615 - val_acc: 0.9307\nEpoch 29/50\n39071/39071 [==============================] - 13s 322us/step - loss: 0.0880 - acc: 0.9699 - val_loss: 0.2720 - val_acc: 0.9277\nEpoch 30/50\n39071/39071 [==============================] - 13s 322us/step - loss: 0.0812 - acc: 0.9714 - val_loss: 0.2920 - val_acc: 0.9280\nEpoch 31/50\n39071/39071 [==============================] - 13s 326us/step - loss: 0.0833 - acc: 0.9715 - val_loss: 0.2826 - val_acc: 0.9302\nEpoch 32/50\n39071/39071 [==============================] - 13s 323us/step - loss: 0.0822 - acc: 0.9714 - val_loss: 0.2621 - val_acc: 0.9341\nEpoch 33/50\n39071/39071 [==============================] - 13s 322us/step - loss: 0.0764 - acc: 0.9740 - val_loss: 0.2776 - val_acc: 0.9321\nEpoch 34/50\n39071/39071 [==============================] - 13s 325us/step - loss: 0.0722 - acc: 0.9747 - val_loss: 0.2602 - val_acc: 0.9345\nEpoch 35/50\n39071/39071 [==============================] - 13s 322us/step - loss: 0.0760 - acc: 0.9736 - val_loss: 0.2739 - val_acc: 0.9327\nEpoch 36/50\n39071/39071 [==============================] - 13s 323us/step - loss: 0.0793 - acc: 0.9726 - val_loss: 0.2675 - val_acc: 0.9349\nEpoch 37/50\n39071/39071 [==============================] - 13s 322us/step - loss: 0.0668 - acc: 0.9772 - val_loss: 0.2857 - val_acc: 0.9333\nEpoch 38/50\n39071/39071 [==============================] - 13s 322us/step - loss: 0.0639 - acc: 0.9784 - val_loss: 0.2818 - val_acc: 0.9310\nEpoch 39/50\n39071/39071 [==============================] - 13s 324us/step - loss: 0.0655 - acc: 0.9772 - val_loss: 0.2922 - val_acc: 0.9331\nEpoch 40/50\n39071/39071 [==============================] - 13s 324us/step - loss: 0.0672 - acc: 0.9771 - val_loss: 0.3078 - val_acc: 0.9258\nEpoch 41/50\n39071/39071 [==============================] - 13s 323us/step - loss: 0.0674 - acc: 0.9769 - val_loss: 0.2887 - val_acc: 0.9319\nEpoch 42/50\n39071/39071 [==============================] - 13s 322us/step - loss: 0.0597 - acc: 0.9794 - val_loss: 0.2832 - val_acc: 0.9377\nEpoch 43/50\n39071/39071 [==============================] - 13s 323us/step - loss: 0.0579 - acc: 0.9802 - val_loss: 0.2866 - val_acc: 0.9329\nEpoch 44/50\n39071/39071 [==============================] - 13s 322us/step - loss: 0.0604 - acc: 0.9798 - val_loss: 0.2980 - val_acc: 0.9326\nEpoch 45/50\n39071/39071 [==============================] - 13s 323us/step - loss: 0.0568 - acc: 0.9803 - val_loss: 0.2915 - val_acc: 0.9328\nEpoch 46/50\n39071/39071 [==============================] - 13s 323us/step - loss: 0.0541 - acc: 0.9809 - val_loss: 0.2978 - val_acc: 0.9316\nEpoch 47/50\n39071/39071 [==============================] - 13s 321us/step - loss: 0.0580 - acc: 0.9799 - val_loss: 0.3017 - val_acc: 0.9302\nEpoch 48/50\n39071/39071 [==============================] - 13s 322us/step - loss: 0.0531 - acc: 0.9817 - val_loss: 0.2835 - val_acc: 0.9345\nEpoch 49/50\n39071/39071 [==============================] - 13s 323us/step - loss: 0.0527 - acc: 0.9822 - val_loss: 0.2879 - val_acc: 0.9359\nEpoch 50/50\n39071/39071 [==============================] - 13s 322us/step - loss: 0.0546 - acc: 0.9814 - val_loss: 0.3097 - val_acc: 0.9338\n","name":"stdout"},{"output_type":"execute_result","execution_count":45,"data":{"text/plain":"<keras.callbacks.History at 0x7f4960166438>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(model.output.op.name)\nprint(model.input.op.name)","execution_count":46,"outputs":[{"output_type":"stream","text":"dense_2/Softmax\ntrainable_stft_input_1\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.output.op.name","execution_count":47,"outputs":[{"output_type":"execute_result","execution_count":47,"data":{"text/plain":"'dense_2/Softmax'"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save_weights('dscnn.h5',keras)","execution_count":48,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save(\"dscnn-model.h5\")\nimport tensorflow as tf","execution_count":49,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from tensorflow.contrib import lite\n# converter = lite.TFLiteConverter.from_keras_model_file( 'yo.h5')\n# tfmodel = converter.convert()\n# converter.allow_custom_ops=True\n# open (\"model.tflite\" , \"wb\") .write(tfmodel)\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}