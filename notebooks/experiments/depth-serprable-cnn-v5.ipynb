{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train', 'sample_submission.csv']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "from os.path import isdir, join\n",
    "import librosa\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D,SeparableConv2D,BatchNormalization,AveragePooling2D\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['happy', 'nine', 'two', 'stop', 'wow', 'down', 'on', 'off', 'zero', 'seven', 'bird', 'house', 'go', 'eight', 'six', 'tree', 'one', 'up', 'cat', 'yes', 'sheila', 'no', 'right', 'four', 'left', 'five', 'bed', 'three', 'dog', '_background_noise_', 'marvin']\n"
     ]
    }
   ],
   "source": [
    "audio_path = \"../input/train/audio\"\n",
    "print(os.listdir(audio_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all audio dirs\n",
    "dirs = [f for f in os.listdir(audio_path) if os.path.isdir(join(audio_path, f))]\n",
    "dirs.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# plt.figure(figsize=(10, 4))\n",
    "# librosa.display.specshow(mfcc, x_axis='time')\n",
    "# plt.colorbar()\n",
    "# plt.title('MFCC')\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa.display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# plt.figure(figsize=(10, 4))\n",
    "# librosa.display.specshow(mfcc, x_axis='time')\n",
    "# plt.colorbar()\n",
    "# plt.title('MFCC')\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "class AudioFeatureDataset():\n",
    "    def __init__(self,file_path):\n",
    "        self.file_path = file_path\n",
    "        self.labels = os.listdir(self.file_path)\n",
    "        self.target_labels = ['no', 'seven', 'right', 'up', 'down', 'eight', 'six', 'wow', 'bird', 'tree', 'happy', 'three', 'five', 'zero', 'go', 'left', 'nine', 'two', 'four', 'yes', 'bed', 'stop', 'cat', 'dog', 'marvin', 'off', 'one', 'on', 'sheila', 'house']\n",
    "        self.data_dict = {}\n",
    "        for tl in self.target_labels:\n",
    "            files_dir = os.path.join(file_path,tl)\n",
    "            all_audio_fp_s =[ os.path.join(files_dir,f) for f in os.listdir(files_dir)]\n",
    "            self.data_dict[tl] = all_audio_fp_s\n",
    "    \n",
    "    def process(self,file,max_pad = 35):\n",
    "        samps,sr = librosa.load(file, mono=True, sr=None)\n",
    "        mfcc = librosa.feature.mfcc(samps, sr = sr)\n",
    "        pad_width = max_pad - mfcc.shape[1]\n",
    "        mfcc = np.pad(mfcc, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "        return mfcc\n",
    "    def get_dataset(self):\n",
    "        labels =  []\n",
    "        features = []\n",
    "        for t in self.target_labels:\n",
    "            for fp in self.data_dict[t]:\n",
    "                labels.append(t)\n",
    "                features.append(self.process(fp))\n",
    "        return labels, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = AudioFeatureDataset(audio_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y,x = a.get_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(x)\n",
    "Y = np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def get_train_test(split_ratio=0.6, random_state=42):\n",
    "    return train_test_split(librosa.util.normalize(x), Y, test_size= (1 - split_ratio), random_state=random_state, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = get_train_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size= 0.1, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 4))\n",
    "librosa.display.specshow(X_train[3], x_axis='time')\n",
    "plt.colorbar()\n",
    "plt.title('MFCC')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 20, 35, 1)\n",
    "X_valid =  X_valid.reshape(X_valid.shape[0], 20, 35, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3, 14, 25, ..., 25, 21,  6])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelencoder.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = dict(zip(labelencoder.classes_, range(len(labelencoder.classes_))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bed': 0,\n",
       " 'bird': 1,\n",
       " 'cat': 2,\n",
       " 'dog': 3,\n",
       " 'down': 4,\n",
       " 'eight': 5,\n",
       " 'five': 6,\n",
       " 'four': 7,\n",
       " 'go': 8,\n",
       " 'happy': 9,\n",
       " 'house': 10,\n",
       " 'left': 11,\n",
       " 'marvin': 12,\n",
       " 'nine': 13,\n",
       " 'no': 14,\n",
       " 'off': 15,\n",
       " 'on': 16,\n",
       " 'one': 17,\n",
       " 'right': 18,\n",
       " 'seven': 19,\n",
       " 'sheila': 20,\n",
       " 'six': 21,\n",
       " 'stop': 22,\n",
       " 'three': 23,\n",
       " 'tree': 24,\n",
       " 'two': 25,\n",
       " 'up': 26,\n",
       " 'wow': 27,\n",
       " 'yes': 28,\n",
       " 'zero': 29}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = labelencoder.fit_transform(y_test)\n",
    "mapping = dict(zip(labelencoder.classes_, range(len(labelencoder.classes_))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid = labelencoder.fit_transform(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3, 14, 25, ..., 25, 21,  6])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = labelencoder.fit_transform(y_train)\n",
    "mapping = dict(zip(labelencoder.classes_, range(len(labelencoder.classes_))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bed': 0,\n",
       " 'bird': 1,\n",
       " 'cat': 2,\n",
       " 'dog': 3,\n",
       " 'down': 4,\n",
       " 'eight': 5,\n",
       " 'five': 6,\n",
       " 'four': 7,\n",
       " 'go': 8,\n",
       " 'happy': 9,\n",
       " 'house': 10,\n",
       " 'left': 11,\n",
       " 'marvin': 12,\n",
       " 'nine': 13,\n",
       " 'no': 14,\n",
       " 'off': 15,\n",
       " 'on': 16,\n",
       " 'one': 17,\n",
       " 'right': 18,\n",
       " 'seven': 19,\n",
       " 'sheila': 20,\n",
       " 'six': 21,\n",
       " 'stop': 22,\n",
       " 'three': 23,\n",
       " 'tree': 24,\n",
       " 'two': 25,\n",
       " 'up': 26,\n",
       " 'wow': 27,\n",
       " 'yes': 28,\n",
       " 'zero': 29}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = to_categorical(y_test)\n",
    "y_train = to_categorical(y_train)\n",
    "y_valid = to_categorical(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25889, 20, 35)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_test = X_test.reshape(X_test.shape[0], 20, 35, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25889, 20, 35, 1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Optimizer\n",
    "from keras import backend as K\n",
    "import six\n",
    "import copy\n",
    "from six.moves import zip\n",
    "from keras.utils.generic_utils import serialize_keras_object\n",
    "from keras.utils.generic_utils import deserialize_keras_object\n",
    "from keras.legacy import interfaces\n",
    "class AdamW(Optimizer):\n",
    "    \"\"\"Adam optimizer.\n",
    "    Default parameters follow those provided in the original paper.\n",
    "    # Arguments\n",
    "        lr: float >= 0. Learning rate.\n",
    "        beta_1: float, 0 < beta < 1. Generally close to 1.\n",
    "        beta_2: float, 0 < beta < 1. Generally close to 1.\n",
    "        epsilon: float >= 0. Fuzz factor.\n",
    "        decay: float >= 0. Learning rate decay over each update.\n",
    "        weight_decay: float >= 0. Decoupled weight decay over each update.\n",
    "    # References\n",
    "        - [Adam - A Method for Stochastic Optimization](http://arxiv.org/abs/1412.6980v8)\n",
    "        - [Optimization for Deep Learning Highlights in 2017](http://ruder.io/deep-learning-optimization-2017/index.html)\n",
    "        - [Fixing Weight Decay Regularization in Adam](https://arxiv.org/abs/1711.05101)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, lr=0.001, beta_1=0.9, beta_2=0.999, weight_decay=1e-4,  # decoupled weight decay (1/6)\n",
    "                 epsilon=1e-8, decay=0., **kwargs):\n",
    "        super(AdamW, self).__init__(**kwargs)\n",
    "        with K.name_scope(self.__class__.__name__):\n",
    "            self.iterations = K.variable(0, dtype='int64', name='iterations')\n",
    "            self.lr = K.variable(lr, name='lr')\n",
    "            self.init_lr = lr # decoupled weight decay (2/6)\n",
    "            self.beta_1 = K.variable(beta_1, name='beta_1')\n",
    "            self.beta_2 = K.variable(beta_2, name='beta_2')\n",
    "            self.decay = K.variable(decay, name='decay')\n",
    "            self.wd = K.variable(weight_decay, name='weight_decay') # decoupled weight decay (3/6)\n",
    "        self.epsilon = epsilon\n",
    "        self.initial_decay = decay\n",
    "\n",
    "    @interfaces.legacy_get_updates_support\n",
    "    def get_updates(self, loss, params):\n",
    "        grads = self.get_gradients(loss, params)\n",
    "        self.updates = [K.update_add(self.iterations, 1)]\n",
    "        wd = self.wd # decoupled weight decay (4/6)\n",
    "\n",
    "        lr = self.lr\n",
    "        if self.initial_decay > 0:\n",
    "            lr *= (1. / (1. + self.decay * K.cast(self.iterations,\n",
    "                                                  K.dtype(self.decay))))\n",
    "        eta_t = lr / self.init_lr # decoupled weight decay (5/6)\n",
    "\n",
    "        t = K.cast(self.iterations, K.floatx()) + 1\n",
    "        lr_t = lr * (K.sqrt(1. - K.pow(self.beta_2, t)) /\n",
    "                     (1. - K.pow(self.beta_1, t)))\n",
    "\n",
    "        ms = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n",
    "        vs = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n",
    "        self.weights = [self.iterations] + ms + vs\n",
    "\n",
    "        for p, g, m, v in zip(params, grads, ms, vs):\n",
    "            m_t = (self.beta_1 * m) + (1. - self.beta_1) * g\n",
    "            v_t = (self.beta_2 * v) + (1. - self.beta_2) * K.square(g)\n",
    "            p_t = p - lr_t * m_t / (K.sqrt(v_t) + self.epsilon) - eta_t * wd * p # decoupled weight decay (6/6)\n",
    "\n",
    "            self.updates.append(K.update(m, m_t))\n",
    "            self.updates.append(K.update(v, v_t))\n",
    "            new_p = p_t\n",
    "\n",
    "            # Apply constraints.\n",
    "            if getattr(p, 'constraint', None) is not None:\n",
    "                new_p = p.constraint(new_p)\n",
    "\n",
    "            self.updates.append(K.update(p, new_p))\n",
    "        return self.updates\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'lr': float(K.get_value(self.lr)),\n",
    "                  'beta_1': float(K.get_value(self.beta_1)),\n",
    "                  'beta_2': float(K.get_value(self.beta_2)),\n",
    "                  'decay': float(K.get_value(self.decay)),\n",
    "                  'weight_decay': float(K.get_value(self.wd)),\n",
    "                  'epsilon': self.epsilon}\n",
    "        base_config = super(AdamW, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:4: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\")`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:7: UserWarning: Update your `SeparableConv2D` call to the Keras 2 API: `SeparableConv2D(64, kernel_size=(10, 4), activation=\"relu\", data_format=\"channels_first\")`\n",
      "  import sys\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, kernel_size=(1, 1), activation=\"relu\", data_format=\"channels_first\")`\n",
      "  if __name__ == '__main__':\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:16: UserWarning: Update your `AveragePooling2D` call to the Keras 2 API: `AveragePooling2D(pool_size=(2, 2), data_format=\"channels_first\")`\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 1, 28, 64)         10304     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 1, 14, 32)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1, 14, 32)         0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_1 (Separabl (None, 64, 5, 29)         168       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 64, 5, 29)         116       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 64, 5, 29)         4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 64, 5, 29)         116       \n",
      "_________________________________________________________________\n",
      "separable_conv2d_2 (Separabl (None, 55, 2, 64)         3080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 55, 2, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 55, 2, 64)         4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 55, 2, 64)         256       \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average (None, 55, 1, 32)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 55, 1, 32)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1760)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 30)                52830     \n",
      "=================================================================\n",
      "Total params: 75,446\n",
      "Trainable params: 75,074\n",
      "Non-trainable params: 372\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Depth Wise CNN (DS-CNN)\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, kernel_size=(20, 8), activation='relu', input_shape=(20, 35, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2),dim_ordering=\"th\"))\n",
    "model.add(Dropout(0.25))\n",
    "## Depth Seprable Pooling Layer - start\n",
    "model.add(SeparableConv2D(64, kernel_size=(10, 4), activation='relu',dim_ordering=\"th\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, kernel_size=(1, 1), activation='relu',dim_ordering=\"th\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(SeparableConv2D(64, kernel_size=(10, 4), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, kernel_size=(1, 1), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "## Depth Seprable pooling Layer - end\n",
    "model.add(AveragePooling2D(pool_size=(2, 2),dim_ordering=\"th\"))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(30, activation='softmax'))\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.adam(),metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 34948 samples, validate on 3884 samples\n",
      "Epoch 1/150\n",
      "34948/34948 [==============================] - 8s 236us/step - loss: 2.0452 - acc: 0.4079 - val_loss: 0.9244 - val_acc: 0.7276\n",
      "Epoch 2/150\n",
      "34948/34948 [==============================] - 4s 105us/step - loss: 0.9385 - acc: 0.7146 - val_loss: 0.6632 - val_acc: 0.8036\n",
      "Epoch 3/150\n",
      "34948/34948 [==============================] - 4s 105us/step - loss: 0.7489 - acc: 0.7726 - val_loss: 0.5563 - val_acc: 0.8326\n",
      "Epoch 4/150\n",
      "34948/34948 [==============================] - 4s 105us/step - loss: 0.6619 - acc: 0.7986 - val_loss: 0.5126 - val_acc: 0.8481\n",
      "Epoch 5/150\n",
      "34948/34948 [==============================] - 4s 105us/step - loss: 0.6038 - acc: 0.8154 - val_loss: 0.4703 - val_acc: 0.8628\n",
      "Epoch 6/150\n",
      "34948/34948 [==============================] - 4s 104us/step - loss: 0.5673 - acc: 0.8271 - val_loss: 0.4654 - val_acc: 0.8581\n",
      "Epoch 7/150\n",
      "34948/34948 [==============================] - 4s 104us/step - loss: 0.5386 - acc: 0.8337 - val_loss: 0.4640 - val_acc: 0.8597\n",
      "Epoch 8/150\n",
      "34948/34948 [==============================] - 4s 105us/step - loss: 0.5194 - acc: 0.8409 - val_loss: 0.4281 - val_acc: 0.8723\n",
      "Epoch 9/150\n",
      "34948/34948 [==============================] - 4s 105us/step - loss: 0.5018 - acc: 0.8460 - val_loss: 0.4175 - val_acc: 0.8738\n",
      "Epoch 10/150\n",
      "34948/34948 [==============================] - 4s 105us/step - loss: 0.4822 - acc: 0.8498 - val_loss: 0.4298 - val_acc: 0.8790\n",
      "Epoch 11/150\n",
      "34948/34948 [==============================] - 4s 105us/step - loss: 0.4653 - acc: 0.8562 - val_loss: 0.3938 - val_acc: 0.8808\n",
      "Epoch 12/150\n",
      "34948/34948 [==============================] - 4s 105us/step - loss: 0.4558 - acc: 0.8585 - val_loss: 0.4314 - val_acc: 0.8774\n",
      "Epoch 13/150\n",
      "34948/34948 [==============================] - 4s 105us/step - loss: 0.4512 - acc: 0.8608 - val_loss: 0.4093 - val_acc: 0.8811\n",
      "Epoch 14/150\n",
      "34948/34948 [==============================] - 4s 105us/step - loss: 0.4363 - acc: 0.8637 - val_loss: 0.4047 - val_acc: 0.8870\n",
      "Epoch 15/150\n",
      "34948/34948 [==============================] - 4s 106us/step - loss: 0.4215 - acc: 0.8677 - val_loss: 0.3958 - val_acc: 0.8826\n",
      "Epoch 16/150\n",
      "34948/34948 [==============================] - 4s 106us/step - loss: 0.4162 - acc: 0.8715 - val_loss: 0.4026 - val_acc: 0.8829\n",
      "Epoch 17/150\n",
      "34948/34948 [==============================] - 4s 106us/step - loss: 0.4118 - acc: 0.8714 - val_loss: 0.3905 - val_acc: 0.8870\n",
      "Epoch 18/150\n",
      "34948/34948 [==============================] - 4s 106us/step - loss: 0.3985 - acc: 0.8751 - val_loss: 0.3923 - val_acc: 0.8885\n",
      "Epoch 19/150\n",
      "34948/34948 [==============================] - 4s 106us/step - loss: 0.3997 - acc: 0.8748 - val_loss: 0.3798 - val_acc: 0.8913\n",
      "Epoch 20/150\n",
      "34948/34948 [==============================] - 4s 108us/step - loss: 0.3869 - acc: 0.8785 - val_loss: 0.3975 - val_acc: 0.8880\n",
      "Epoch 21/150\n",
      "34948/34948 [==============================] - 4s 109us/step - loss: 0.3877 - acc: 0.8786 - val_loss: 0.3688 - val_acc: 0.8929\n",
      "Epoch 22/150\n",
      "34948/34948 [==============================] - 4s 106us/step - loss: 0.3788 - acc: 0.8813 - val_loss: 0.3868 - val_acc: 0.8901\n",
      "Epoch 23/150\n",
      "34948/34948 [==============================] - 4s 105us/step - loss: 0.3715 - acc: 0.8834 - val_loss: 0.3970 - val_acc: 0.8862\n",
      "Epoch 24/150\n",
      "34948/34948 [==============================] - 4s 105us/step - loss: 0.3636 - acc: 0.8857 - val_loss: 0.3807 - val_acc: 0.8913\n",
      "Epoch 25/150\n",
      "34948/34948 [==============================] - 4s 105us/step - loss: 0.3616 - acc: 0.8869 - val_loss: 0.3745 - val_acc: 0.8957\n",
      "Epoch 26/150\n",
      "34948/34948 [==============================] - 4s 105us/step - loss: 0.3546 - acc: 0.8883 - val_loss: 0.3712 - val_acc: 0.8960\n",
      "Epoch 27/150\n",
      "34948/34948 [==============================] - 4s 105us/step - loss: 0.3509 - acc: 0.8901 - val_loss: 0.3756 - val_acc: 0.8898\n",
      "Epoch 28/150\n",
      "34948/34948 [==============================] - 4s 105us/step - loss: 0.3458 - acc: 0.8907 - val_loss: 0.3588 - val_acc: 0.8975\n",
      "Epoch 29/150\n",
      "34948/34948 [==============================] - 4s 105us/step - loss: 0.3466 - acc: 0.8900 - val_loss: 0.3886 - val_acc: 0.8937\n",
      "Epoch 30/150\n",
      "34948/34948 [==============================] - 4s 105us/step - loss: 0.3436 - acc: 0.8908 - val_loss: 0.3783 - val_acc: 0.8911\n",
      "Epoch 31/150\n",
      "34948/34948 [==============================] - 4s 105us/step - loss: 0.3389 - acc: 0.8924 - val_loss: 0.3705 - val_acc: 0.8939\n",
      "Epoch 32/150\n",
      "34948/34948 [==============================] - 4s 105us/step - loss: 0.3230 - acc: 0.8986 - val_loss: 0.3736 - val_acc: 0.8939\n",
      "Epoch 33/150\n",
      "34948/34948 [==============================] - 4s 105us/step - loss: 0.3274 - acc: 0.8949 - val_loss: 0.3680 - val_acc: 0.8960\n",
      "Epoch 34/150\n",
      "34948/34948 [==============================] - 4s 105us/step - loss: 0.3220 - acc: 0.8974 - val_loss: 0.3748 - val_acc: 0.8952\n",
      "Epoch 35/150\n",
      "34948/34948 [==============================] - 4s 105us/step - loss: 0.3249 - acc: 0.8976 - val_loss: 0.3809 - val_acc: 0.8929\n",
      "Epoch 36/150\n",
      "34948/34948 [==============================] - 4s 105us/step - loss: 0.3134 - acc: 0.8986 - val_loss: 0.3639 - val_acc: 0.8937\n",
      "Epoch 37/150\n",
      "34948/34948 [==============================] - 4s 106us/step - loss: 0.3128 - acc: 0.9003 - val_loss: 0.3688 - val_acc: 0.8988\n",
      "Epoch 38/150\n",
      "34948/34948 [==============================] - 4s 106us/step - loss: 0.3137 - acc: 0.9003 - val_loss: 0.3697 - val_acc: 0.8924\n",
      "Epoch 39/150\n",
      "34948/34948 [==============================] - 4s 106us/step - loss: 0.3109 - acc: 0.9008 - val_loss: 0.3765 - val_acc: 0.9001\n",
      "Epoch 40/150\n",
      "34948/34948 [==============================] - 4s 106us/step - loss: 0.3108 - acc: 0.8999 - val_loss: 0.3684 - val_acc: 0.8947\n",
      "Epoch 41/150\n",
      "34948/34948 [==============================] - 4s 106us/step - loss: 0.3021 - acc: 0.9037 - val_loss: 0.3654 - val_acc: 0.8944\n",
      "Epoch 42/150\n",
      "34948/34948 [==============================] - 4s 106us/step - loss: 0.2983 - acc: 0.9047 - val_loss: 0.3569 - val_acc: 0.9058\n",
      "Epoch 43/150\n",
      "34948/34948 [==============================] - 4s 105us/step - loss: 0.2981 - acc: 0.9038 - val_loss: 0.3579 - val_acc: 0.9011\n",
      "Epoch 44/150\n",
      "34948/34948 [==============================] - 4s 105us/step - loss: 0.2974 - acc: 0.9038 - val_loss: 0.3714 - val_acc: 0.8944\n",
      "Epoch 45/150\n",
      "34948/34948 [==============================] - 4s 105us/step - loss: 0.2963 - acc: 0.9054 - val_loss: 0.3617 - val_acc: 0.8960\n",
      "Epoch 46/150\n",
      "34948/34948 [==============================] - 4s 105us/step - loss: 0.2921 - acc: 0.9047 - val_loss: 0.3629 - val_acc: 0.8993\n",
      "Epoch 47/150\n",
      "34948/34948 [==============================] - 4s 105us/step - loss: 0.2956 - acc: 0.9040 - val_loss: 0.3667 - val_acc: 0.8978\n",
      "Epoch 48/150\n",
      "34948/34948 [==============================] - 4s 105us/step - loss: 0.2901 - acc: 0.9063 - val_loss: 0.3520 - val_acc: 0.8996\n",
      "Epoch 49/150\n",
      "34948/34948 [==============================] - 4s 105us/step - loss: 0.2871 - acc: 0.9075 - val_loss: 0.3529 - val_acc: 0.9024\n",
      "Epoch 50/150\n",
      "34948/34948 [==============================] - 4s 105us/step - loss: 0.2843 - acc: 0.9102 - val_loss: 0.3583 - val_acc: 0.8978\n",
      "Epoch 51/150\n",
      "34948/34948 [==============================] - 4s 106us/step - loss: 0.2840 - acc: 0.9085 - val_loss: 0.3652 - val_acc: 0.8973\n",
      "Epoch 52/150\n",
      "34948/34948 [==============================] - 4s 105us/step - loss: 0.2792 - acc: 0.9086 - val_loss: 0.3503 - val_acc: 0.9022\n",
      "Epoch 53/150\n",
      "34948/34948 [==============================] - 4s 105us/step - loss: 0.2815 - acc: 0.9085 - val_loss: 0.3594 - val_acc: 0.9047\n",
      "Epoch 54/150\n",
      "34948/34948 [==============================] - 4s 107us/step - loss: 0.2753 - acc: 0.9111 - val_loss: 0.3670 - val_acc: 0.8955\n",
      "Epoch 55/150\n",
      "34948/34948 [==============================] - 4s 106us/step - loss: 0.2742 - acc: 0.9105 - val_loss: 0.3656 - val_acc: 0.8975\n",
      "Epoch 56/150\n",
      "34948/34948 [==============================] - 4s 105us/step - loss: 0.2712 - acc: 0.9111 - val_loss: 0.3804 - val_acc: 0.8988\n",
      "Epoch 57/150\n",
      "34948/34948 [==============================] - 4s 105us/step - loss: 0.2795 - acc: 0.9093 - val_loss: 0.3544 - val_acc: 0.9032\n",
      "Epoch 58/150\n",
      "34948/34948 [==============================] - 4s 106us/step - loss: 0.2671 - acc: 0.9152 - val_loss: 0.3690 - val_acc: 0.8960\n",
      "Epoch 59/150\n",
      "34948/34948 [==============================] - 4s 106us/step - loss: 0.2680 - acc: 0.9113 - val_loss: 0.3566 - val_acc: 0.8998\n",
      "Epoch 60/150\n",
      "34948/34948 [==============================] - 4s 106us/step - loss: 0.2667 - acc: 0.9150 - val_loss: 0.3608 - val_acc: 0.9022\n",
      "Epoch 61/150\n",
      "34948/34948 [==============================] - 4s 107us/step - loss: 0.2664 - acc: 0.9139 - val_loss: 0.3641 - val_acc: 0.9006\n",
      "Epoch 62/150\n",
      "34948/34948 [==============================] - 4s 106us/step - loss: 0.2615 - acc: 0.9146 - val_loss: 0.3656 - val_acc: 0.9001\n",
      "Epoch 63/150\n",
      "34948/34948 [==============================] - 4s 105us/step - loss: 0.2652 - acc: 0.9142 - val_loss: 0.3520 - val_acc: 0.9024\n",
      "Epoch 64/150\n",
      "34948/34948 [==============================] - 4s 106us/step - loss: 0.2594 - acc: 0.9159 - val_loss: 0.3667 - val_acc: 0.9019\n",
      "Epoch 65/150\n",
      "34948/34948 [==============================] - 4s 105us/step - loss: 0.2577 - acc: 0.9171 - val_loss: 0.3703 - val_acc: 0.8975\n",
      "Epoch 66/150\n",
      "34948/34948 [==============================] - 4s 106us/step - loss: 0.2606 - acc: 0.9160 - val_loss: 0.3624 - val_acc: 0.8973\n",
      "Epoch 67/150\n",
      "34948/34948 [==============================] - 4s 105us/step - loss: 0.2614 - acc: 0.9153 - val_loss: 0.3631 - val_acc: 0.9014\n",
      "Epoch 68/150\n",
      "34948/34948 [==============================] - 4s 106us/step - loss: 0.2583 - acc: 0.9143 - val_loss: 0.3619 - val_acc: 0.8947\n",
      "Epoch 69/150\n",
      "34948/34948 [==============================] - 4s 106us/step - loss: 0.2552 - acc: 0.9164 - val_loss: 0.3655 - val_acc: 0.9014\n",
      "Epoch 70/150\n",
      "34948/34948 [==============================] - 4s 106us/step - loss: 0.2542 - acc: 0.9181 - val_loss: 0.3536 - val_acc: 0.9009\n",
      "Epoch 71/150\n",
      "34948/34948 [==============================] - 4s 106us/step - loss: 0.2516 - acc: 0.9186 - val_loss: 0.3601 - val_acc: 0.9014\n",
      "Epoch 72/150\n",
      "34948/34948 [==============================] - 4s 106us/step - loss: 0.2551 - acc: 0.9159 - val_loss: 0.3764 - val_acc: 0.9014\n",
      "Epoch 73/150\n",
      "34948/34948 [==============================] - 4s 106us/step - loss: 0.2513 - acc: 0.9189 - val_loss: 0.3553 - val_acc: 0.9042\n",
      "Epoch 74/150\n",
      "34948/34948 [==============================] - 4s 106us/step - loss: 0.2497 - acc: 0.9199 - val_loss: 0.3670 - val_acc: 0.8986\n",
      "Epoch 75/150\n",
      "34948/34948 [==============================] - 4s 106us/step - loss: 0.2503 - acc: 0.9184 - val_loss: 0.3548 - val_acc: 0.8998\n",
      "Epoch 76/150\n",
      "34948/34948 [==============================] - 4s 105us/step - loss: 0.2475 - acc: 0.9187 - val_loss: 0.3571 - val_acc: 0.8983\n",
      "Epoch 77/150\n",
      "34948/34948 [==============================] - 4s 105us/step - loss: 0.2509 - acc: 0.9185 - val_loss: 0.3520 - val_acc: 0.9027\n",
      "Epoch 78/150\n",
      "34948/34948 [==============================] - 4s 106us/step - loss: 0.2515 - acc: 0.9183 - val_loss: 0.3692 - val_acc: 0.9022\n",
      "Epoch 79/150\n",
      "34948/34948 [==============================] - 4s 106us/step - loss: 0.2449 - acc: 0.9196 - val_loss: 0.3727 - val_acc: 0.8975\n",
      "Epoch 80/150\n",
      "34948/34948 [==============================] - 4s 106us/step - loss: 0.2463 - acc: 0.9190 - val_loss: 0.3677 - val_acc: 0.8996\n",
      "Epoch 81/150\n",
      "34948/34948 [==============================] - 4s 106us/step - loss: 0.2486 - acc: 0.9200 - val_loss: 0.3656 - val_acc: 0.8998\n",
      "Epoch 82/150\n",
      "34948/34948 [==============================] - 4s 106us/step - loss: 0.2405 - acc: 0.9206 - val_loss: 0.3750 - val_acc: 0.8942\n",
      "Epoch 83/150\n",
      "34948/34948 [==============================] - 4s 106us/step - loss: 0.2435 - acc: 0.9206 - val_loss: 0.3568 - val_acc: 0.9027\n",
      "Epoch 84/150\n",
      "21200/34948 [=================>............] - ETA: 1s - loss: 0.2324 - acc: 0.9249"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=100, epochs=150, verbose=1, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "911\n",
      "CPU times: user 1.89 s, sys: 212 ms, total: 2.1 s\n",
      "Wall time: 1.54 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "count = 0\n",
    "for i in range(1000):    \n",
    "    tesval = np.array([X_test[i]]).reshape(1,20,35,1)\n",
    "    if np.argmax(model.predict(tesval)) ==  np.argmax(y_test[i]):\n",
    "        count+= 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 20, 35, 1)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tesval.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(model.predict(tesval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 20, 35, 1)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tesval.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('result-dscnn.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
