{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\nfrom os.path import isdir, join\nimport librosa\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D,SeparableConv2D,BatchNormalization,AveragePooling2D\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"audio_path = \"../input/train/audio\"\nprint(os.listdir(audio_path))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# all audio dirs\ndirs = [f for f in os.listdir(audio_path) if os.path.isdir(join(audio_path, f))]\ndirs.sort()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import matplotlib.pyplot as plt\n# plt.figure(figsize=(10, 4))\n# librosa.display.specshow(mfcc, x_axis='time')\n# plt.colorbar()\n# plt.title('MFCC')\n# plt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import librosa.display","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import matplotlib.pyplot as plt\n# plt.figure(figsize=(10, 4))\n# librosa.display.specshow(mfcc, x_axis='time')\n# plt.colorbar()\n# plt.title('MFCC')\n# plt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport librosa\nimport numpy as np\nclass AudioFeatureDataset():\n    def __init__(self,file_path):\n        self.file_path = file_path\n        self.labels = os.listdir(self.file_path)\n        self.target_labels = ['no', 'seven', 'right', 'up', 'down', 'eight', 'six', 'wow', 'bird', 'tree', 'happy', 'three', 'five', 'zero', 'go', 'left', 'nine', 'two', 'four', 'yes', 'bed', 'stop', 'cat', 'dog', 'marvin', 'off', 'one', 'on', 'sheila', 'house']\n        self.data_dict = {}\n        for tl in self.target_labels:\n            files_dir = os.path.join(file_path,tl)\n            all_audio_fp_s =[ os.path.join(files_dir,f) for f in os.listdir(files_dir)]\n            self.data_dict[tl] = all_audio_fp_s\n    \n    def process(self,file,max_pad = 35):\n        samps,sr = librosa.load(file, mono=True, sr=None)\n        mfcc = librosa.feature.mfcc(samps, sr = sr)\n        pad_width = max_pad - mfcc.shape[1]\n        mfcc = np.pad(mfcc, pad_width=((0, 0), (0, pad_width)), mode='constant')\n        return mfcc\n    def get_dataset(self):\n        labels =  []\n        features = []\n        for t in self.target_labels:\n            for fp in self.data_dict[t]:\n                labels.append(t)\n                features.append(self.process(fp))\n        return labels, features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a = AudioFeatureDataset(audio_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y,x = a.get_dataset()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = np.array(x)\nY = np.array(Y)","execution_count":86,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":87,"outputs":[{"output_type":"execute_result","execution_count":87,"data":{"text/plain":"(64721,)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ndef get_train_test(split_ratio=0.8, random_state=42):\n    return train_test_split(librosa.util.normalize(x), Y, test_size= (1 - split_ratio), random_state=random_state, shuffle=True)","execution_count":88,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = get_train_test()","execution_count":89,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test, X_valid, y_test, y_valid = train_test_split(X_test, y_test, test_size= 0.5, random_state=42, shuffle=True)","execution_count":90,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.figure(figsize=(10, 4))\nlibrosa.display.specshow(X_train[3], x_axis='time')\nplt.colorbar()\nplt.title('MFCC')\nplt.tight_layout()","execution_count":91,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 720x288 with 2 Axes>","image/png":"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\n"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.utils.np_utils import to_categorical","execution_count":92,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nX_train = X_train.reshape(X_train.shape[0], 20, 35, 1)\nX_valid =  X_valid.reshape(X_valid.shape[0], 20, 35, 1)","execution_count":93,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nlabelencoder = LabelEncoder()","execution_count":94,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labelencoder.fit_transform(y_test)","execution_count":95,"outputs":[{"output_type":"execute_result","execution_count":95,"data":{"text/plain":"array([ 4,  1, 29, ..., 15, 20,  5])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"mapping = dict(zip(labelencoder.classes_, range(len(labelencoder.classes_))))","execution_count":96,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mapping","execution_count":97,"outputs":[{"output_type":"execute_result","execution_count":97,"data":{"text/plain":"{'bed': 0,\n 'bird': 1,\n 'cat': 2,\n 'dog': 3,\n 'down': 4,\n 'eight': 5,\n 'five': 6,\n 'four': 7,\n 'go': 8,\n 'happy': 9,\n 'house': 10,\n 'left': 11,\n 'marvin': 12,\n 'nine': 13,\n 'no': 14,\n 'off': 15,\n 'on': 16,\n 'one': 17,\n 'right': 18,\n 'seven': 19,\n 'sheila': 20,\n 'six': 21,\n 'stop': 22,\n 'three': 23,\n 'tree': 24,\n 'two': 25,\n 'up': 26,\n 'wow': 27,\n 'yes': 28,\n 'zero': 29}"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test = labelencoder.fit_transform(y_test)\nmapping = dict(zip(labelencoder.classes_, range(len(labelencoder.classes_))))","execution_count":98,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_valid = labelencoder.fit_transform(y_valid)","execution_count":99,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test.shape","execution_count":100,"outputs":[{"output_type":"execute_result","execution_count":100,"data":{"text/plain":"(6472,)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = labelencoder.fit_transform(y_train)\nmapping = dict(zip(labelencoder.classes_, range(len(labelencoder.classes_))))","execution_count":101,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mapping","execution_count":102,"outputs":[{"output_type":"execute_result","execution_count":102,"data":{"text/plain":"{'bed': 0,\n 'bird': 1,\n 'cat': 2,\n 'dog': 3,\n 'down': 4,\n 'eight': 5,\n 'five': 6,\n 'four': 7,\n 'go': 8,\n 'happy': 9,\n 'house': 10,\n 'left': 11,\n 'marvin': 12,\n 'nine': 13,\n 'no': 14,\n 'off': 15,\n 'on': 16,\n 'one': 17,\n 'right': 18,\n 'seven': 19,\n 'sheila': 20,\n 'six': 21,\n 'stop': 22,\n 'three': 23,\n 'tree': 24,\n 'two': 25,\n 'up': 26,\n 'wow': 27,\n 'yes': 28,\n 'zero': 29}"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test = to_categorical(y_test)\ny_train = to_categorical(y_train)\ny_valid = to_categorical(y_valid)","execution_count":103,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.shape","execution_count":104,"outputs":[{"output_type":"execute_result","execution_count":104,"data":{"text/plain":"(51776, 30)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nX_test = X_test.reshape(X_test.shape[0], 20, 35, 1)","execution_count":105,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test.shape","execution_count":106,"outputs":[{"output_type":"execute_result","execution_count":106,"data":{"text/plain":"(6472, 20, 35, 1)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.optimizers import Optimizer\nfrom keras import backend as K\nimport six\nimport copy\nfrom six.moves import zip\nfrom keras.utils.generic_utils import serialize_keras_object\nfrom keras.utils.generic_utils import deserialize_keras_object\nfrom keras.legacy import interfaces\nclass AdamW(Optimizer):\n    \"\"\"Adam optimizer.\n    Default parameters follow those provided in the original paper.\n    # Arguments\n        lr: float >= 0. Learning rate.\n        beta_1: float, 0 < beta < 1. Generally close to 1.\n        beta_2: float, 0 < beta < 1. Generally close to 1.\n        epsilon: float >= 0. Fuzz factor.\n        decay: float >= 0. Learning rate decay over each update.\n        weight_decay: float >= 0. Decoupled weight decay over each update.\n    # References\n        - [Adam - A Method for Stochastic Optimization](http://arxiv.org/abs/1412.6980v8)\n        - [Optimization for Deep Learning Highlights in 2017](http://ruder.io/deep-learning-optimization-2017/index.html)\n        - [Fixing Weight Decay Regularization in Adam](https://arxiv.org/abs/1711.05101)\n    \"\"\"\n\n    def __init__(self, lr=0.001, beta_1=0.9, beta_2=0.999, weight_decay=1e-4,  # decoupled weight decay (1/6)\n                 epsilon=1e-8, decay=0., **kwargs):\n        super(AdamW, self).__init__(**kwargs)\n        with K.name_scope(self.__class__.__name__):\n            self.iterations = K.variable(0, dtype='int64', name='iterations')\n            self.lr = K.variable(lr, name='lr')\n            self.init_lr = lr # decoupled weight decay (2/6)\n            self.beta_1 = K.variable(beta_1, name='beta_1')\n            self.beta_2 = K.variable(beta_2, name='beta_2')\n            self.decay = K.variable(decay, name='decay')\n            self.wd = K.variable(weight_decay, name='weight_decay') # decoupled weight decay (3/6)\n        self.epsilon = epsilon\n        self.initial_decay = decay\n\n    @interfaces.legacy_get_updates_support\n    def get_updates(self, loss, params):\n        grads = self.get_gradients(loss, params)\n        self.updates = [K.update_add(self.iterations, 1)]\n        wd = self.wd # decoupled weight decay (4/6)\n\n        lr = self.lr\n        if self.initial_decay > 0:\n            lr *= (1. / (1. + self.decay * K.cast(self.iterations,\n                                                  K.dtype(self.decay))))\n        eta_t = lr / self.init_lr # decoupled weight decay (5/6)\n\n        t = K.cast(self.iterations, K.floatx()) + 1\n        lr_t = lr * (K.sqrt(1. - K.pow(self.beta_2, t)) /\n                     (1. - K.pow(self.beta_1, t)))\n\n        ms = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n        vs = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n        self.weights = [self.iterations] + ms + vs\n\n        for p, g, m, v in zip(params, grads, ms, vs):\n            m_t = (self.beta_1 * m) + (1. - self.beta_1) * g\n            v_t = (self.beta_2 * v) + (1. - self.beta_2) * K.square(g)\n            p_t = p - lr_t * m_t / (K.sqrt(v_t) + self.epsilon) - eta_t * wd * p # decoupled weight decay (6/6)\n\n            self.updates.append(K.update(m, m_t))\n            self.updates.append(K.update(v, v_t))\n            new_p = p_t\n\n            # Apply constraints.\n            if getattr(p, 'constraint', None) is not None:\n                new_p = p.constraint(new_p)\n\n            self.updates.append(K.update(p, new_p))\n        return self.updates\n\n    def get_config(self):\n        config = {'lr': float(K.get_value(self.lr)),\n                  'beta_1': float(K.get_value(self.beta_1)),\n                  'beta_2': float(K.get_value(self.beta_2)),\n                  'decay': float(K.get_value(self.decay)),\n                  'weight_decay': float(K.get_value(self.wd)),\n                  'epsilon': self.epsilon}\n        base_config = super(AdamW, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))","execution_count":107,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Depth Wise CNN (DS-CNN)\nmodel = Sequential()\nmodel.add(Conv2D(39, kernel_size=(3, 3), activation='relu', input_shape=(20, 35, 1)))\nmodel.add(Conv2D(20, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\nmodel.add(Conv2D(39, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\nmodel.add(Conv2D(15, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\nmodel.add(Conv2D(39, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\nmodel.add(Conv2D(25, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\nmodel.add(Conv2D(39, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\nmodel.add(Conv2D(22, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\nmodel.add(Conv2D(39, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\nmodel.add(Conv2D(22, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\nmodel.add(Conv2D(39, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\nmodel.add(Conv2D(25, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\nmodel.add(Conv2D(39, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\nmodel.add(Conv2D(45, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\nmodel.add(AveragePooling2D(pool_size=(5, 5)))\nmodel.add(Flatten())\nmodel.add(Dense(12))\nmodel.add(Dense(30, activation='softmax'))\nmodel.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=AdamW(),metrics=['accuracy'])\nmodel.summary()\n","execution_count":130,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(20, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n  after removing the cwd from sys.path.\n/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(39, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n  \"\"\"\n/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(15, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n  \n/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:7: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(39, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n  import sys\n/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(25, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n  \n/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(39, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n  if __name__ == '__main__':\n/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:10: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(22, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n  # Remove the CWD from sys.path while we load stuff.\n/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(39, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n  # This is added back by InteractiveShellApp.init_path()\n/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(22, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n  if sys.path[0] == '':\n/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(39, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n  del sys.path[0]\n/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:14: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(25, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n  \n/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(39, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n  from ipykernel import kernelapp as app\n/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(45, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n  app.launch_new_instance()\n","name":"stderr"},{"output_type":"stream","text":"_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_400 (Conv2D)          (None, 18, 33, 39)        390       \n_________________________________________________________________\nconv2d_401 (Conv2D)          (None, 20, 31, 37)        3260      \n_________________________________________________________________\nconv2d_402 (Conv2D)          (None, 39, 29, 35)        7059      \n_________________________________________________________________\nconv2d_403 (Conv2D)          (None, 15, 27, 33)        5280      \n_________________________________________________________________\nconv2d_404 (Conv2D)          (None, 39, 25, 31)        5304      \n_________________________________________________________________\nconv2d_405 (Conv2D)          (None, 25, 23, 29)        8800      \n_________________________________________________________________\nconv2d_406 (Conv2D)          (None, 39, 21, 27)        8814      \n_________________________________________________________________\nconv2d_407 (Conv2D)          (None, 22, 19, 25)        7744      \n_________________________________________________________________\nconv2d_408 (Conv2D)          (None, 39, 17, 23)        7761      \n_________________________________________________________________\nconv2d_409 (Conv2D)          (None, 22, 15, 21)        7744      \n_________________________________________________________________\nconv2d_410 (Conv2D)          (None, 39, 13, 19)        7761      \n_________________________________________________________________\nconv2d_411 (Conv2D)          (None, 25, 11, 17)        8800      \n_________________________________________________________________\nconv2d_412 (Conv2D)          (None, 39, 9, 15)         8814      \n_________________________________________________________________\nconv2d_413 (Conv2D)          (None, 45, 7, 13)         15840     \n_________________________________________________________________\naverage_pooling2d_25 (Averag (None, 9, 1, 13)          0         \n_________________________________________________________________\nflatten_16 (Flatten)         (None, 117)               0         \n_________________________________________________________________\ndense_27 (Dense)             (None, 30)                3540      \n=================================================================\nTotal params: 106,911\nTrainable params: 106,911\nNon-trainable params: 0\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(X_train, y_train, batch_size=100, epochs=100, verbose=1, validation_data=(X_valid, y_valid))","execution_count":131,"outputs":[{"output_type":"stream","text":"Train on 51776 samples, validate on 6473 samples\nEpoch 1/100\n51776/51776 [==============================] - 13s 254us/step - loss: 2.6423 - acc: 0.2262 - val_loss: 1.5108 - val_acc: 0.5429\nEpoch 2/100\n51776/51776 [==============================] - 10s 194us/step - loss: 1.1388 - acc: 0.6558 - val_loss: 0.9084 - val_acc: 0.7273\nEpoch 3/100\n51776/51776 [==============================] - 10s 194us/step - loss: 0.7952 - acc: 0.7626 - val_loss: 0.7870 - val_acc: 0.7531\nEpoch 4/100\n51776/51776 [==============================] - 10s 195us/step - loss: 0.6528 - acc: 0.8045 - val_loss: 0.6332 - val_acc: 0.8097\nEpoch 5/100\n51776/51776 [==============================] - 10s 195us/step - loss: 0.5779 - acc: 0.8261 - val_loss: 0.5703 - val_acc: 0.8287\nEpoch 6/100\n51776/51776 [==============================] - 10s 194us/step - loss: 0.5192 - acc: 0.8435 - val_loss: 0.5565 - val_acc: 0.8319\nEpoch 7/100\n51776/51776 [==============================] - 10s 194us/step - loss: 0.4871 - acc: 0.8549 - val_loss: 0.5092 - val_acc: 0.8508\nEpoch 8/100\n51776/51776 [==============================] - 10s 194us/step - loss: 0.4575 - acc: 0.8632 - val_loss: 0.5179 - val_acc: 0.8455\nEpoch 9/100\n51776/51776 [==============================] - 10s 195us/step - loss: 0.4394 - acc: 0.8679 - val_loss: 0.5005 - val_acc: 0.8480\nEpoch 10/100\n51776/51776 [==============================] - 10s 196us/step - loss: 0.4141 - acc: 0.8757 - val_loss: 0.4640 - val_acc: 0.8603\nEpoch 11/100\n51776/51776 [==============================] - 10s 196us/step - loss: 0.4019 - acc: 0.8785 - val_loss: 0.4750 - val_acc: 0.8591\nEpoch 12/100\n51776/51776 [==============================] - 10s 195us/step - loss: 0.3869 - acc: 0.8846 - val_loss: 0.4573 - val_acc: 0.8647\nEpoch 13/100\n51776/51776 [==============================] - 10s 195us/step - loss: 0.3717 - acc: 0.8882 - val_loss: 0.4614 - val_acc: 0.8658\nEpoch 14/100\n51776/51776 [==============================] - 10s 194us/step - loss: 0.3550 - acc: 0.8931 - val_loss: 0.4616 - val_acc: 0.8628\nEpoch 15/100\n51776/51776 [==============================] - 10s 194us/step - loss: 0.3495 - acc: 0.8933 - val_loss: 0.4403 - val_acc: 0.8702\nEpoch 16/100\n51776/51776 [==============================] - 10s 194us/step - loss: 0.3432 - acc: 0.8957 - val_loss: 0.4474 - val_acc: 0.8665\nEpoch 17/100\n51776/51776 [==============================] - 10s 194us/step - loss: 0.3333 - acc: 0.8975 - val_loss: 0.4290 - val_acc: 0.8738\nEpoch 18/100\n51776/51776 [==============================] - 10s 194us/step - loss: 0.3266 - acc: 0.9012 - val_loss: 0.4257 - val_acc: 0.8753\nEpoch 19/100\n51776/51776 [==============================] - 10s 194us/step - loss: 0.3188 - acc: 0.9031 - val_loss: 0.4082 - val_acc: 0.8746\nEpoch 20/100\n51776/51776 [==============================] - 10s 195us/step - loss: 0.3143 - acc: 0.9042 - val_loss: 0.3964 - val_acc: 0.8759\nEpoch 21/100\n51776/51776 [==============================] - 10s 194us/step - loss: 0.3079 - acc: 0.9063 - val_loss: 0.4370 - val_acc: 0.8687\nEpoch 22/100\n51776/51776 [==============================] - 10s 195us/step - loss: 0.2945 - acc: 0.9099 - val_loss: 0.3981 - val_acc: 0.8821\nEpoch 23/100\n51776/51776 [==============================] - 10s 195us/step - loss: 0.2935 - acc: 0.9105 - val_loss: 0.3961 - val_acc: 0.8848\nEpoch 24/100\n51776/51776 [==============================] - 10s 195us/step - loss: 0.2927 - acc: 0.9110 - val_loss: 0.3963 - val_acc: 0.8815\nEpoch 25/100\n51776/51776 [==============================] - 10s 195us/step - loss: 0.2870 - acc: 0.9129 - val_loss: 0.4040 - val_acc: 0.8829\nEpoch 26/100\n51776/51776 [==============================] - 10s 194us/step - loss: 0.2870 - acc: 0.9122 - val_loss: 0.4017 - val_acc: 0.8804\nEpoch 27/100\n51776/51776 [==============================] - 10s 195us/step - loss: 0.2753 - acc: 0.9162 - val_loss: 0.3858 - val_acc: 0.8852\nEpoch 28/100\n51776/51776 [==============================] - 10s 194us/step - loss: 0.2761 - acc: 0.9146 - val_loss: 0.3804 - val_acc: 0.8865\nEpoch 29/100\n51776/51776 [==============================] - 10s 195us/step - loss: 0.2720 - acc: 0.9169 - val_loss: 0.3882 - val_acc: 0.8838\nEpoch 30/100\n51776/51776 [==============================] - 10s 195us/step - loss: 0.2703 - acc: 0.9173 - val_loss: 0.3637 - val_acc: 0.8948\nEpoch 31/100\n51776/51776 [==============================] - 10s 194us/step - loss: 0.2664 - acc: 0.9187 - val_loss: 0.3860 - val_acc: 0.8882\nEpoch 32/100\n51776/51776 [==============================] - 10s 195us/step - loss: 0.2611 - acc: 0.9192 - val_loss: 0.3664 - val_acc: 0.8914\nEpoch 33/100\n51776/51776 [==============================] - 10s 194us/step - loss: 0.2578 - acc: 0.9218 - val_loss: 0.3795 - val_acc: 0.8911\nEpoch 34/100\n51776/51776 [==============================] - 10s 194us/step - loss: 0.2521 - acc: 0.9222 - val_loss: 0.3506 - val_acc: 0.8942\nEpoch 35/100\n51776/51776 [==============================] - 10s 195us/step - loss: 0.2532 - acc: 0.9221 - val_loss: 0.3877 - val_acc: 0.8869\nEpoch 36/100\n51776/51776 [==============================] - 10s 194us/step - loss: 0.2497 - acc: 0.9247 - val_loss: 0.3595 - val_acc: 0.8929\nEpoch 37/100\n51776/51776 [==============================] - 10s 195us/step - loss: 0.2537 - acc: 0.9229 - val_loss: 0.3693 - val_acc: 0.8889\nEpoch 38/100\n51776/51776 [==============================] - 10s 195us/step - loss: 0.2457 - acc: 0.9240 - val_loss: 0.3697 - val_acc: 0.8909\nEpoch 39/100\n51776/51776 [==============================] - 10s 194us/step - loss: 0.2437 - acc: 0.9252 - val_loss: 0.3498 - val_acc: 0.8925\nEpoch 40/100\n51776/51776 [==============================] - 10s 196us/step - loss: 0.2453 - acc: 0.9246 - val_loss: 0.3650 - val_acc: 0.8931\nEpoch 41/100\n51776/51776 [==============================] - 10s 196us/step - loss: 0.2394 - acc: 0.9249 - val_loss: 0.3675 - val_acc: 0.8922\nEpoch 42/100\n51776/51776 [==============================] - 10s 195us/step - loss: 0.2413 - acc: 0.9256 - val_loss: 0.3634 - val_acc: 0.8886\nEpoch 43/100\n51776/51776 [==============================] - 10s 195us/step - loss: 0.2395 - acc: 0.9264 - val_loss: 0.3354 - val_acc: 0.8977\nEpoch 44/100\n51776/51776 [==============================] - 10s 195us/step - loss: 0.2327 - acc: 0.9282 - val_loss: 0.3362 - val_acc: 0.8996\nEpoch 45/100\n51776/51776 [==============================] - 10s 195us/step - loss: 0.2337 - acc: 0.9285 - val_loss: 0.3735 - val_acc: 0.8882\nEpoch 46/100\n51776/51776 [==============================] - 10s 195us/step - loss: 0.2295 - acc: 0.9294 - val_loss: 0.3677 - val_acc: 0.8911\nEpoch 47/100\n51776/51776 [==============================] - 10s 195us/step - loss: 0.2350 - acc: 0.9275 - val_loss: 0.3420 - val_acc: 0.8962\nEpoch 48/100\n51776/51776 [==============================] - 10s 194us/step - loss: 0.2317 - acc: 0.9292 - val_loss: 0.3305 - val_acc: 0.9053\nEpoch 49/100\n51776/51776 [==============================] - 10s 195us/step - loss: 0.2252 - acc: 0.9294 - val_loss: 0.3566 - val_acc: 0.8949\nEpoch 50/100\n51776/51776 [==============================] - 10s 195us/step - loss: 0.2275 - acc: 0.9294 - val_loss: 0.3461 - val_acc: 0.8951\nEpoch 51/100\n51776/51776 [==============================] - 10s 195us/step - loss: 0.2223 - acc: 0.9308 - val_loss: 0.3199 - val_acc: 0.9053\nEpoch 52/100\n51776/51776 [==============================] - 10s 195us/step - loss: 0.2232 - acc: 0.9305 - val_loss: 0.3526 - val_acc: 0.8945\nEpoch 53/100\n51776/51776 [==============================] - 10s 195us/step - loss: 0.2216 - acc: 0.9323 - val_loss: 0.3364 - val_acc: 0.8985\nEpoch 54/100\n51776/51776 [==============================] - 10s 195us/step - loss: 0.2205 - acc: 0.9313 - val_loss: 0.3645 - val_acc: 0.8923\nEpoch 55/100\n51776/51776 [==============================] - 10s 194us/step - loss: 0.2189 - acc: 0.9323 - val_loss: 0.3417 - val_acc: 0.9025\nEpoch 56/100\n51776/51776 [==============================] - 10s 195us/step - loss: 0.2195 - acc: 0.9306 - val_loss: 0.3617 - val_acc: 0.8973\nEpoch 57/100\n51776/51776 [==============================] - 10s 194us/step - loss: 0.2182 - acc: 0.9326 - val_loss: 0.3399 - val_acc: 0.9008\nEpoch 58/100\n51776/51776 [==============================] - 10s 195us/step - loss: 0.2150 - acc: 0.9337 - val_loss: 0.3420 - val_acc: 0.8963\n","name":"stdout"},{"output_type":"stream","text":"Epoch 59/100\n51776/51776 [==============================] - 10s 195us/step - loss: 0.2121 - acc: 0.9351 - val_loss: 0.3421 - val_acc: 0.8951\nEpoch 60/100\n51776/51776 [==============================] - 10s 194us/step - loss: 0.2127 - acc: 0.9330 - val_loss: 0.3184 - val_acc: 0.9070\nEpoch 61/100\n51776/51776 [==============================] - 10s 195us/step - loss: 0.2114 - acc: 0.9355 - val_loss: 0.3286 - val_acc: 0.9031\nEpoch 62/100\n51776/51776 [==============================] - 10s 195us/step - loss: 0.2081 - acc: 0.9349 - val_loss: 0.3448 - val_acc: 0.9045\nEpoch 63/100\n51776/51776 [==============================] - 10s 195us/step - loss: 0.2061 - acc: 0.9366 - val_loss: 0.3445 - val_acc: 0.8988\nEpoch 64/100\n51776/51776 [==============================] - 10s 195us/step - loss: 0.2082 - acc: 0.9365 - val_loss: 0.3468 - val_acc: 0.8988\nEpoch 65/100\n51776/51776 [==============================] - 10s 195us/step - loss: 0.2090 - acc: 0.9347 - val_loss: 0.3370 - val_acc: 0.9017\nEpoch 66/100\n51776/51776 [==============================] - 10s 194us/step - loss: 0.2071 - acc: 0.9357 - val_loss: 0.3169 - val_acc: 0.9050\nEpoch 67/100\n51776/51776 [==============================] - 10s 194us/step - loss: 0.2053 - acc: 0.9354 - val_loss: 0.3553 - val_acc: 0.8920\nEpoch 68/100\n51776/51776 [==============================] - 10s 194us/step - loss: 0.2027 - acc: 0.9378 - val_loss: 0.3146 - val_acc: 0.9036\nEpoch 69/100\n51776/51776 [==============================] - 10s 194us/step - loss: 0.2069 - acc: 0.9360 - val_loss: 0.3399 - val_acc: 0.8991\nEpoch 70/100\n51776/51776 [==============================] - 10s 196us/step - loss: 0.2060 - acc: 0.9366 - val_loss: 0.3731 - val_acc: 0.8973\nEpoch 71/100\n51776/51776 [==============================] - 10s 195us/step - loss: 0.1970 - acc: 0.9388 - val_loss: 0.3298 - val_acc: 0.9050\nEpoch 72/100\n51776/51776 [==============================] - 10s 195us/step - loss: 0.2003 - acc: 0.9381 - val_loss: 0.3189 - val_acc: 0.9059\nEpoch 73/100\n51776/51776 [==============================] - 10s 195us/step - loss: 0.1979 - acc: 0.9381 - val_loss: 0.3334 - val_acc: 0.9027\nEpoch 74/100\n51776/51776 [==============================] - 10s 195us/step - loss: 0.2012 - acc: 0.9377 - val_loss: 0.3443 - val_acc: 0.8985\nEpoch 75/100\n51776/51776 [==============================] - 10s 195us/step - loss: 0.1977 - acc: 0.9385 - val_loss: 0.3375 - val_acc: 0.9025\nEpoch 76/100\n51776/51776 [==============================] - 10s 195us/step - loss: 0.1981 - acc: 0.9379 - val_loss: 0.3245 - val_acc: 0.9061\nEpoch 77/100\n51776/51776 [==============================] - 10s 195us/step - loss: 0.1995 - acc: 0.9375 - val_loss: 0.3120 - val_acc: 0.9119\nEpoch 78/100\n51776/51776 [==============================] - 10s 194us/step - loss: 0.1949 - acc: 0.9405 - val_loss: 0.3428 - val_acc: 0.9038\nEpoch 79/100\n51776/51776 [==============================] - 10s 194us/step - loss: 0.1961 - acc: 0.9392 - val_loss: 0.3455 - val_acc: 0.9019\nEpoch 80/100\n51776/51776 [==============================] - 10s 194us/step - loss: 0.1960 - acc: 0.9395 - val_loss: 0.3167 - val_acc: 0.9067\nEpoch 81/100\n51776/51776 [==============================] - 10s 195us/step - loss: 0.1984 - acc: 0.9396 - val_loss: 0.3231 - val_acc: 0.9030\nEpoch 82/100\n51776/51776 [==============================] - 10s 195us/step - loss: 0.1932 - acc: 0.9401 - val_loss: 0.3337 - val_acc: 0.9031\nEpoch 83/100\n51776/51776 [==============================] - 10s 195us/step - loss: 0.1929 - acc: 0.9408 - val_loss: 0.3338 - val_acc: 0.9022\nEpoch 84/100\n51776/51776 [==============================] - 10s 194us/step - loss: 0.1890 - acc: 0.9412 - val_loss: 0.3506 - val_acc: 0.8966\nEpoch 85/100\n51776/51776 [==============================] - 10s 194us/step - loss: 0.1960 - acc: 0.9397 - val_loss: 0.3286 - val_acc: 0.9067\nEpoch 86/100\n51776/51776 [==============================] - 10s 194us/step - loss: 0.1940 - acc: 0.9390 - val_loss: 0.3497 - val_acc: 0.9005\nEpoch 87/100\n51776/51776 [==============================] - 10s 195us/step - loss: 0.1921 - acc: 0.9406 - val_loss: 0.3480 - val_acc: 0.8996\nEpoch 88/100\n51776/51776 [==============================] - 10s 195us/step - loss: 0.1902 - acc: 0.9404 - val_loss: 0.3357 - val_acc: 0.9039\nEpoch 89/100\n51776/51776 [==============================] - 10s 195us/step - loss: 0.1907 - acc: 0.9403 - val_loss: 0.3409 - val_acc: 0.8979\nEpoch 90/100\n51776/51776 [==============================] - 10s 195us/step - loss: 0.1910 - acc: 0.9406 - val_loss: 0.3211 - val_acc: 0.9098\nEpoch 91/100\n51776/51776 [==============================] - 10s 195us/step - loss: 0.1875 - acc: 0.9422 - val_loss: 0.3460 - val_acc: 0.9041\nEpoch 92/100\n51776/51776 [==============================] - 10s 194us/step - loss: 0.1931 - acc: 0.9391 - val_loss: 0.3268 - val_acc: 0.9039\nEpoch 93/100\n51776/51776 [==============================] - 10s 194us/step - loss: 0.1861 - acc: 0.9416 - val_loss: 0.3200 - val_acc: 0.9042\nEpoch 94/100\n51776/51776 [==============================] - 10s 194us/step - loss: 0.1860 - acc: 0.9421 - val_loss: 0.3433 - val_acc: 0.9022\nEpoch 95/100\n51776/51776 [==============================] - 10s 194us/step - loss: 0.1871 - acc: 0.9418 - val_loss: 0.3406 - val_acc: 0.9041\nEpoch 96/100\n51776/51776 [==============================] - 10s 195us/step - loss: 0.1866 - acc: 0.9411 - val_loss: 0.3397 - val_acc: 0.9024\nEpoch 97/100\n51776/51776 [==============================] - 10s 195us/step - loss: 0.1860 - acc: 0.9420 - val_loss: 0.3355 - val_acc: 0.8987\nEpoch 98/100\n51776/51776 [==============================] - 10s 195us/step - loss: 0.1880 - acc: 0.9419 - val_loss: 0.3125 - val_acc: 0.9059\nEpoch 99/100\n51776/51776 [==============================] - 10s 195us/step - loss: 0.1863 - acc: 0.9429 - val_loss: 0.3386 - val_acc: 0.9050\nEpoch 100/100\n51776/51776 [==============================] - 10s 196us/step - loss: 0.1887 - acc: 0.9409 - val_loss: 0.3300 - val_acc: 0.9044\n","name":"stdout"},{"output_type":"execute_result","execution_count":131,"data":{"text/plain":"<keras.callbacks.History at 0x7f539297c0f0>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ncount = 0\nfor i in range(len(X_test)):    \n    tesval = np.array([X_test[i]]).reshape(1,20,35,1)\n    if np.argmax(model.predict(tesval)) ==  np.argmax(y_test[i]):\n        count+= 1\nprint(count/len(X_test))","execution_count":132,"outputs":[{"output_type":"stream","text":"0.9080655129789864\nCPU times: user 19.9 s, sys: 1.41 s, total: 21.3 s\nWall time: 17.2 s\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.shape","execution_count":123,"outputs":[{"output_type":"execute_result","execution_count":123,"data":{"text/plain":"(51776, 30)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.argmax(model.predict(tesval))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tesval.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save_weights('result-dscnn.h5')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}