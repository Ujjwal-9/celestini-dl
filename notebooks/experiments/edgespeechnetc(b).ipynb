{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train', 'sample_submission.csv']\n",
      "Default GPU Device: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "from os.path import isdir, join\n",
    "import librosa\n",
    "from tqdm import tqdm\n",
    "# Any results you write to the current directory are saved as output.\n",
    "import tensorflow as tf\n",
    "if tf.test.gpu_device_name():\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"Please install GPU version of TF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# os.listdir(\"../input/dataasdfasd/\")\n",
    "# audio_file_path = \"../input/dataasdfasd/output.wav\"\n",
    "# os.linesep()\n",
    "# samps,sr = librosa.load(audio_file_path, mono=True, sr=None)\n",
    "# mfcc = librosa.feature.mfcc(samps, sr = sr)z\n",
    "# pad_width = max_pad - mfcc.shape[1]\n",
    "# mfcc = np.pad(mfcc, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "audio_path = \"../input/train/audio/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all audio dirs\n",
    "dirs = [f for f in os.listdir(audio_path) if os.path.isdir(join(audio_path, f))]\n",
    "dirs.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_background_noise_', 'bed', 'bird', 'cat', 'dog', 'down', 'eight', 'five', 'four', 'go', 'happy', 'house', 'left', 'marvin', 'nine', 'no', 'off', 'on', 'one', 'right', 'seven', 'sheila', 'six', 'stop', 'three', 'tree', 'two', 'up', 'wow', 'yes', 'zero']\n"
     ]
    }
   ],
   "source": [
    "print(dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa.display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# plt.figure(figsize=(10, 4))\n",
    "# librosa.display.specshow(mfcc, x_axis='time')\n",
    "# plt.colorbar()\n",
    "# plt.title('MFCC')\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "class AudioFeatureDataset():\n",
    "    def __init__(self,file_path):\n",
    "        self.file_path = file_path\n",
    "        self.labels = os.listdir(self.file_path)\n",
    "        self.labels.remove('_background_noise_')\n",
    "        self.target_labels = ['no', 'left', 'right', 'up', 'yes', 'down', 'stop', 'go', 'on', 'off','silence','unknown']\n",
    "        self.data_dict = {}\n",
    "        for tl in self.labels:\n",
    "            files_dir = os.path.join(file_path,tl)\n",
    "            all_audio_fp_s =[ os.path.join(files_dir,f) for f in os.listdir(files_dir)]\n",
    "            self.data_dict[tl] = all_audio_fp_s\n",
    "    \n",
    "    def process(self,file,max_pad = 32):\n",
    "        try:\n",
    "            samps,sr = librosa.load(file, mono=True, sr=None)\n",
    "            pad_len = 16000 - samps.shape[0]\n",
    "            if pad_len  >= 0:\n",
    "                samps= np.pad(samps,(0,pad_len),'constant')\n",
    "            return np.array(samps[:16000])\n",
    "        except:\n",
    "            print(file)\n",
    "\n",
    "\n",
    "    def get_dataset(self, include_background = False):\n",
    "        labels =  []\n",
    "        features = []\n",
    "        for t in tqdm(self.labels):\n",
    "            if (t == \"_background_noise_\"):\n",
    "                pass\n",
    "            if( t not in self.target_labels):\n",
    "                for fp in self.data_dict[t]:\n",
    "                    labels.append('unknown')\n",
    "                    features.append(self.process(fp))\n",
    "            else:\n",
    "                 for fp in self.data_dict[t]:\n",
    "                    labels.append(t)\n",
    "                    features.append(self.process(fp))\n",
    "        if include_background:\n",
    "            _dir_path = (audio_path + \"/_background_noise_\")\n",
    "            all_files_in_dir = os.listdir(_dir_path)\n",
    "            all_files_in_dir.remove('README.md')\n",
    "            all_sound_path = [ (audio_path + \"/_background_noise_/\" + x) for x in all_files_in_dir]\n",
    "            all_sound_path\n",
    "            all_samps = []\n",
    "            for file in all_sound_path:\n",
    "                print(file)\n",
    "                samps,sr = librosa.load(file, mono=True, sr=None)\n",
    "                k = int(samps.shape[0]/16000) * 16000\n",
    "                samps =samps[:k].reshape(int(samps.shape[0]/16000),16000)\n",
    "                for s in tqdm(range(len(samps))):\n",
    "                    all_samps.append(samps[s])\n",
    "                    labels.append('silence')\n",
    "                    features.append(samps[s])\n",
    "            all_samps = np.array(all_samps)\n",
    "            \n",
    "        return labels, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = AudioFeatureDataset(audio_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [02:25<00:00,  4.74s/it]\n",
      "100%|██████████| 95/95 [00:00<00:00, 129076.41it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 226618.73it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 69506.26it/s]\n",
      "100%|██████████| 60/60 [00:00<00:00, 84534.18it/s]\n",
      "100%|██████████| 60/60 [00:00<00:00, 80945.08it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 63220.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../input/train/audio//_background_noise_/doing_the_dishes.wav\n",
      "../input/train/audio//_background_noise_/exercise_bike.wav\n",
      "../input/train/audio//_background_noise_/running_tap.wav\n",
      "../input/train/audio//_background_noise_/pink_noise.wav\n",
      "../input/train/audio//_background_noise_/white_noise.wav\n",
      "../input/train/audio//_background_noise_/dude_miaowing.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "Y,x = a.get_dataset(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(x)\n",
    "Y = np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "del a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "class_weights = class_weight.compute_class_weight('balanced',np.unique(Y),Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.30037445,  2.287767  ,  2.30624026,  2.28487719,  2.3023264 ,\n",
       "        2.29259963,  2.29259963, 13.63463149,  2.28007703,  0.13222991,\n",
       "        2.28487719,  2.2829547 ])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(x)):\n",
    "#     pad_len = 16000 - x[i].shape[0]\n",
    "#     x[i] = np.pad(x[i],(0,pad_len),'constant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.reshape(x.shape[0], 1, 16000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "z  = [[1,2],[1,2]]\n",
    "z = np.array(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65119, 1, 16000)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def get_train_test(split_ratio=0.6, random_state=42):\n",
    "    return train_test_split(x, Y, test_size= (1 - split_ratio), random_state=random_state, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = get_train_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "del x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# plt.figure(figsize=(10, 4))\n",
    "# librosa.display.specshow(X_train[3], x_axis='time')\n",
    "# plt.colorbar()\n",
    "# plt.title('MFCC')\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "del Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9,  4,  9, ..., 11,  6,  9])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelencoder.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = dict(zip(labelencoder.classes_, range(len(labelencoder.classes_))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'down': 0,\n",
       " 'go': 1,\n",
       " 'left': 2,\n",
       " 'no': 3,\n",
       " 'off': 4,\n",
       " 'on': 5,\n",
       " 'right': 6,\n",
       " 'silence': 7,\n",
       " 'stop': 8,\n",
       " 'unknown': 9,\n",
       " 'up': 10,\n",
       " 'yes': 11}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = labelencoder.fit_transform(y_test)\n",
    "mapping = dict(zip(labelencoder.classes_, range(len(labelencoder.classes_))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'down': 0,\n",
       " 'go': 1,\n",
       " 'left': 2,\n",
       " 'no': 3,\n",
       " 'off': 4,\n",
       " 'on': 5,\n",
       " 'right': 6,\n",
       " 'silence': 7,\n",
       " 'stop': 8,\n",
       " 'unknown': 9,\n",
       " 'up': 10,\n",
       " 'yes': 11}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9,  4,  9, ..., 11,  6,  9])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = labelencoder.fit_transform(y_train)\n",
    "mapping = dict(zip(labelencoder.classes_, range(len(labelencoder.classes_))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kapre\r\n",
      "  Downloading https://files.pythonhosted.org/packages/3f/2e/f540d1d1f05c764686163fdb5bb1e5c703f1528076d2829bfc3900683f06/kapre-0.1.4-py3-none-any.whl\r\n",
      "Requirement already satisfied: keras>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from kapre) (2.2.4)\r\n",
      "Requirement already satisfied: librosa>=0.5 in /opt/conda/lib/python3.6/site-packages (from kapre) (0.6.3)\r\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.6/site-packages (from kapre) (0.17.1)\r\n",
      "Requirement already satisfied: numpy>=1.8.0 in /opt/conda/lib/python3.6/site-packages (from kapre) (1.16.3)\r\n",
      "Requirement already satisfied: scipy>=0.14 in /opt/conda/lib/python3.6/site-packages (from keras>=2.0.0->kapre) (1.1.0)\r\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.6/site-packages (from keras>=2.0.0->kapre) (1.12.0)\r\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.6/site-packages (from keras>=2.0.0->kapre) (2.9.0)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.6/site-packages (from keras>=2.0.0->kapre) (3.12)\r\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.6/site-packages (from keras>=2.0.0->kapre) (1.0.9)\r\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /opt/conda/lib/python3.6/site-packages (from keras>=2.0.0->kapre) (1.0.7)\r\n",
      "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /opt/conda/lib/python3.6/site-packages (from librosa>=0.5->kapre) (0.20.3)\r\n",
      "Requirement already satisfied: decorator>=3.0.0 in /opt/conda/lib/python3.6/site-packages (from librosa>=0.5->kapre) (4.3.0)\r\n",
      "Requirement already satisfied: numba>=0.38.0 in /opt/conda/lib/python3.6/site-packages (from librosa>=0.5->kapre) (0.38.0)\r\n",
      "Requirement already satisfied: audioread>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from librosa>=0.5->kapre) (2.1.6)\r\n",
      "Requirement already satisfied: joblib>=0.12 in /opt/conda/lib/python3.6/site-packages (from librosa>=0.5->kapre) (0.13.2)\r\n",
      "Requirement already satisfied: resampy>=0.2.0 in /opt/conda/lib/python3.6/site-packages (from librosa>=0.5->kapre) (0.2.1)\r\n",
      "Requirement already satisfied: llvmlite>=0.23.0dev0 in /opt/conda/lib/python3.6/site-packages (from numba>=0.38.0->librosa>=0.5->kapre) (0.23.1)\r\n",
      "Installing collected packages: kapre\r\n",
      "Successfully installed kapre-0.1.4\r\n",
      "\u001b[33mYou are using pip version 19.0.3, however version 19.1.1 is available.\r\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install kapre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:28: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:29: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(30, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:30: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(9, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:31: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(30, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:32: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(11, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:33: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(30, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:34: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:35: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(30, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:36: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:37: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(30, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:38: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(11, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:39: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(30, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:40: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(45, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "trainable_stft (Melspectrogr (None, 128, 32, 1)        296064    \n",
      "_________________________________________________________________\n",
      "additive_noise_1 (AdditiveNo (None, 128, 32, 1)        0         \n",
      "_________________________________________________________________\n",
      "normalization2d_1 (Normaliza (None, 128, 32, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 126, 30, 30)       300       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 28, 28)         9080      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 30, 26, 26)        2190      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 9, 24, 24)         2439      \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 30, 22, 22)        2460      \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 11, 20, 20)        2981      \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 30, 18, 18)        3000      \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 10, 16, 16)        2710      \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 30, 14, 14)        2730      \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 8, 12, 12)         2168      \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 30, 10, 10)        2190      \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 11, 8, 8)          2981      \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 30, 6, 6)          3000      \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 45, 4, 4)          12195     \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average (None, 22, 2, 4)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 176)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12)                2124      \n",
      "=================================================================\n",
      "Total params: 348,612\n",
      "Trainable params: 52,548\n",
      "Non-trainable params: 296,064\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import kapre\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,AveragePooling2D\n",
    "from kapre.time_frequency import Melspectrogram\n",
    "from kapre.utils import Normalization2D\n",
    "from kapre.augmentation import AdditiveNoise\n",
    "\n",
    "# 6 channels (!), maybe 1-sec audio signal, for an example.\n",
    "input_shape = (1,16000)\n",
    "sr = 16000\n",
    "model = Sequential()\n",
    "# A mel-spectrogram layer\n",
    "model.add(Melspectrogram(n_dft=512, n_hop=512, input_shape=input_shape,\n",
    "                         padding='same', sr=sr, n_mels=128,\n",
    "                         fmin=0.0, fmax=sr/2, power_melgram=1.0,\n",
    "                         return_decibel_melgram=True,trainable_fb=False,\n",
    "                         trainable_kernel=False,\n",
    "                         name='trainable_stft'))\n",
    "# Maybe some additive white noise.\n",
    "model.add(AdditiveNoise(power=0.1))\n",
    "# If you wanna normalise it per-frequency\n",
    "model.add(Normalization2D(str_axis='freq')) # or 'channel', 'time', 'batch', 'data_sample'\n",
    "# After this, it's just a usual keras workflow. For example..\n",
    "# Add some layers, e.g., model.add(some convolution layers..)\n",
    "# Compile the model\n",
    "model.add(Conv2D(30, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(Conv2D(8, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\n",
    "model.add(Conv2D(30, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\n",
    "model.add(Conv2D(9, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\n",
    "model.add(Conv2D(30, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\n",
    "model.add(Conv2D(11, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\n",
    "model.add(Conv2D(30, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\n",
    "model.add(Conv2D(10, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\n",
    "model.add(Conv2D(30, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\n",
    "model.add(Conv2D(8, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\n",
    "model.add(Conv2D(30, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\n",
    "model.add(Conv2D(11, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\n",
    "model.add(Conv2D(30, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\n",
    "model.add(Conv2D(45, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\n",
    "\n",
    "model.add(AveragePooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "# model.add(Dense(16))\n",
    "model.add(Dense(12, activation='softmax'))\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.adam(),metrics=['accuracy'])\n",
    "model.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "y_test = to_categorical(y_test)\n",
    "y_train = to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train.reshape(-1,13062,16000).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# X_test = X_test.reshape(X_test.shape[0], 20, 32, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = X_train[0].reshape(1,16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.predict(np.array([a]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Optimizer\n",
    "from keras import backend as K\n",
    "import six\n",
    "import copy\n",
    "from six.moves import zip\n",
    "from keras.utils.generic_utils import serialize_keras_object\n",
    "from keras.utils.generic_utils import deserialize_keras_object\n",
    "from keras.legacy import interfaces\n",
    "class AdamW(Optimizer):\n",
    "    \"\"\"Adam optimizer.\n",
    "    Default parameters follow those provided in the original paper.\n",
    "    # Arguments\n",
    "        lr: float >= 0. Learning rate.\n",
    "        beta_1: float, 0 < beta < 1. Generally close to 1.\n",
    "        beta_2: float, 0 < beta < 1. Generally close to 1.\n",
    "        epsilon: float >= 0. Fuzz factor.\n",
    "        decay: float >= 0. Learning rate decay over each update.\n",
    "        weight_decay: float >= 0. Decoupled weight decay over each update.\n",
    "    # References\n",
    "        - [Adam - A Method for Stochastic Optimization](http://arxiv.org/abs/1412.6980v8)\n",
    "        - [Optimization for Deep Learning Highlights in 2017](http://ruder.io/deep-learning-optimization-2017/index.html)\n",
    "        - [Fixing Weight Decay Regularization in Adam](https://arxiv.org/abs/1711.05101)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, lr=0.001, beta_1=0.9, beta_2=0.999, weight_decay=1e-4,  # decoupled weight decay (1/6)\n",
    "                 epsilon=1e-8, decay=0., **kwargs):\n",
    "        super(AdamW, self).__init__(**kwargs)\n",
    "        with K.name_scope(self.__class__.__name__):\n",
    "            self.iterations = K.variable(0, dtype='int64', name='iterations')\n",
    "            self.lr = K.variable(lr, name='lr')\n",
    "            self.init_lr = lr # decoupled weight decay (2/6)\n",
    "            self.beta_1 = K.variable(beta_1, name='beta_1')\n",
    "            self.beta_2 = K.variable(beta_2, name='beta_2')\n",
    "            self.decay = K.variable(decay, name='decay')\n",
    "            self.wd = K.variable(weight_decay, name='weight_decay') # decoupled weight decay (3/6)\n",
    "        self.epsilon = epsilon\n",
    "        self.initial_decay = decay\n",
    "\n",
    "    @interfaces.legacy_get_updates_support\n",
    "    def get_updates(self, loss, params):\n",
    "        grads = self.get_gradients(loss, params)\n",
    "        self.updates = [K.update_add(self.iterations, 1)]\n",
    "        wd = self.wd # decoupled weight decay (4/6)\n",
    "\n",
    "        lr = self.lr\n",
    "        if self.initial_decay > 0:\n",
    "            lr *= (1. / (1. + self.decay * K.cast(self.iterations,\n",
    "                                                  K.dtype(self.decay))))\n",
    "        eta_t = lr / self.init_lr # decoupled weight decay (5/6)\n",
    "\n",
    "        t = K.cast(self.iterations, K.floatx()) + 1\n",
    "        lr_t = lr * (K.sqrt(1. - K.pow(self.beta_2, t)) /\n",
    "                     (1. - K.pow(self.beta_1, t)))\n",
    "\n",
    "        ms = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n",
    "        vs = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n",
    "        self.weights = [self.iterations] + ms + vs\n",
    "\n",
    "        for p, g, m, v in zip(params, grads, ms, vs):\n",
    "            m_t = (self.beta_1 * m) + (1. - self.beta_1) * g\n",
    "            v_t = (self.beta_2 * v) + (1. - self.beta_2) * K.square(g)\n",
    "            p_t = p - lr_t * m_t / (K.sqrt(v_t) + self.epsilon) - eta_t * wd * p # decoupled weight decay (6/6)\n",
    "\n",
    "            self.updates.append(K.update(m, m_t))\n",
    "            self.updates.append(K.update(v, v_t))\n",
    "            new_p = p_t\n",
    "\n",
    "            # Apply constraints.\n",
    "            if getattr(p, 'constraint', None) is not None:\n",
    "                new_p = p.constraint(new_p)\n",
    "\n",
    "            self.updates.append(K.update(p, new_p))\n",
    "        return self.updates\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'lr': float(K.get_value(self.lr)),\n",
    "                  'beta_1': float(K.get_value(self.beta_1)),\n",
    "                  'beta_2': float(K.get_value(self.beta_2)),\n",
    "                  'decay': float(K.get_value(self.decay)),\n",
    "                  'weight_decay': float(K.get_value(self.wd)),\n",
    "                  'epsilon': self.epsilon}\n",
    "        base_config = super(AdamW, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Conv2D(64, kernel_size=(20, 8), activation='relu', input_shape=(20, 32, 1)))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2),dim_ordering=\"th\"))\n",
    "# model.add(Dropout(0.25))\n",
    "# model.add(Conv2D(64, kernel_size=(10, 4), activation='relu',dim_ordering=\"th\"))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2),dim_ordering=\"th\"))\n",
    "# model.add(Dropout(0.25))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(128, activation='relu'))\n",
    "# model.add(Dropout(0.25))\n",
    "# model.add(Dense(10, activation='softmax'))\n",
    "# model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "#               optimizer=keras.optimizers.adam(),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 38071 samples, validate on 26048 samples\n",
      "Epoch 1/100\n",
      "38071/38071 [==============================] - 13s 347us/step - loss: 1.4585 - acc: 0.6262 - val_loss: 1.2883 - val_acc: 0.6329\n",
      "Epoch 2/100\n",
      "38071/38071 [==============================] - 9s 229us/step - loss: 1.1516 - acc: 0.6478 - val_loss: 0.9298 - val_acc: 0.6940\n",
      "Epoch 3/100\n",
      "38071/38071 [==============================] - 9s 229us/step - loss: 0.8027 - acc: 0.7356 - val_loss: 0.6556 - val_acc: 0.7951\n",
      "Epoch 4/100\n",
      "38071/38071 [==============================] - 9s 229us/step - loss: 0.5557 - acc: 0.8182 - val_loss: 0.4818 - val_acc: 0.8461\n",
      "Epoch 5/100\n",
      "38071/38071 [==============================] - 9s 229us/step - loss: 0.4399 - acc: 0.8591 - val_loss: 0.4432 - val_acc: 0.8599\n",
      "Epoch 6/100\n",
      "38071/38071 [==============================] - 9s 230us/step - loss: 0.3730 - acc: 0.8826 - val_loss: 0.3817 - val_acc: 0.8810\n",
      "Epoch 7/100\n",
      "38071/38071 [==============================] - 9s 232us/step - loss: 0.3268 - acc: 0.8969 - val_loss: 0.3102 - val_acc: 0.9052\n",
      "Epoch 8/100\n",
      "38071/38071 [==============================] - 9s 229us/step - loss: 0.2938 - acc: 0.9068 - val_loss: 0.3142 - val_acc: 0.9038\n",
      "Epoch 9/100\n",
      "38071/38071 [==============================] - 9s 229us/step - loss: 0.2735 - acc: 0.9141 - val_loss: 0.3032 - val_acc: 0.9076\n",
      "Epoch 10/100\n",
      "38071/38071 [==============================] - 9s 229us/step - loss: 0.2549 - acc: 0.9198 - val_loss: 0.2912 - val_acc: 0.9127\n",
      "Epoch 11/100\n",
      "38071/38071 [==============================] - 9s 229us/step - loss: 0.2396 - acc: 0.9249 - val_loss: 0.2916 - val_acc: 0.9137\n",
      "Epoch 12/100\n",
      "38071/38071 [==============================] - 9s 228us/step - loss: 0.2281 - acc: 0.9288 - val_loss: 0.2820 - val_acc: 0.9178\n",
      "Epoch 13/100\n",
      "38071/38071 [==============================] - 9s 229us/step - loss: 0.2179 - acc: 0.9306 - val_loss: 0.2679 - val_acc: 0.9200\n",
      "Epoch 14/100\n",
      "38071/38071 [==============================] - 9s 229us/step - loss: 0.2046 - acc: 0.9351 - val_loss: 0.2521 - val_acc: 0.9252\n",
      "Epoch 15/100\n",
      "38071/38071 [==============================] - 9s 229us/step - loss: 0.1946 - acc: 0.9388 - val_loss: 0.2626 - val_acc: 0.9238\n",
      "Epoch 16/100\n",
      "38071/38071 [==============================] - 9s 229us/step - loss: 0.1980 - acc: 0.9369 - val_loss: 0.3102 - val_acc: 0.9077\n",
      "Epoch 17/100\n",
      "38071/38071 [==============================] - 9s 231us/step - loss: 0.1791 - acc: 0.9427 - val_loss: 0.2659 - val_acc: 0.9219\n",
      "Epoch 18/100\n",
      "38071/38071 [==============================] - 9s 231us/step - loss: 0.1750 - acc: 0.9442 - val_loss: 0.2732 - val_acc: 0.9259\n",
      "Epoch 19/100\n",
      "38071/38071 [==============================] - 9s 229us/step - loss: 0.1654 - acc: 0.9481 - val_loss: 0.2667 - val_acc: 0.9285\n",
      "Epoch 20/100\n",
      "38071/38071 [==============================] - 9s 228us/step - loss: 0.1653 - acc: 0.9472 - val_loss: 0.2473 - val_acc: 0.9303\n",
      "Epoch 21/100\n",
      "38071/38071 [==============================] - 9s 230us/step - loss: 0.1580 - acc: 0.9502 - val_loss: 0.3044 - val_acc: 0.9178\n",
      "Epoch 22/100\n",
      "38071/38071 [==============================] - 9s 227us/step - loss: 0.1529 - acc: 0.9523 - val_loss: 0.2757 - val_acc: 0.9202\n",
      "Epoch 23/100\n",
      "38071/38071 [==============================] - 9s 228us/step - loss: 0.1449 - acc: 0.9542 - val_loss: 0.2500 - val_acc: 0.9282\n",
      "Epoch 24/100\n",
      "38071/38071 [==============================] - 9s 228us/step - loss: 0.1482 - acc: 0.9534 - val_loss: 0.2571 - val_acc: 0.9270\n",
      "Epoch 25/100\n",
      "38071/38071 [==============================] - 9s 227us/step - loss: 0.1421 - acc: 0.9538 - val_loss: 0.2481 - val_acc: 0.9294\n",
      "Epoch 26/100\n",
      "38071/38071 [==============================] - 9s 228us/step - loss: 0.1346 - acc: 0.9567 - val_loss: 0.2612 - val_acc: 0.9287\n",
      "Epoch 27/100\n",
      "38071/38071 [==============================] - 9s 228us/step - loss: 0.1342 - acc: 0.9577 - val_loss: 0.2470 - val_acc: 0.9365\n",
      "Epoch 28/100\n",
      "38071/38071 [==============================] - 9s 230us/step - loss: 0.1321 - acc: 0.9579 - val_loss: 0.2466 - val_acc: 0.9312\n",
      "Epoch 29/100\n",
      "38071/38071 [==============================] - 9s 229us/step - loss: 0.1248 - acc: 0.9600 - val_loss: 0.2580 - val_acc: 0.9277\n",
      "Epoch 30/100\n",
      "38071/38071 [==============================] - 9s 228us/step - loss: 0.1179 - acc: 0.9621 - val_loss: 0.2609 - val_acc: 0.9301\n",
      "Epoch 31/100\n",
      "38071/38071 [==============================] - 9s 229us/step - loss: 0.1246 - acc: 0.9601 - val_loss: 0.2710 - val_acc: 0.9317\n",
      "Epoch 32/100\n",
      "38071/38071 [==============================] - 9s 228us/step - loss: 0.1174 - acc: 0.9622 - val_loss: 0.2759 - val_acc: 0.9307\n",
      "Epoch 33/100\n",
      "38071/38071 [==============================] - 9s 228us/step - loss: 0.1170 - acc: 0.9634 - val_loss: 0.3094 - val_acc: 0.9246\n",
      "Epoch 34/100\n",
      "38071/38071 [==============================] - 9s 228us/step - loss: 0.1140 - acc: 0.9631 - val_loss: 0.2894 - val_acc: 0.9221\n",
      "Epoch 35/100\n",
      "38071/38071 [==============================] - 9s 230us/step - loss: 0.1110 - acc: 0.9648 - val_loss: 0.2784 - val_acc: 0.9324\n",
      "Epoch 36/100\n",
      "38071/38071 [==============================] - 9s 229us/step - loss: 0.1103 - acc: 0.9652 - val_loss: 0.2411 - val_acc: 0.9341\n",
      "Epoch 37/100\n",
      "38071/38071 [==============================] - 9s 228us/step - loss: 0.1056 - acc: 0.9665 - val_loss: 0.2699 - val_acc: 0.9312\n",
      "Epoch 38/100\n",
      "38071/38071 [==============================] - 9s 229us/step - loss: 0.1092 - acc: 0.9655 - val_loss: 0.2645 - val_acc: 0.9316\n",
      "Epoch 39/100\n",
      "38071/38071 [==============================] - 9s 228us/step - loss: 0.1110 - acc: 0.9640 - val_loss: 0.2534 - val_acc: 0.9364\n",
      "Epoch 40/100\n",
      "38071/38071 [==============================] - 9s 227us/step - loss: 0.1033 - acc: 0.9669 - val_loss: 0.2769 - val_acc: 0.9308\n",
      "Epoch 41/100\n",
      "38071/38071 [==============================] - 9s 228us/step - loss: 0.0990 - acc: 0.9685 - val_loss: 0.2725 - val_acc: 0.9310\n",
      "Epoch 42/100\n",
      "38071/38071 [==============================] - 9s 231us/step - loss: 0.0964 - acc: 0.9690 - val_loss: 0.2875 - val_acc: 0.9324\n",
      "Epoch 43/100\n",
      "38071/38071 [==============================] - 9s 228us/step - loss: 0.1016 - acc: 0.9668 - val_loss: 0.2565 - val_acc: 0.9370\n",
      "Epoch 44/100\n",
      "38071/38071 [==============================] - 9s 228us/step - loss: 0.0940 - acc: 0.9696 - val_loss: 0.2602 - val_acc: 0.9349\n",
      "Epoch 45/100\n",
      "38071/38071 [==============================] - 9s 229us/step - loss: 0.0967 - acc: 0.9688 - val_loss: 0.2712 - val_acc: 0.9325\n",
      "Epoch 46/100\n",
      "11200/38071 [=======>......................] - ETA: 4s - loss: 0.0867 - acc: 0.9720"
     ]
    }
   ],
   "source": [
    "model.fit(X_train[1000:], y_train[1000:], batch_size=100, epochs=100, verbose=1, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense_1/Softmax\n",
      "trainable_stft_input\n"
     ]
    }
   ],
   "source": [
    "print(model.output.op.name)\n",
    "print(model.input.op.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "851\n",
      "CPU times: user 3.4 s, sys: 232 ms, total: 3.63 s\n",
      "Wall time: 2.77 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "count = 0\n",
    "for i in range(1000):    \n",
    "    tesval = np.array([X_train[i]]).reshape(1,1,16000)\n",
    "    if np.argmax(model.predict(tesval)) ==  np.argmax(y_train[i]):\n",
    "        count+= 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(model.predict(tesval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dense_1/Softmax'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.output.op.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('94_cnn.h5',keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"yo.h5\")\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown layer: Melspectrogram",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-d577127b235e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlite\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mconverter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFLiteConverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_keras_model_file\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m'yo.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtfmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallow_custom_ops\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mopen\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"model.tflite\"\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36mfrom_keras_model_file\u001b[0;34m(cls, model_file, input_arrays, input_shapes, output_arrays)\u001b[0m\n\u001b[1;32m    368\u001b[0m     \u001b[0m_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m     \u001b[0m_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_learning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m     \u001b[0mkeras_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m     \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    232\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No model found in config file.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_from_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;31m# set weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/engine/saving.py\u001b[0m in \u001b[0;36mmodel_from_config\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m    322\u001b[0m                     '`Sequential.from_config(config)`?')\n\u001b[1;32m    323\u001b[0m   \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeserialize\u001b[0m  \u001b[0;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/layers/serialization.py\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m     72\u001b[0m       \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m       \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m       printable_module_name='layer')\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    190\u001b[0m             custom_objects=dict(\n\u001b[1;32m    191\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_GLOBAL_CUSTOM_OBJECTS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m                 list(custom_objects.items())))\n\u001b[0m\u001b[1;32m    193\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mCustomObjectScope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m    347\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlayer_config\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayer_configs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m       layer = layer_module.deserialize(layer_config,\n\u001b[0;32m--> 349\u001b[0;31m                                        custom_objects=custom_objects)\n\u001b[0m\u001b[1;32m    350\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbuild_input_shape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/layers/serialization.py\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m     72\u001b[0m       \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m       \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m       printable_module_name='layer')\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midentifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     (cls, cls_config) = class_and_config_for_serialized_keras_object(\n\u001b[0;32m--> 181\u001b[0;31m         config, module_objects, custom_objects, printable_module_name)\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'from_config'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mclass_and_config_for_serialized_keras_object\u001b[0;34m(config, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule_objects\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unknown '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mprintable_module_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mclass_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown layer: Melspectrogram"
     ]
    }
   ],
   "source": [
    "from tensorflow.contrib import lite\n",
    "converter = lite.TFLiteConverter.from_keras_model_file( 'yo.h5')\n",
    "tfmodel = converter.convert()\n",
    "converter.allow_custom_ops=True\n",
    "open (\"model.tflite\" , \"wb\") .write(tfmodel)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
