{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Watch_accelerometer.csv', 'Phones_accelerometer.csv', 'Phones_gyroscope.csv', 'readme.txt', 'Watch_gyroscope.csv']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "data_Dir = \"../input\"\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_Dir + \"/Watch_accelerometer.csv\" )\n",
    "df2 = pd.read_csv(data_Dir + \"/Watch_gyroscope.csv\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.dropna(how='any',axis=0)\n",
    "# df2 = df2.dropna(how='any',axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Arrival_Time</th>\n",
       "      <th>Creation_Time</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>User</th>\n",
       "      <th>Model</th>\n",
       "      <th>Device</th>\n",
       "      <th>gt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1424696638740</td>\n",
       "      <td>27920678471000</td>\n",
       "      <td>-0.565032</td>\n",
       "      <td>-9.572019</td>\n",
       "      <td>-0.614113</td>\n",
       "      <td>a</td>\n",
       "      <td>gear</td>\n",
       "      <td>gear_1</td>\n",
       "      <td>stand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1424696638740</td>\n",
       "      <td>27920681910000</td>\n",
       "      <td>-0.832584</td>\n",
       "      <td>-9.713276</td>\n",
       "      <td>-0.606930</td>\n",
       "      <td>a</td>\n",
       "      <td>gear</td>\n",
       "      <td>gear_1</td>\n",
       "      <td>stand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1424696638740</td>\n",
       "      <td>27920692014000</td>\n",
       "      <td>-1.018134</td>\n",
       "      <td>-9.935339</td>\n",
       "      <td>-0.544082</td>\n",
       "      <td>a</td>\n",
       "      <td>gear</td>\n",
       "      <td>gear_1</td>\n",
       "      <td>stand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1424696638741</td>\n",
       "      <td>27920701983000</td>\n",
       "      <td>-1.222838</td>\n",
       "      <td>-10.142437</td>\n",
       "      <td>-0.566229</td>\n",
       "      <td>a</td>\n",
       "      <td>gear</td>\n",
       "      <td>gear_1</td>\n",
       "      <td>stand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1424696638741</td>\n",
       "      <td>27920711906000</td>\n",
       "      <td>-1.577180</td>\n",
       "      <td>-10.480618</td>\n",
       "      <td>-0.402824</td>\n",
       "      <td>a</td>\n",
       "      <td>gear</td>\n",
       "      <td>gear_1</td>\n",
       "      <td>stand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1424696638741</td>\n",
       "      <td>27920721675000</td>\n",
       "      <td>-2.164358</td>\n",
       "      <td>-10.920552</td>\n",
       "      <td>-0.183755</td>\n",
       "      <td>a</td>\n",
       "      <td>gear</td>\n",
       "      <td>gear_1</td>\n",
       "      <td>stand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>1424696638741</td>\n",
       "      <td>27920731721000</td>\n",
       "      <td>-2.973000</td>\n",
       "      <td>-11.063007</td>\n",
       "      <td>0.211887</td>\n",
       "      <td>a</td>\n",
       "      <td>gear</td>\n",
       "      <td>gear_1</td>\n",
       "      <td>stand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>1424696638741</td>\n",
       "      <td>27920743061000</td>\n",
       "      <td>-3.888184</td>\n",
       "      <td>-11.082760</td>\n",
       "      <td>0.684742</td>\n",
       "      <td>a</td>\n",
       "      <td>gear</td>\n",
       "      <td>gear_1</td>\n",
       "      <td>stand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1424696638742</td>\n",
       "      <td>27920751586000</td>\n",
       "      <td>-4.891953</td>\n",
       "      <td>-10.890625</td>\n",
       "      <td>1.015740</td>\n",
       "      <td>a</td>\n",
       "      <td>gear</td>\n",
       "      <td>gear_1</td>\n",
       "      <td>stand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>1424696638742</td>\n",
       "      <td>27920825873000</td>\n",
       "      <td>-12.600683</td>\n",
       "      <td>-7.674015</td>\n",
       "      <td>-1.179144</td>\n",
       "      <td>a</td>\n",
       "      <td>gear</td>\n",
       "      <td>gear_1</td>\n",
       "      <td>stand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>1424696638742</td>\n",
       "      <td>27920827227000</td>\n",
       "      <td>-9.214086</td>\n",
       "      <td>-4.556765</td>\n",
       "      <td>0.217274</td>\n",
       "      <td>a</td>\n",
       "      <td>gear</td>\n",
       "      <td>gear_1</td>\n",
       "      <td>stand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>1424696638742</td>\n",
       "      <td>27920830887000</td>\n",
       "      <td>-9.214086</td>\n",
       "      <td>-4.556765</td>\n",
       "      <td>0.217274</td>\n",
       "      <td>a</td>\n",
       "      <td>gear</td>\n",
       "      <td>gear_1</td>\n",
       "      <td>stand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>1424696638742</td>\n",
       "      <td>27920840675000</td>\n",
       "      <td>-9.240421</td>\n",
       "      <td>-4.104859</td>\n",
       "      <td>0.223259</td>\n",
       "      <td>a</td>\n",
       "      <td>gear</td>\n",
       "      <td>gear_1</td>\n",
       "      <td>stand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>1424696638743</td>\n",
       "      <td>27920853362000</td>\n",
       "      <td>-9.273342</td>\n",
       "      <td>-3.729568</td>\n",
       "      <td>0.240617</td>\n",
       "      <td>a</td>\n",
       "      <td>gear</td>\n",
       "      <td>gear_1</td>\n",
       "      <td>stand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>1424696638897</td>\n",
       "      <td>27921589696000</td>\n",
       "      <td>-9.166800</td>\n",
       "      <td>-3.670311</td>\n",
       "      <td>-0.729633</td>\n",
       "      <td>a</td>\n",
       "      <td>gear</td>\n",
       "      <td>gear_1</td>\n",
       "      <td>stand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>1424696639000</td>\n",
       "      <td>27921599563000</td>\n",
       "      <td>-9.153033</td>\n",
       "      <td>-3.605668</td>\n",
       "      <td>-0.732626</td>\n",
       "      <td>a</td>\n",
       "      <td>gear</td>\n",
       "      <td>gear_1</td>\n",
       "      <td>stand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>1424696639001</td>\n",
       "      <td>27921609644000</td>\n",
       "      <td>-9.151238</td>\n",
       "      <td>-3.612252</td>\n",
       "      <td>-0.745195</td>\n",
       "      <td>a</td>\n",
       "      <td>gear</td>\n",
       "      <td>gear_1</td>\n",
       "      <td>stand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>1424696639001</td>\n",
       "      <td>27921619491000</td>\n",
       "      <td>-9.202713</td>\n",
       "      <td>-3.646369</td>\n",
       "      <td>-0.729633</td>\n",
       "      <td>a</td>\n",
       "      <td>gear</td>\n",
       "      <td>gear_1</td>\n",
       "      <td>stand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>1424696639001</td>\n",
       "      <td>27921629562000</td>\n",
       "      <td>-9.288904</td>\n",
       "      <td>-3.736152</td>\n",
       "      <td>-0.726640</td>\n",
       "      <td>a</td>\n",
       "      <td>gear</td>\n",
       "      <td>gear_1</td>\n",
       "      <td>stand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>1424696639001</td>\n",
       "      <td>27921639447000</td>\n",
       "      <td>-9.290700</td>\n",
       "      <td>-3.772065</td>\n",
       "      <td>-0.730231</td>\n",
       "      <td>a</td>\n",
       "      <td>gear</td>\n",
       "      <td>gear_1</td>\n",
       "      <td>stand</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Index   Arrival_Time   Creation_Time  ...    Model  Device     gt\n",
       "0       0  1424696638740  27920678471000  ...     gear  gear_1  stand\n",
       "1       1  1424696638740  27920681910000  ...     gear  gear_1  stand\n",
       "2       2  1424696638740  27920692014000  ...     gear  gear_1  stand\n",
       "3       3  1424696638741  27920701983000  ...     gear  gear_1  stand\n",
       "4       4  1424696638741  27920711906000  ...     gear  gear_1  stand\n",
       "5       5  1424696638741  27920721675000  ...     gear  gear_1  stand\n",
       "6       6  1424696638741  27920731721000  ...     gear  gear_1  stand\n",
       "7       7  1424696638741  27920743061000  ...     gear  gear_1  stand\n",
       "8       8  1424696638742  27920751586000  ...     gear  gear_1  stand\n",
       "9       9  1424696638742  27920825873000  ...     gear  gear_1  stand\n",
       "10     10  1424696638742  27920827227000  ...     gear  gear_1  stand\n",
       "11     11  1424696638742  27920830887000  ...     gear  gear_1  stand\n",
       "12     12  1424696638742  27920840675000  ...     gear  gear_1  stand\n",
       "13     13  1424696638743  27920853362000  ...     gear  gear_1  stand\n",
       "14     14  1424696638897  27921589696000  ...     gear  gear_1  stand\n",
       "15     15  1424696639000  27921599563000  ...     gear  gear_1  stand\n",
       "16     16  1424696639001  27921609644000  ...     gear  gear_1  stand\n",
       "17     17  1424696639001  27921619491000  ...     gear  gear_1  stand\n",
       "18     18  1424696639001  27921629562000  ...     gear  gear_1  stand\n",
       "19     19  1424696639001  27921639447000  ...     gear  gear_1  stand\n",
       "\n",
       "[20 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Arrival_Time</th>\n",
       "      <th>Creation_Time</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>User</th>\n",
       "      <th>Model</th>\n",
       "      <th>Device</th>\n",
       "      <th>gt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1424696638743</td>\n",
       "      <td>27920678496000</td>\n",
       "      <td>-0.162187</td>\n",
       "      <td>-0.022104</td>\n",
       "      <td>0.059655</td>\n",
       "      <td>a</td>\n",
       "      <td>gear</td>\n",
       "      <td>gear_1</td>\n",
       "      <td>stand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1424696638743</td>\n",
       "      <td>27920681926000</td>\n",
       "      <td>-0.183225</td>\n",
       "      <td>-0.061785</td>\n",
       "      <td>0.012517</td>\n",
       "      <td>a</td>\n",
       "      <td>gear</td>\n",
       "      <td>gear_1</td>\n",
       "      <td>stand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1424696638743</td>\n",
       "      <td>27920692031000</td>\n",
       "      <td>-0.180829</td>\n",
       "      <td>-0.108657</td>\n",
       "      <td>-0.036485</td>\n",
       "      <td>a</td>\n",
       "      <td>gear</td>\n",
       "      <td>gear_1</td>\n",
       "      <td>stand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1424696638743</td>\n",
       "      <td>27920701997000</td>\n",
       "      <td>-0.147805</td>\n",
       "      <td>-0.157925</td>\n",
       "      <td>-0.098537</td>\n",
       "      <td>a</td>\n",
       "      <td>gear</td>\n",
       "      <td>gear_1</td>\n",
       "      <td>stand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>1424696638744</td>\n",
       "      <td>27920743068000</td>\n",
       "      <td>0.182160</td>\n",
       "      <td>-0.323574</td>\n",
       "      <td>-0.277235</td>\n",
       "      <td>a</td>\n",
       "      <td>gear</td>\n",
       "      <td>gear_1</td>\n",
       "      <td>stand</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index   Arrival_Time   Creation_Time  ...    Model  Device     gt\n",
       "0      0  1424696638743  27920678496000  ...     gear  gear_1  stand\n",
       "1      1  1424696638743  27920681926000  ...     gear  gear_1  stand\n",
       "2      2  1424696638743  27920692031000  ...     gear  gear_1  stand\n",
       "3      3  1424696638743  27920701997000  ...     gear  gear_1  stand\n",
       "4      7  1424696638744  27920743068000  ...     gear  gear_1  stand\n",
       "\n",
       "[5 rows x 10 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3540962"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(how='any',axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(labels = ['Arrival_Time','Creation_Time','Index', 'User'], axis=1)\n",
    "df2 = df2.drop(labels = ['Arrival_Time','Creation_Time','Index', 'User','Model','Device'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "length1 = len(df)\n",
    "length2 = len(df2)\n",
    "length = min(length1, length2)\n",
    "df = df.head(length)\n",
    "df2 = df2.head(length)\n",
    "df2.columns = ['x1', 'y1', 'z1', 'gt1']\n",
    "data = pd.concat([df, df2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = ['null']\n",
    "data = data[~data['gt'].isin(to_drop)]\n",
    "data = data[~data['gt1'].isin(to_drop)]\n",
    "\n",
    "data = data.drop(labels = ['gt1'], axis=1)\n",
    "\n",
    "data = data.iloc[::10, :]\n",
    "\n",
    "cols_to_norm = ['x','y','z', 'x1','y1','z1']\n",
    "data[cols_to_norm] = data[cols_to_norm].apply(lambda x: (x - x.mean()) / (x.max() - x.min()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>Model</th>\n",
       "      <th>Device</th>\n",
       "      <th>gt</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>z1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.000438</td>\n",
       "      <td>-0.180286</td>\n",
       "      <td>-0.068694</td>\n",
       "      <td>gear</td>\n",
       "      <td>gear_1</td>\n",
       "      <td>stand</td>\n",
       "      <td>-0.003297</td>\n",
       "      <td>-0.001565</td>\n",
       "      <td>0.003418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.220615</td>\n",
       "      <td>-0.052724</td>\n",
       "      <td>-0.047486</td>\n",
       "      <td>gear</td>\n",
       "      <td>gear_1</td>\n",
       "      <td>stand</td>\n",
       "      <td>0.013210</td>\n",
       "      <td>-0.032330</td>\n",
       "      <td>-0.055840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.221041</td>\n",
       "      <td>-0.033709</td>\n",
       "      <td>-0.072924</td>\n",
       "      <td>gear</td>\n",
       "      <td>gear_1</td>\n",
       "      <td>stand</td>\n",
       "      <td>-0.000254</td>\n",
       "      <td>0.000585</td>\n",
       "      <td>-0.003290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>-0.224074</td>\n",
       "      <td>-0.027299</td>\n",
       "      <td>-0.072282</td>\n",
       "      <td>gear</td>\n",
       "      <td>gear_1</td>\n",
       "      <td>stand</td>\n",
       "      <td>-0.000173</td>\n",
       "      <td>-0.004702</td>\n",
       "      <td>-0.003021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>-0.217735</td>\n",
       "      <td>-0.031882</td>\n",
       "      <td>-0.070206</td>\n",
       "      <td>gear</td>\n",
       "      <td>gear_1</td>\n",
       "      <td>stand</td>\n",
       "      <td>-0.000835</td>\n",
       "      <td>-0.002902</td>\n",
       "      <td>-0.002691</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           x         y         z    ...           x1        y1        z1\n",
       "0  -0.000438 -0.180286 -0.068694    ...    -0.003297 -0.001565  0.003418\n",
       "10 -0.220615 -0.052724 -0.047486    ...     0.013210 -0.032330 -0.055840\n",
       "20 -0.221041 -0.033709 -0.072924    ...    -0.000254  0.000585 -0.003290\n",
       "30 -0.224074 -0.027299 -0.072282    ...    -0.000173 -0.004702 -0.003021\n",
       "40 -0.217735 -0.031882 -0.070206    ...    -0.000835 -0.002902 -0.002691\n",
       "\n",
       "[5 rows x 9 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data[['gt']]\n",
    "data = data.drop(labels = ['gt','Device','Model'], axis = 1)\n",
    "data = pd.get_dummies(data)\n",
    "parameters1 = len(data.columns)\t\n",
    "\n",
    "y = pd.get_dummies(y)\n",
    "parameters2 = len(y.columns)\n",
    "\n",
    "\n",
    "data = np.array(data)\n",
    "y = np.array(y)\n",
    "\n",
    "m = len(data)\n",
    "crossval = round(3*m/4)\n",
    "train_data = data[0:crossval,:]\n",
    "train_data_y = y[0:crossval,:]\n",
    "\n",
    "test_data = data[crossval:,:]\n",
    "test_data_y = y[crossval:,:]\n",
    "\n",
    "X_train = train_data\n",
    "X_train = np.reshape(X_train, (X_train.shape[0],1,X_train.shape[1]))\n",
    "X_train = np.array(X_train)\n",
    "\n",
    "y_train = train_data_y\n",
    "\n",
    "X_test = test_data\n",
    "X_test = np.reshape(X_test, (X_test.shape[0],1,X_test.shape[1]))\n",
    "X_test = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00043755, -0.18028597, -0.06869415, -0.00329739, -0.00156469,\n",
       "         0.00341772]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(344557, 6)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 0], dtype=uint8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = test_data_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Activity_dict = {'stand':1,'sit':2,'walk':3,'stairsup':4,'stairsdown':5,'bike':6}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,LSTM,Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing import  sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(LSTM(24, input_dim = parameters1,return_sequences=True))\n",
    "# model.add(LSTM(12,return_sequences=False))\n",
    "# model.add(Dense(6, activation='softmax'))\n",
    "# opt = SGD(lr=0.001, momentum=0.9, clipvalue=5.0)\n",
    "# model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "# model.fit(X_train,y_train, validation_data=(X_test,y_test), epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.any(np.isnan(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(np.isfinite(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103047"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(X_train).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.nan_to_num(X_train)\n",
    "X_test = np.nan_to_num(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'NeuralNetworkTrain' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-1b5d9412d105>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mNeuralNetworkTrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'NeuralNetworkTrain' is not defined"
     ]
    }
   ],
   "source": [
    "NeuralNetworkTrain(X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:2: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "  \n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:2: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(24, return_sequences=True, input_shape=(None, 6))`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 258418 samples, validate on 86139 samples\n",
      "Epoch 1/500\n",
      "258418/258418 [==============================] - 4s 17us/step - loss: 1.5198 - acc: 0.3424 - val_loss: 1.5842 - val_acc: 0.3247\n",
      "Epoch 2/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 1.3095 - acc: 0.3233 - val_loss: 1.7962 - val_acc: 0.2553\n",
      "Epoch 3/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 1.2641 - acc: 0.3316 - val_loss: 1.7965 - val_acc: 0.2623\n",
      "Epoch 4/500\n",
      "258418/258418 [==============================] - 2s 7us/step - loss: 1.2345 - acc: 0.3457 - val_loss: 1.7777 - val_acc: 0.2668\n",
      "Epoch 5/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 1.2024 - acc: 0.3587 - val_loss: 1.7894 - val_acc: 0.2844\n",
      "Epoch 6/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 1.1678 - acc: 0.3711 - val_loss: 1.8159 - val_acc: 0.3032\n",
      "Epoch 7/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 1.1360 - acc: 0.3904 - val_loss: 1.8147 - val_acc: 0.3007\n",
      "Epoch 8/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 1.1127 - acc: 0.4105 - val_loss: 1.8216 - val_acc: 0.2933\n",
      "Epoch 9/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 1.0956 - acc: 0.4133 - val_loss: 1.8161 - val_acc: 0.2896\n",
      "Epoch 10/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 1.0813 - acc: 0.4283 - val_loss: 1.8011 - val_acc: 0.2840\n",
      "Epoch 11/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 1.0678 - acc: 0.4453 - val_loss: 1.7836 - val_acc: 0.2789\n",
      "Epoch 12/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 1.0529 - acc: 0.4516 - val_loss: 1.7585 - val_acc: 0.2859\n",
      "Epoch 13/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 1.0366 - acc: 0.4604 - val_loss: 1.7367 - val_acc: 0.2947\n",
      "Epoch 14/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 1.0195 - acc: 0.4717 - val_loss: 1.7277 - val_acc: 0.3127\n",
      "Epoch 15/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 1.0029 - acc: 0.4826 - val_loss: 1.7074 - val_acc: 0.3207\n",
      "Epoch 16/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.9879 - acc: 0.4890 - val_loss: 1.6906 - val_acc: 0.3284\n",
      "Epoch 17/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.9735 - acc: 0.4944 - val_loss: 1.6799 - val_acc: 0.3337\n",
      "Epoch 18/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.9588 - acc: 0.5002 - val_loss: 1.6660 - val_acc: 0.3286\n",
      "Epoch 19/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.9428 - acc: 0.5046 - val_loss: 1.6533 - val_acc: 0.3342\n",
      "Epoch 20/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.9255 - acc: 0.5097 - val_loss: 1.6391 - val_acc: 0.3423\n",
      "Epoch 21/500\n",
      "258418/258418 [==============================] - 2s 7us/step - loss: 0.9090 - acc: 0.5145 - val_loss: 1.6223 - val_acc: 0.3447\n",
      "Epoch 22/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.8938 - acc: 0.5200 - val_loss: 1.6064 - val_acc: 0.3485\n",
      "Epoch 23/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.8802 - acc: 0.5244 - val_loss: 1.5916 - val_acc: 0.3501\n",
      "Epoch 24/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.8676 - acc: 0.5283 - val_loss: 1.5794 - val_acc: 0.3574\n",
      "Epoch 25/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.8563 - acc: 0.5316 - val_loss: 1.5670 - val_acc: 0.3625\n",
      "Epoch 26/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.8462 - acc: 0.5343 - val_loss: 1.5595 - val_acc: 0.3641\n",
      "Epoch 27/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.8368 - acc: 0.5372 - val_loss: 1.5551 - val_acc: 0.3663\n",
      "Epoch 28/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.8278 - acc: 0.5395 - val_loss: 1.5582 - val_acc: 0.3662\n",
      "Epoch 29/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.8198 - acc: 0.5421 - val_loss: 1.5490 - val_acc: 0.3662\n",
      "Epoch 30/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.8120 - acc: 0.5448 - val_loss: 1.5479 - val_acc: 0.3681\n",
      "Epoch 31/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.8051 - acc: 0.5468 - val_loss: 1.5369 - val_acc: 0.3714\n",
      "Epoch 32/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.7986 - acc: 0.5489 - val_loss: 1.5309 - val_acc: 0.3736\n",
      "Epoch 33/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.7927 - acc: 0.5510 - val_loss: 1.5324 - val_acc: 0.3769\n",
      "Epoch 34/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.7871 - acc: 0.5534 - val_loss: 1.5262 - val_acc: 0.3724\n",
      "Epoch 35/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.7817 - acc: 0.5554 - val_loss: 1.5191 - val_acc: 0.3734\n",
      "Epoch 36/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.7766 - acc: 0.5574 - val_loss: 1.5137 - val_acc: 0.3794\n",
      "Epoch 37/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.7720 - acc: 0.5596 - val_loss: 1.5107 - val_acc: 0.3796\n",
      "Epoch 38/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.7676 - acc: 0.5614 - val_loss: 1.5142 - val_acc: 0.3755\n",
      "Epoch 39/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.7636 - acc: 0.5631 - val_loss: 1.5136 - val_acc: 0.3796\n",
      "Epoch 40/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.7598 - acc: 0.5645 - val_loss: 1.5138 - val_acc: 0.3797\n",
      "Epoch 41/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.7565 - acc: 0.5656 - val_loss: 1.5060 - val_acc: 0.3794\n",
      "Epoch 42/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.7531 - acc: 0.5672 - val_loss: 1.5061 - val_acc: 0.3774\n",
      "Epoch 43/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.7501 - acc: 0.5683 - val_loss: 1.5130 - val_acc: 0.3803\n",
      "Epoch 44/500\n",
      "258418/258418 [==============================] - 2s 7us/step - loss: 0.7473 - acc: 0.5695 - val_loss: 1.5004 - val_acc: 0.3800\n",
      "Epoch 45/500\n",
      "258418/258418 [==============================] - 2s 7us/step - loss: 0.7446 - acc: 0.5703 - val_loss: 1.5049 - val_acc: 0.3793\n",
      "Epoch 46/500\n",
      "258418/258418 [==============================] - 2s 7us/step - loss: 0.7423 - acc: 0.5712 - val_loss: 1.5070 - val_acc: 0.3792\n",
      "Epoch 47/500\n",
      "258418/258418 [==============================] - 2s 7us/step - loss: 0.7399 - acc: 0.5717 - val_loss: 1.5046 - val_acc: 0.3799\n",
      "Epoch 48/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.7375 - acc: 0.5723 - val_loss: 1.5112 - val_acc: 0.3778\n",
      "Epoch 49/500\n",
      "258418/258418 [==============================] - 2s 7us/step - loss: 0.7353 - acc: 0.5731 - val_loss: 1.5095 - val_acc: 0.3797\n",
      "Epoch 50/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.7333 - acc: 0.5740 - val_loss: 1.5046 - val_acc: 0.3805\n",
      "Epoch 51/500\n",
      "258418/258418 [==============================] - 2s 7us/step - loss: 0.7314 - acc: 0.5748 - val_loss: 1.5009 - val_acc: 0.3785\n",
      "Epoch 52/500\n",
      "258418/258418 [==============================] - 2s 7us/step - loss: 0.7294 - acc: 0.5753 - val_loss: 1.5031 - val_acc: 0.3771\n",
      "Epoch 53/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.7276 - acc: 0.5760 - val_loss: 1.5068 - val_acc: 0.3795\n",
      "Epoch 54/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.7259 - acc: 0.5769 - val_loss: 1.5070 - val_acc: 0.3754\n",
      "Epoch 55/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.7244 - acc: 0.5776 - val_loss: 1.5122 - val_acc: 0.3786\n",
      "Epoch 56/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.7228 - acc: 0.5780 - val_loss: 1.5046 - val_acc: 0.3764\n",
      "Epoch 57/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.7212 - acc: 0.5787 - val_loss: 1.5031 - val_acc: 0.3790\n",
      "Epoch 58/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.7199 - acc: 0.5794 - val_loss: 1.5125 - val_acc: 0.3786\n",
      "Epoch 59/500\n",
      "258418/258418 [==============================] - 2s 7us/step - loss: 0.7186 - acc: 0.5797 - val_loss: 1.4993 - val_acc: 0.3793\n",
      "Epoch 60/500\n",
      "258418/258418 [==============================] - 2s 7us/step - loss: 0.7173 - acc: 0.5806 - val_loss: 1.5065 - val_acc: 0.3789\n",
      "Epoch 61/500\n",
      "258418/258418 [==============================] - 2s 7us/step - loss: 0.7160 - acc: 0.5808 - val_loss: 1.5063 - val_acc: 0.3777\n",
      "Epoch 62/500\n",
      "258418/258418 [==============================] - 2s 7us/step - loss: 0.7148 - acc: 0.5816 - val_loss: 1.5065 - val_acc: 0.3787\n",
      "Epoch 63/500\n",
      "258418/258418 [==============================] - 2s 7us/step - loss: 0.7137 - acc: 0.5819 - val_loss: 1.5022 - val_acc: 0.3767\n",
      "Epoch 64/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.7125 - acc: 0.5825 - val_loss: 1.4993 - val_acc: 0.3753\n",
      "Epoch 65/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.7116 - acc: 0.5827 - val_loss: 1.4936 - val_acc: 0.3775\n",
      "Epoch 66/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.7103 - acc: 0.5832 - val_loss: 1.5008 - val_acc: 0.3754\n",
      "Epoch 67/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.7093 - acc: 0.5837 - val_loss: 1.4982 - val_acc: 0.3825\n",
      "Epoch 68/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.7084 - acc: 0.5843 - val_loss: 1.5017 - val_acc: 0.3776\n",
      "Epoch 69/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.7075 - acc: 0.5844 - val_loss: 1.4955 - val_acc: 0.3785\n",
      "Epoch 70/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.7063 - acc: 0.5851 - val_loss: 1.4984 - val_acc: 0.3801\n",
      "Epoch 71/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.7057 - acc: 0.5856 - val_loss: 1.4837 - val_acc: 0.3821\n",
      "Epoch 72/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.7047 - acc: 0.5854 - val_loss: 1.4950 - val_acc: 0.3786\n",
      "Epoch 73/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.7039 - acc: 0.5853 - val_loss: 1.4882 - val_acc: 0.3782\n",
      "Epoch 74/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.7030 - acc: 0.5859 - val_loss: 1.4875 - val_acc: 0.3798\n",
      "Epoch 75/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.7022 - acc: 0.5860 - val_loss: 1.4935 - val_acc: 0.3783\n",
      "Epoch 76/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.7012 - acc: 0.5861 - val_loss: 1.4894 - val_acc: 0.3794\n",
      "Epoch 77/500\n",
      "258418/258418 [==============================] - 2s 9us/step - loss: 0.7004 - acc: 0.5870 - val_loss: 1.4884 - val_acc: 0.3799\n",
      "Epoch 78/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.6997 - acc: 0.5864 - val_loss: 1.4879 - val_acc: 0.3770\n",
      "Epoch 79/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.6989 - acc: 0.5868 - val_loss: 1.4874 - val_acc: 0.3756\n",
      "Epoch 80/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.6983 - acc: 0.5873 - val_loss: 1.4906 - val_acc: 0.3776\n",
      "Epoch 81/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.6975 - acc: 0.5876 - val_loss: 1.4787 - val_acc: 0.3798\n",
      "Epoch 82/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.6969 - acc: 0.5876 - val_loss: 1.4900 - val_acc: 0.3769\n",
      "Epoch 83/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.6961 - acc: 0.5880 - val_loss: 1.4862 - val_acc: 0.3799\n",
      "Epoch 84/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.6955 - acc: 0.5877 - val_loss: 1.4738 - val_acc: 0.3810\n",
      "Epoch 85/500\n",
      "258418/258418 [==============================] - 2s 9us/step - loss: 0.6948 - acc: 0.5885 - val_loss: 1.4774 - val_acc: 0.3799\n",
      "Epoch 86/500\n",
      "258418/258418 [==============================] - 2s 9us/step - loss: 0.6942 - acc: 0.5887 - val_loss: 1.4820 - val_acc: 0.3805\n",
      "Epoch 87/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.6934 - acc: 0.5886 - val_loss: 1.4768 - val_acc: 0.3794\n",
      "Epoch 88/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.6929 - acc: 0.5888 - val_loss: 1.4833 - val_acc: 0.3763\n",
      "Epoch 89/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.6923 - acc: 0.5893 - val_loss: 1.4728 - val_acc: 0.3790\n",
      "Epoch 90/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.6918 - acc: 0.5899 - val_loss: 1.4787 - val_acc: 0.3788\n",
      "Epoch 91/500\n",
      "258418/258418 [==============================] - 2s 9us/step - loss: 0.6912 - acc: 0.5896 - val_loss: 1.4824 - val_acc: 0.3770\n",
      "Epoch 92/500\n",
      "258418/258418 [==============================] - 2s 9us/step - loss: 0.6907 - acc: 0.5898 - val_loss: 1.4779 - val_acc: 0.3756\n",
      "Epoch 93/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.6901 - acc: 0.5903 - val_loss: 1.4721 - val_acc: 0.3784\n",
      "Epoch 94/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.6895 - acc: 0.5904 - val_loss: 1.4722 - val_acc: 0.3787\n",
      "Epoch 95/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.6890 - acc: 0.5909 - val_loss: 1.4822 - val_acc: 0.3780\n",
      "Epoch 96/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.6884 - acc: 0.5909 - val_loss: 1.4738 - val_acc: 0.3792\n",
      "Epoch 97/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.6879 - acc: 0.5913 - val_loss: 1.4800 - val_acc: 0.3791\n",
      "Epoch 98/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.6874 - acc: 0.5910 - val_loss: 1.4783 - val_acc: 0.3784\n",
      "Epoch 99/500\n",
      "258418/258418 [==============================] - 2s 9us/step - loss: 0.6870 - acc: 0.5919 - val_loss: 1.4713 - val_acc: 0.3799\n",
      "Epoch 100/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.6865 - acc: 0.5916 - val_loss: 1.4668 - val_acc: 0.3792\n",
      "Epoch 101/500\n",
      "258418/258418 [==============================] - 2s 9us/step - loss: 0.6859 - acc: 0.5919 - val_loss: 1.4775 - val_acc: 0.3777\n",
      "Epoch 102/500\n",
      "258418/258418 [==============================] - 2s 9us/step - loss: 0.6856 - acc: 0.5923 - val_loss: 1.4774 - val_acc: 0.3774\n",
      "Epoch 103/500\n",
      "258418/258418 [==============================] - 2s 9us/step - loss: 0.6850 - acc: 0.5922 - val_loss: 1.4693 - val_acc: 0.3788\n",
      "Epoch 104/500\n",
      "258418/258418 [==============================] - 2s 9us/step - loss: 0.6847 - acc: 0.5925 - val_loss: 1.4777 - val_acc: 0.3798\n",
      "Epoch 105/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.6841 - acc: 0.5927 - val_loss: 1.4670 - val_acc: 0.3792\n",
      "Epoch 106/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.6837 - acc: 0.5927 - val_loss: 1.4730 - val_acc: 0.3783\n",
      "Epoch 107/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.6832 - acc: 0.5929 - val_loss: 1.4621 - val_acc: 0.3790\n",
      "Epoch 108/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.6828 - acc: 0.5932 - val_loss: 1.4735 - val_acc: 0.3799\n",
      "Epoch 109/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.6823 - acc: 0.5934 - val_loss: 1.4675 - val_acc: 0.3785\n",
      "Epoch 110/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.6820 - acc: 0.5940 - val_loss: 1.4758 - val_acc: 0.3794\n",
      "Epoch 111/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.6816 - acc: 0.5937 - val_loss: 1.4619 - val_acc: 0.3808\n",
      "Epoch 112/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.6810 - acc: 0.5940 - val_loss: 1.4750 - val_acc: 0.3781\n",
      "Epoch 113/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.6808 - acc: 0.5944 - val_loss: 1.4654 - val_acc: 0.3795\n",
      "Epoch 114/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.6804 - acc: 0.5939 - val_loss: 1.4572 - val_acc: 0.3800\n",
      "Epoch 115/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.6800 - acc: 0.5948 - val_loss: 1.4753 - val_acc: 0.3767\n",
      "Epoch 116/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.6796 - acc: 0.5948 - val_loss: 1.4645 - val_acc: 0.3774\n",
      "Epoch 117/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.6793 - acc: 0.5949 - val_loss: 1.4619 - val_acc: 0.3809\n",
      "Epoch 118/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.6788 - acc: 0.5952 - val_loss: 1.4683 - val_acc: 0.3784\n",
      "Epoch 119/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.6787 - acc: 0.5949 - val_loss: 1.4629 - val_acc: 0.3767\n",
      "Epoch 120/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.6782 - acc: 0.5955 - val_loss: 1.4695 - val_acc: 0.3791\n",
      "Epoch 121/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.6779 - acc: 0.5958 - val_loss: 1.4671 - val_acc: 0.3790\n",
      "Epoch 122/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.6775 - acc: 0.5958 - val_loss: 1.4720 - val_acc: 0.3763\n",
      "Epoch 123/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.6773 - acc: 0.5958 - val_loss: 1.4642 - val_acc: 0.3776\n",
      "Epoch 124/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.6768 - acc: 0.5960 - val_loss: 1.4719 - val_acc: 0.3759\n",
      "Epoch 125/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.6765 - acc: 0.5961 - val_loss: 1.4679 - val_acc: 0.3777\n",
      "Epoch 126/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.6761 - acc: 0.5965 - val_loss: 1.4668 - val_acc: 0.3815\n",
      "Epoch 127/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.6758 - acc: 0.5968 - val_loss: 1.4640 - val_acc: 0.3795\n",
      "Epoch 128/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.6754 - acc: 0.5966 - val_loss: 1.4654 - val_acc: 0.3781\n",
      "Epoch 129/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.6751 - acc: 0.5968 - val_loss: 1.4704 - val_acc: 0.3802\n",
      "Epoch 130/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.6748 - acc: 0.5973 - val_loss: 1.4574 - val_acc: 0.3804\n",
      "Epoch 131/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.6746 - acc: 0.5974 - val_loss: 1.4625 - val_acc: 0.3798\n",
      "Epoch 132/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.6741 - acc: 0.5977 - val_loss: 1.4683 - val_acc: 0.3756\n",
      "Epoch 133/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.6739 - acc: 0.5976 - val_loss: 1.4710 - val_acc: 0.3760\n",
      "Epoch 134/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.6735 - acc: 0.5974 - val_loss: 1.4652 - val_acc: 0.3788\n",
      "Epoch 135/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.6732 - acc: 0.5979 - val_loss: 1.4613 - val_acc: 0.3779\n",
      "Epoch 136/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.6730 - acc: 0.5978 - val_loss: 1.4542 - val_acc: 0.3779\n",
      "Epoch 137/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.6727 - acc: 0.5982 - val_loss: 1.4565 - val_acc: 0.3801\n",
      "Epoch 138/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.6724 - acc: 0.5980 - val_loss: 1.4662 - val_acc: 0.3784\n",
      "Epoch 139/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.6721 - acc: 0.5984 - val_loss: 1.4625 - val_acc: 0.3795\n",
      "Epoch 140/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.6718 - acc: 0.5986 - val_loss: 1.4647 - val_acc: 0.3780\n",
      "Epoch 141/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.6716 - acc: 0.5991 - val_loss: 1.4658 - val_acc: 0.3791\n",
      "Epoch 142/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.6712 - acc: 0.5990 - val_loss: 1.4581 - val_acc: 0.3789\n",
      "Epoch 143/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.6710 - acc: 0.5988 - val_loss: 1.4611 - val_acc: 0.3774\n",
      "Epoch 144/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.6708 - acc: 0.5993 - val_loss: 1.4581 - val_acc: 0.3797\n",
      "Epoch 145/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.6704 - acc: 0.5993 - val_loss: 1.4606 - val_acc: 0.3786\n",
      "Epoch 146/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.6703 - acc: 0.5990 - val_loss: 1.4582 - val_acc: 0.3783\n",
      "Epoch 147/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.6699 - acc: 0.5996 - val_loss: 1.4601 - val_acc: 0.3798\n",
      "Epoch 148/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.6697 - acc: 0.5996 - val_loss: 1.4610 - val_acc: 0.3763\n",
      "Epoch 149/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.6694 - acc: 0.5999 - val_loss: 1.4641 - val_acc: 0.3792\n",
      "Epoch 150/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.6691 - acc: 0.5999 - val_loss: 1.4678 - val_acc: 0.3796\n",
      "Epoch 151/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.6688 - acc: 0.6000 - val_loss: 1.4591 - val_acc: 0.3791\n",
      "Epoch 152/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.6686 - acc: 0.5997 - val_loss: 1.4676 - val_acc: 0.3784\n",
      "Epoch 153/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.6684 - acc: 0.6001 - val_loss: 1.4551 - val_acc: 0.3785\n",
      "Epoch 154/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.6681 - acc: 0.6002 - val_loss: 1.4580 - val_acc: 0.3808\n",
      "Epoch 155/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.6679 - acc: 0.6003 - val_loss: 1.4562 - val_acc: 0.3781\n",
      "Epoch 156/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.6676 - acc: 0.6003 - val_loss: 1.4565 - val_acc: 0.3800\n",
      "Epoch 157/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.6674 - acc: 0.6005 - val_loss: 1.4594 - val_acc: 0.3788\n",
      "Epoch 158/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.6672 - acc: 0.6004 - val_loss: 1.4613 - val_acc: 0.3782\n",
      "Epoch 159/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.6669 - acc: 0.6008 - val_loss: 1.4653 - val_acc: 0.3793\n",
      "Epoch 160/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.6668 - acc: 0.6007 - val_loss: 1.4575 - val_acc: 0.3790\n",
      "Epoch 161/500\n",
      "258418/258418 [==============================] - 2s 8us/step - loss: 0.6664 - acc: 0.6009 - val_loss: 1.4656 - val_acc: 0.3756\n",
      "Epoch 162/500\n",
      " 30000/258418 [==>...........................] - ETA: 1s - loss: 0.6635 - acc: 0.6038"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(24, input_dim = parameters1,return_sequences=True))\n",
    "model.add(LSTM(12))\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train,y_train, validation_data=(X_test,y_test), epochs=500,batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
