{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train', 'sample_submission.csv']\n",
      "Default GPU Device: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "from os.path import isdir, join\n",
    "import librosa\n",
    "from tqdm import tqdm\n",
    "# Any results you write to the current directory are saved as output.\n",
    "import tensorflow as tf\n",
    "if tf.test.gpu_device_name():\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"Please install GPU version of TF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# os.listdir(\"../input/dataasdfasd/\")\n",
    "# audio_file_path = \"../input/dataasdfasd/output.wav\"\n",
    "# os.linesep()\n",
    "# samps,sr = librosa.load(audio_file_path, mono=True, sr=None)\n",
    "# mfcc = librosa.feature.mfcc(samps, sr = sr)z\n",
    "# pad_width = max_pad - mfcc.shape[1]\n",
    "# mfcc = np.pad(mfcc, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "audio_path = \"../input/train/audio/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all audio dirs\n",
    "dirs = [f for f in os.listdir(audio_path) if os.path.isdir(join(audio_path, f))]\n",
    "dirs.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_background_noise_', 'bed', 'bird', 'cat', 'dog', 'down', 'eight', 'five', 'four', 'go', 'happy', 'house', 'left', 'marvin', 'nine', 'no', 'off', 'on', 'one', 'right', 'seven', 'sheila', 'six', 'stop', 'three', 'tree', 'two', 'up', 'wow', 'yes', 'zero']\n"
     ]
    }
   ],
   "source": [
    "print(dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa.display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# plt.figure(figsize=(10, 4))\n",
    "# librosa.display.specshow(mfcc, x_axis='time')\n",
    "# plt.colorbar()\n",
    "# plt.title('MFCC')\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "class AudioFeatureDataset():\n",
    "    def __init__(self,file_path):\n",
    "        self.file_path = file_path\n",
    "        self.labels = os.listdir(self.file_path)\n",
    "        self.labels.remove('_background_noise_')\n",
    "        self.target_labels = ['no', 'left', 'right', 'up', 'yes', 'down', 'stop', 'go', 'on', 'off','silence','unknown']\n",
    "        self.data_dict = {}\n",
    "        for tl in self.labels:\n",
    "            files_dir = os.path.join(file_path,tl)\n",
    "            all_audio_fp_s =[ os.path.join(files_dir,f) for f in os.listdir(files_dir)]\n",
    "            self.data_dict[tl] = all_audio_fp_s\n",
    "    \n",
    "    def process(self,file,max_pad = 32):\n",
    "        try:\n",
    "            samps,sr = librosa.load(file, mono=True, sr=None)\n",
    "            pad_len = 16000 - samps.shape[0]\n",
    "            if pad_len  >= 0:\n",
    "                samps= np.pad(samps,(0,pad_len),'constant')\n",
    "            return np.array(samps[:16000])\n",
    "        except:\n",
    "            print(file)\n",
    "\n",
    "\n",
    "    def get_dataset(self, include_background = False):\n",
    "        labels =  []\n",
    "        features = []\n",
    "        for t in tqdm(self.labels):\n",
    "            if (t == \"_background_noise_\"):\n",
    "                pass\n",
    "            if( t not in self.target_labels):\n",
    "                for fp in self.data_dict[t]:\n",
    "                    labels.append('unknown')\n",
    "                    features.append(self.process(fp))\n",
    "            else:\n",
    "                 for fp in self.data_dict[t]:\n",
    "                    labels.append(t)\n",
    "                    features.append(self.process(fp))\n",
    "        if include_background:\n",
    "            _dir_path = (audio_path + \"/_background_noise_\")\n",
    "            all_files_in_dir = os.listdir(_dir_path)\n",
    "            all_files_in_dir.pop()\n",
    "            all_sound_path = [ (audio_path + \"/_background_noise_/\" + x) for x in all_files_in_dir]\n",
    "            all_sound_path\n",
    "            all_samps = []\n",
    "            for file in all_sound_path:\n",
    "                samps,sr = librosa.load(file, mono=True, sr=None)\n",
    "                k = int(samps.shape[0]/16000) * 16000\n",
    "                samps =samps[:k].reshape(int(samps.shape[0]/16000),16000)\n",
    "                for s in tqdm(range(len(samps))):\n",
    "                    all_samps.append(samps[s])\n",
    "                    labels.append('silence')\n",
    "                    features.append(samps[s])\n",
    "            all_samps = np.array(all_samps)\n",
    "            \n",
    "        return labels, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = AudioFeatureDataset(audio_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [02:22<00:00,  4.34s/it]\n",
      "100%|██████████| 60/60 [00:00<00:00, 69193.91it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 181971.94it/s]\n",
      "100%|██████████| 95/95 [00:00<00:00, 257902.19it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 262412.87it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 102875.97it/s]\n",
      "100%|██████████| 60/60 [00:00<00:00, 183960.70it/s]\n"
     ]
    }
   ],
   "source": [
    "Y,x = a.get_dataset(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(x)\n",
    "Y = np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "del a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "class_weights = class_weight.compute_class_weight('balanced',np.unique(Y),Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.30037445,  2.287767  ,  2.30624026,  2.28487719,  2.3023264 ,\n",
       "        2.29259963,  2.29259963, 13.63463149,  2.28007703,  0.13222991,\n",
       "        2.28487719,  2.2829547 ])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(x)):\n",
    "#     pad_len = 16000 - x[i].shape[0]\n",
    "#     x[i] = np.pad(x[i],(0,pad_len),'constant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.reshape(x.shape[0], 1, 16000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "z  = [[1,2],[1,2]]\n",
    "z = np.array(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65119, 1, 16000)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def get_train_test(split_ratio=0.6, random_state=42):\n",
    "    return train_test_split(x, Y, test_size= (1 - split_ratio), random_state=random_state, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = get_train_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "del x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# plt.figure(figsize=(10, 4))\n",
    "# librosa.display.specshow(X_train[3], x_axis='time')\n",
    "# plt.colorbar()\n",
    "# plt.title('MFCC')\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "del Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4,  9,  0, ...,  9,  9, 11])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelencoder.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = dict(zip(labelencoder.classes_, range(len(labelencoder.classes_))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'down': 0,\n",
       " 'go': 1,\n",
       " 'left': 2,\n",
       " 'no': 3,\n",
       " 'off': 4,\n",
       " 'on': 5,\n",
       " 'right': 6,\n",
       " 'silence': 7,\n",
       " 'stop': 8,\n",
       " 'unknown': 9,\n",
       " 'up': 10,\n",
       " 'yes': 11}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = labelencoder.fit_transform(y_test)\n",
    "mapping = dict(zip(labelencoder.classes_, range(len(labelencoder.classes_))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'down': 0,\n",
       " 'go': 1,\n",
       " 'left': 2,\n",
       " 'no': 3,\n",
       " 'off': 4,\n",
       " 'on': 5,\n",
       " 'right': 6,\n",
       " 'silence': 7,\n",
       " 'stop': 8,\n",
       " 'unknown': 9,\n",
       " 'up': 10,\n",
       " 'yes': 11}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4,  9,  0, ...,  9,  9, 11])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = labelencoder.fit_transform(y_train)\n",
    "mapping = dict(zip(labelencoder.classes_, range(len(labelencoder.classes_))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kapre\r\n",
      "  Downloading https://files.pythonhosted.org/packages/3f/2e/f540d1d1f05c764686163fdb5bb1e5c703f1528076d2829bfc3900683f06/kapre-0.1.4-py3-none-any.whl\r\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.6/site-packages (from kapre) (0.17.1)\r\n",
      "Requirement already satisfied: numpy>=1.8.0 in /opt/conda/lib/python3.6/site-packages (from kapre) (1.16.3)\r\n",
      "Requirement already satisfied: librosa>=0.5 in /opt/conda/lib/python3.6/site-packages (from kapre) (0.6.3)\r\n",
      "Requirement already satisfied: keras>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from kapre) (2.2.4)\r\n",
      "Requirement already satisfied: six>=1.3 in /opt/conda/lib/python3.6/site-packages (from librosa>=0.5->kapre) (1.12.0)\r\n",
      "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /opt/conda/lib/python3.6/site-packages (from librosa>=0.5->kapre) (0.20.3)\r\n",
      "Requirement already satisfied: audioread>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from librosa>=0.5->kapre) (2.1.6)\r\n",
      "Requirement already satisfied: decorator>=3.0.0 in /opt/conda/lib/python3.6/site-packages (from librosa>=0.5->kapre) (4.3.0)\r\n",
      "Requirement already satisfied: joblib>=0.12 in /opt/conda/lib/python3.6/site-packages (from librosa>=0.5->kapre) (0.13.2)\r\n",
      "Requirement already satisfied: resampy>=0.2.0 in /opt/conda/lib/python3.6/site-packages (from librosa>=0.5->kapre) (0.2.1)\r\n",
      "Requirement already satisfied: scipy>=1.0.0 in /opt/conda/lib/python3.6/site-packages (from librosa>=0.5->kapre) (1.1.0)\r\n",
      "Requirement already satisfied: numba>=0.38.0 in /opt/conda/lib/python3.6/site-packages (from librosa>=0.5->kapre) (0.38.0)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.6/site-packages (from keras>=2.0.0->kapre) (3.12)\r\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /opt/conda/lib/python3.6/site-packages (from keras>=2.0.0->kapre) (1.0.7)\r\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.6/site-packages (from keras>=2.0.0->kapre) (2.9.0)\r\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.6/site-packages (from keras>=2.0.0->kapre) (1.0.9)\r\n",
      "Requirement already satisfied: llvmlite>=0.23.0dev0 in /opt/conda/lib/python3.6/site-packages (from numba>=0.38.0->librosa>=0.5->kapre) (0.23.1)\r\n",
      "Installing collected packages: kapre\r\n",
      "Successfully installed kapre-0.1.4\r\n",
      "\u001b[33mYou are using pip version 19.0.3, however version 19.1.1 is available.\r\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install kapre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:29: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(30, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "trainable_stft (Melspectrogr (None, 128, 32, 1)        296064    \n",
      "_________________________________________________________________\n",
      "additive_noise_1 (AdditiveNo (None, 128, 32, 1)        0         \n",
      "_________________________________________________________________\n",
      "normalization2d_1 (Normaliza (None, 128, 32, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 126, 30, 45)       450       \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average (None, 63, 15, 45)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 30, 13, 43)        17040     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 45, 11, 41)        12195     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 33, 9, 39)         13398     \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 45, 7, 37)         13410     \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 35, 5, 35)         14210     \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 45, 3, 33)         14220     \n",
      "_________________________________________________________________\n",
      "average_pooling2d_2 (Average (None, 22, 1, 33)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 726)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                11632     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 12)                204       \n",
      "=================================================================\n",
      "Total params: 392,823\n",
      "Trainable params: 96,759\n",
      "Non-trainable params: 296,064\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:30: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(45, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:31: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(33, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:32: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(45, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:33: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(35, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:34: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(45, kernel_size=(3, 3), activation=\"relu\", data_format=\"channels_first\")`\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import kapre\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,AveragePooling2D\n",
    "from kapre.time_frequency import Melspectrogram\n",
    "from kapre.utils import Normalization2D\n",
    "from kapre.augmentation import AdditiveNoise\n",
    "\n",
    "# 6 channels (!), maybe 1-sec audio signal, for an example.\n",
    "input_shape = (1,16000)\n",
    "sr = 16000\n",
    "model = Sequential()\n",
    "# A mel-spectrogram layer\n",
    "model.add(Melspectrogram(n_dft=512, n_hop=512, input_shape=input_shape,\n",
    "                         padding='same', sr=sr, n_mels=128,\n",
    "                         fmin=0.0, fmax=sr/2, power_melgram=1.0,\n",
    "                         return_decibel_melgram=True,trainable_fb=False,\n",
    "                         trainable_kernel=False,\n",
    "                         name='trainable_stft'))\n",
    "# Maybe some additive white noise.\n",
    "model.add(AdditiveNoise(power=0.1))\n",
    "# If you wanna normalise it per-frequency\n",
    "model.add(Normalization2D(str_axis='freq')) # or 'channel', 'time', 'batch', 'data_sample'\n",
    "# After this, it's just a usual keras workflow. For example..\n",
    "# Add some layers, e.g., model.add(some convolution layers..)\n",
    "# Compile the model\n",
    "model.add(Conv2D(45, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(AveragePooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(30, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\n",
    "model.add(Conv2D(45, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\n",
    "model.add(Conv2D(33, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\n",
    "model.add(Conv2D(45, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\n",
    "model.add(Conv2D(35, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\n",
    "model.add(Conv2D(45, kernel_size=(3, 3), activation='relu',dim_ordering=\"th\"))\n",
    "\n",
    "model.add(AveragePooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(16))\n",
    "model.add(Dense(12, activation='softmax'))\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.adam(),metrics=['accuracy'])\n",
    "model.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "y_test = to_categorical(y_test)\n",
    "y_train = to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train.reshape(-1,13062,16000).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# X_test = X_test.reshape(X_test.shape[0], 20, 32, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = X_train[0].reshape(1,16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.predict(np.array([a]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Optimizer\n",
    "from keras import backend as K\n",
    "import six\n",
    "import copy\n",
    "from six.moves import zip\n",
    "from keras.utils.generic_utils import serialize_keras_object\n",
    "from keras.utils.generic_utils import deserialize_keras_object\n",
    "from keras.legacy import interfaces\n",
    "class AdamW(Optimizer):\n",
    "    \"\"\"Adam optimizer.\n",
    "    Default parameters follow those provided in the original paper.\n",
    "    # Arguments\n",
    "        lr: float >= 0. Learning rate.\n",
    "        beta_1: float, 0 < beta < 1. Generally close to 1.\n",
    "        beta_2: float, 0 < beta < 1. Generally close to 1.\n",
    "        epsilon: float >= 0. Fuzz factor.\n",
    "        decay: float >= 0. Learning rate decay over each update.\n",
    "        weight_decay: float >= 0. Decoupled weight decay over each update.\n",
    "    # References\n",
    "        - [Adam - A Method for Stochastic Optimization](http://arxiv.org/abs/1412.6980v8)\n",
    "        - [Optimization for Deep Learning Highlights in 2017](http://ruder.io/deep-learning-optimization-2017/index.html)\n",
    "        - [Fixing Weight Decay Regularization in Adam](https://arxiv.org/abs/1711.05101)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, lr=0.001, beta_1=0.9, beta_2=0.999, weight_decay=1e-4,  # decoupled weight decay (1/6)\n",
    "                 epsilon=1e-8, decay=0., **kwargs):\n",
    "        super(AdamW, self).__init__(**kwargs)\n",
    "        with K.name_scope(self.__class__.__name__):\n",
    "            self.iterations = K.variable(0, dtype='int64', name='iterations')\n",
    "            self.lr = K.variable(lr, name='lr')\n",
    "            self.init_lr = lr # decoupled weight decay (2/6)\n",
    "            self.beta_1 = K.variable(beta_1, name='beta_1')\n",
    "            self.beta_2 = K.variable(beta_2, name='beta_2')\n",
    "            self.decay = K.variable(decay, name='decay')\n",
    "            self.wd = K.variable(weight_decay, name='weight_decay') # decoupled weight decay (3/6)\n",
    "        self.epsilon = epsilon\n",
    "        self.initial_decay = decay\n",
    "\n",
    "    @interfaces.legacy_get_updates_support\n",
    "    def get_updates(self, loss, params):\n",
    "        grads = self.get_gradients(loss, params)\n",
    "        self.updates = [K.update_add(self.iterations, 1)]\n",
    "        wd = self.wd # decoupled weight decay (4/6)\n",
    "\n",
    "        lr = self.lr\n",
    "        if self.initial_decay > 0:\n",
    "            lr *= (1. / (1. + self.decay * K.cast(self.iterations,\n",
    "                                                  K.dtype(self.decay))))\n",
    "        eta_t = lr / self.init_lr # decoupled weight decay (5/6)\n",
    "\n",
    "        t = K.cast(self.iterations, K.floatx()) + 1\n",
    "        lr_t = lr * (K.sqrt(1. - K.pow(self.beta_2, t)) /\n",
    "                     (1. - K.pow(self.beta_1, t)))\n",
    "\n",
    "        ms = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n",
    "        vs = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n",
    "        self.weights = [self.iterations] + ms + vs\n",
    "\n",
    "        for p, g, m, v in zip(params, grads, ms, vs):\n",
    "            m_t = (self.beta_1 * m) + (1. - self.beta_1) * g\n",
    "            v_t = (self.beta_2 * v) + (1. - self.beta_2) * K.square(g)\n",
    "            p_t = p - lr_t * m_t / (K.sqrt(v_t) + self.epsilon) - eta_t * wd * p # decoupled weight decay (6/6)\n",
    "\n",
    "            self.updates.append(K.update(m, m_t))\n",
    "            self.updates.append(K.update(v, v_t))\n",
    "            new_p = p_t\n",
    "\n",
    "            # Apply constraints.\n",
    "            if getattr(p, 'constraint', None) is not None:\n",
    "                new_p = p.constraint(new_p)\n",
    "\n",
    "            self.updates.append(K.update(p, new_p))\n",
    "        return self.updates\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'lr': float(K.get_value(self.lr)),\n",
    "                  'beta_1': float(K.get_value(self.beta_1)),\n",
    "                  'beta_2': float(K.get_value(self.beta_2)),\n",
    "                  'decay': float(K.get_value(self.decay)),\n",
    "                  'weight_decay': float(K.get_value(self.wd)),\n",
    "                  'epsilon': self.epsilon}\n",
    "        base_config = super(AdamW, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Conv2D(64, kernel_size=(20, 8), activation='relu', input_shape=(20, 32, 1)))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2),dim_ordering=\"th\"))\n",
    "# model.add(Dropout(0.25))\n",
    "# model.add(Conv2D(64, kernel_size=(10, 4), activation='relu',dim_ordering=\"th\"))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2),dim_ordering=\"th\"))\n",
    "# model.add(Dropout(0.25))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(128, activation='relu'))\n",
    "# model.add(Dropout(0.25))\n",
    "# model.add(Dense(10, activation='softmax'))\n",
    "# model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "#               optimizer=keras.optimizers.adam(),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 38071 samples, validate on 26048 samples\n",
      "Epoch 1/100\n",
      "38071/38071 [==============================] - 12s 325us/step - loss: 1.1853 - acc: 0.6700 - val_loss: 0.6529 - val_acc: 0.7869\n",
      "Epoch 2/100\n",
      "38071/38071 [==============================] - 8s 219us/step - loss: 0.5257 - acc: 0.8309 - val_loss: 0.4527 - val_acc: 0.8536\n",
      "Epoch 3/100\n",
      "38071/38071 [==============================] - 8s 215us/step - loss: 0.3771 - acc: 0.8780 - val_loss: 0.3434 - val_acc: 0.8900\n",
      "Epoch 4/100\n",
      "38071/38071 [==============================] - 8s 215us/step - loss: 0.3189 - acc: 0.8991 - val_loss: 0.2886 - val_acc: 0.9098\n",
      "Epoch 5/100\n",
      "38071/38071 [==============================] - 8s 220us/step - loss: 0.2754 - acc: 0.9114 - val_loss: 0.2783 - val_acc: 0.9114\n",
      "Epoch 6/100\n",
      "38071/38071 [==============================] - 8s 215us/step - loss: 0.2388 - acc: 0.9239 - val_loss: 0.2793 - val_acc: 0.9142\n",
      "Epoch 7/100\n",
      "38071/38071 [==============================] - 8s 214us/step - loss: 0.2181 - acc: 0.9292 - val_loss: 0.2570 - val_acc: 0.9210\n",
      "Epoch 8/100\n",
      "38071/38071 [==============================] - 8s 214us/step - loss: 0.1989 - acc: 0.9356 - val_loss: 0.2448 - val_acc: 0.9282\n",
      "Epoch 9/100\n",
      "38071/38071 [==============================] - 8s 215us/step - loss: 0.1832 - acc: 0.9411 - val_loss: 0.2353 - val_acc: 0.9266\n",
      "Epoch 10/100\n",
      "38071/38071 [==============================] - 8s 217us/step - loss: 0.1686 - acc: 0.9452 - val_loss: 0.2507 - val_acc: 0.9258\n",
      "Epoch 11/100\n",
      "38071/38071 [==============================] - 8s 215us/step - loss: 0.1535 - acc: 0.9503 - val_loss: 0.2274 - val_acc: 0.9326\n",
      "Epoch 12/100\n",
      "38071/38071 [==============================] - 8s 214us/step - loss: 0.1425 - acc: 0.9543 - val_loss: 0.2516 - val_acc: 0.9270\n",
      "Epoch 13/100\n",
      "38071/38071 [==============================] - 8s 214us/step - loss: 0.1352 - acc: 0.9556 - val_loss: 0.2366 - val_acc: 0.9312\n",
      "Epoch 14/100\n",
      "38071/38071 [==============================] - 8s 215us/step - loss: 0.1218 - acc: 0.9602 - val_loss: 0.2190 - val_acc: 0.9388\n",
      "Epoch 15/100\n",
      "38071/38071 [==============================] - 8s 216us/step - loss: 0.1176 - acc: 0.9616 - val_loss: 0.2465 - val_acc: 0.9355\n",
      "Epoch 16/100\n",
      "38071/38071 [==============================] - 8s 215us/step - loss: 0.1081 - acc: 0.9649 - val_loss: 0.2587 - val_acc: 0.9327\n",
      "Epoch 17/100\n",
      "38071/38071 [==============================] - 8s 215us/step - loss: 0.1037 - acc: 0.9659 - val_loss: 0.2683 - val_acc: 0.9313\n",
      "Epoch 18/100\n",
      "38071/38071 [==============================] - 8s 216us/step - loss: 0.0982 - acc: 0.9674 - val_loss: 0.2447 - val_acc: 0.9385\n",
      "Epoch 19/100\n",
      "38071/38071 [==============================] - 8s 215us/step - loss: 0.0913 - acc: 0.9708 - val_loss: 0.2479 - val_acc: 0.9355\n",
      "Epoch 20/100\n",
      "38071/38071 [==============================] - 8s 215us/step - loss: 0.0844 - acc: 0.9721 - val_loss: 0.2805 - val_acc: 0.9372\n",
      "Epoch 21/100\n",
      "38071/38071 [==============================] - 8s 216us/step - loss: 0.0811 - acc: 0.9737 - val_loss: 0.2629 - val_acc: 0.9355\n",
      "Epoch 22/100\n",
      "38071/38071 [==============================] - 8s 215us/step - loss: 0.0783 - acc: 0.9737 - val_loss: 0.2678 - val_acc: 0.9365\n",
      "Epoch 23/100\n",
      "38071/38071 [==============================] - 8s 214us/step - loss: 0.0771 - acc: 0.9748 - val_loss: 0.2884 - val_acc: 0.9303\n",
      "Epoch 24/100\n",
      "38071/38071 [==============================] - 8s 215us/step - loss: 0.0722 - acc: 0.9762 - val_loss: 0.2550 - val_acc: 0.9385\n",
      "Epoch 25/100\n",
      "38071/38071 [==============================] - 8s 216us/step - loss: 0.0675 - acc: 0.9788 - val_loss: 0.2798 - val_acc: 0.9353\n",
      "Epoch 26/100\n",
      "38071/38071 [==============================] - 8s 215us/step - loss: 0.0675 - acc: 0.9777 - val_loss: 0.2649 - val_acc: 0.9409\n",
      "Epoch 27/100\n",
      "38071/38071 [==============================] - 8s 215us/step - loss: 0.0678 - acc: 0.9779 - val_loss: 0.2702 - val_acc: 0.9361\n",
      "Epoch 28/100\n",
      "38071/38071 [==============================] - 8s 215us/step - loss: 0.0593 - acc: 0.9814 - val_loss: 0.3295 - val_acc: 0.9361\n",
      "Epoch 29/100\n",
      "38071/38071 [==============================] - 8s 217us/step - loss: 0.0620 - acc: 0.9801 - val_loss: 0.2766 - val_acc: 0.9355\n",
      "Epoch 30/100\n",
      "38071/38071 [==============================] - 8s 217us/step - loss: 0.0617 - acc: 0.9800 - val_loss: 0.2808 - val_acc: 0.9377\n",
      "Epoch 31/100\n",
      "38071/38071 [==============================] - 8s 216us/step - loss: 0.0605 - acc: 0.9806 - val_loss: 0.2864 - val_acc: 0.9406\n",
      "Epoch 32/100\n",
      "38071/38071 [==============================] - 8s 216us/step - loss: 0.0533 - acc: 0.9828 - val_loss: 0.2874 - val_acc: 0.9383\n",
      "Epoch 33/100\n",
      "38071/38071 [==============================] - 8s 215us/step - loss: 0.0504 - acc: 0.9847 - val_loss: 0.3161 - val_acc: 0.9387\n",
      "Epoch 34/100\n",
      "38071/38071 [==============================] - 8s 215us/step - loss: 0.0605 - acc: 0.9799 - val_loss: 0.3097 - val_acc: 0.9299\n",
      "Epoch 35/100\n",
      "38071/38071 [==============================] - 8s 215us/step - loss: 0.0485 - acc: 0.9846 - val_loss: 0.3603 - val_acc: 0.9327\n",
      "Epoch 36/100\n",
      "38071/38071 [==============================] - 8s 215us/step - loss: 0.0515 - acc: 0.9836 - val_loss: 0.2925 - val_acc: 0.9395\n",
      "Epoch 37/100\n",
      "38071/38071 [==============================] - 8s 216us/step - loss: 0.0493 - acc: 0.9843 - val_loss: 0.2971 - val_acc: 0.9388\n",
      "Epoch 38/100\n",
      "38071/38071 [==============================] - 8s 216us/step - loss: 0.0506 - acc: 0.9845 - val_loss: 0.3011 - val_acc: 0.9401\n",
      "Epoch 39/100\n",
      "38071/38071 [==============================] - 8s 219us/step - loss: 0.0486 - acc: 0.9838 - val_loss: 0.3219 - val_acc: 0.9366\n",
      "Epoch 40/100\n",
      "38071/38071 [==============================] - 8s 217us/step - loss: 0.0491 - acc: 0.9840 - val_loss: 0.3439 - val_acc: 0.9343\n",
      "Epoch 41/100\n",
      "38071/38071 [==============================] - 8s 215us/step - loss: 0.0478 - acc: 0.9853 - val_loss: 0.3063 - val_acc: 0.9379\n",
      "Epoch 42/100\n",
      "38071/38071 [==============================] - 8s 217us/step - loss: 0.0419 - acc: 0.9869 - val_loss: 0.3193 - val_acc: 0.9405\n",
      "Epoch 43/100\n",
      "38071/38071 [==============================] - 8s 219us/step - loss: 0.0438 - acc: 0.9866 - val_loss: 0.3337 - val_acc: 0.9396\n",
      "Epoch 44/100\n",
      "38071/38071 [==============================] - 8s 217us/step - loss: 0.0492 - acc: 0.9845 - val_loss: 0.2942 - val_acc: 0.9354\n",
      "Epoch 45/100\n",
      "38071/38071 [==============================] - 8s 215us/step - loss: 0.0386 - acc: 0.9877 - val_loss: 0.3267 - val_acc: 0.9402\n",
      "Epoch 46/100\n",
      "38071/38071 [==============================] - 8s 216us/step - loss: 0.0425 - acc: 0.9868 - val_loss: 0.3314 - val_acc: 0.9388\n",
      "Epoch 47/100\n",
      "38071/38071 [==============================] - 8s 216us/step - loss: 0.0407 - acc: 0.9874 - val_loss: 0.3541 - val_acc: 0.9353\n",
      "Epoch 48/100\n",
      "38071/38071 [==============================] - 8s 215us/step - loss: 0.0408 - acc: 0.9866 - val_loss: 0.3378 - val_acc: 0.9369\n",
      "Epoch 49/100\n",
      "38071/38071 [==============================] - 8s 215us/step - loss: 0.0443 - acc: 0.9871 - val_loss: 0.3160 - val_acc: 0.9388\n",
      "Epoch 50/100\n",
      "38071/38071 [==============================] - 8s 216us/step - loss: 0.0424 - acc: 0.9863 - val_loss: 0.3316 - val_acc: 0.9378\n",
      "Epoch 51/100\n",
      "38071/38071 [==============================] - 8s 216us/step - loss: 0.0340 - acc: 0.9897 - val_loss: 0.3257 - val_acc: 0.9390\n",
      "Epoch 52/100\n",
      "38071/38071 [==============================] - 8s 215us/step - loss: 0.0328 - acc: 0.9899 - val_loss: 0.3332 - val_acc: 0.9411\n",
      "Epoch 53/100\n",
      "38071/38071 [==============================] - 8s 215us/step - loss: 0.0367 - acc: 0.9889 - val_loss: 0.3515 - val_acc: 0.9396\n",
      "Epoch 54/100\n",
      "38071/38071 [==============================] - 8s 215us/step - loss: 0.0415 - acc: 0.9875 - val_loss: 0.3442 - val_acc: 0.9383\n",
      "Epoch 55/100\n",
      "10000/38071 [======>.......................] - ETA: 4s - loss: 0.0352 - acc: 0.9883"
     ]
    }
   ],
   "source": [
    "model.fit(X_train[1000:], y_train[1000:], batch_size=100, epochs=100, verbose=1, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense_2/Softmax\n",
      "trainable_stft_input\n"
     ]
    }
   ],
   "source": [
    "print(model.output.op.name)\n",
    "print(model.input.op.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "866\n",
      "CPU times: user 2.24 s, sys: 144 ms, total: 2.38 s\n",
      "Wall time: 1.74 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "count = 0\n",
    "for i in range(1000):    \n",
    "    tesval = np.array([X_train[i]]).reshape(1,1,16000)\n",
    "    if np.argmax(model.predict(tesval)) ==  np.argmax(y_train[i]):\n",
    "        count+= 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(model.predict(tesval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dense_2/Softmax'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.output.op.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('94_cnn.h5',keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"yo.h5\")\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown layer: Melspectrogram",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-d577127b235e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlite\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mconverter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFLiteConverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_keras_model_file\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m'yo.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtfmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallow_custom_ops\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mopen\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"model.tflite\"\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36mfrom_keras_model_file\u001b[0;34m(cls, model_file, input_arrays, input_shapes, output_arrays)\u001b[0m\n\u001b[1;32m    368\u001b[0m     \u001b[0m_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m     \u001b[0m_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_learning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m     \u001b[0mkeras_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m     \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    232\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No model found in config file.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_from_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;31m# set weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/engine/saving.py\u001b[0m in \u001b[0;36mmodel_from_config\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m    322\u001b[0m                     '`Sequential.from_config(config)`?')\n\u001b[1;32m    323\u001b[0m   \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeserialize\u001b[0m  \u001b[0;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/layers/serialization.py\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m     72\u001b[0m       \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m       \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m       printable_module_name='layer')\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    190\u001b[0m             custom_objects=dict(\n\u001b[1;32m    191\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_GLOBAL_CUSTOM_OBJECTS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m                 list(custom_objects.items())))\n\u001b[0m\u001b[1;32m    193\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mCustomObjectScope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m    347\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlayer_config\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayer_configs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m       layer = layer_module.deserialize(layer_config,\n\u001b[0;32m--> 349\u001b[0;31m                                        custom_objects=custom_objects)\n\u001b[0m\u001b[1;32m    350\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbuild_input_shape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/layers/serialization.py\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m     72\u001b[0m       \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m       \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m       printable_module_name='layer')\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midentifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     (cls, cls_config) = class_and_config_for_serialized_keras_object(\n\u001b[0;32m--> 181\u001b[0;31m         config, module_objects, custom_objects, printable_module_name)\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'from_config'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mclass_and_config_for_serialized_keras_object\u001b[0;34m(config, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule_objects\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unknown '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mprintable_module_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mclass_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown layer: Melspectrogram"
     ]
    }
   ],
   "source": [
    "from tensorflow.contrib import lite\n",
    "converter = lite.TFLiteConverter.from_keras_model_file( 'yo.h5')\n",
    "tfmodel = converter.convert()\n",
    "converter.allow_custom_ops=True\n",
    "open (\"model.tflite\" , \"wb\") .write(tfmodel)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
